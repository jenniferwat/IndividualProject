{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374a49e1",
   "metadata": {},
   "source": [
    "### Training of procedure classifiers for ensemble - full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "32fcad27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.24.3\n",
      "Pandas version: 1.5.3\n",
      "Scikit version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# External libraries for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "#To render graphs within notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Versions of libraries\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Scikit version: {}\".format(sk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "588d60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "609cc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1bd6d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)\n",
    "\n",
    "df_admissions['dischtime'] = pd.to_datetime(df_admissions['dischtime'], format='%d/%m/%Y %H:%M')\n",
    "df_admissions['admittime'] = pd.to_datetime(df_admissions['admittime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_admittime= pd.DataFrame()\n",
    "df_admittime['hadm_id'] = df_admissions['hadm_id']\n",
    "df_admittime['admittime'] = df_admissions['admittime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe170a1",
   "metadata": {},
   "source": [
    "#### Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "163609a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_days(duration_str):\n",
    "    parts = duration_str.split(' days ')  # Split string into form ['22', '20:55:00']\n",
    "    days = float(parts[0])  # Extract number of days and convert to float\n",
    "    time_parts = parts[1].split(':')  # Split time part (hh:mm:ss) ['20', '55', '00']\n",
    "    hours = float(time_parts[0])  # Extract hours and convert to float\n",
    "    minutes = float(time_parts[1])  # Extract minutes and convert to float\n",
    "    seconds = float(time_parts[2])  # Extract seconds and convert to float\n",
    "    total_days = days + (hours / 24) + (minutes / (24 * 60)) + (seconds / (24 * 3600))  # Calculate total days\n",
    "    return total_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a0f24",
   "metadata": {},
   "source": [
    "### Target variable calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "be4ccf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/procedures_icd.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_procedures = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dff0df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/d_icd_procedures.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_codes = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "55b33994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns \n",
    "df_procedures = df_procedures.drop(columns=['subject_id', 'seq_num','icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6543e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate code values for each group\n",
    "concat_df = df_procedures.groupby(['hadm_id', 'chartdate'])['icd_code'].agg(lambda x: ','.join(x)).reset_index()\n",
    "\n",
    "# Split the comma-separated codes into individual columns\n",
    "split_df = concat_df['icd_code'].str.get_dummies(',')\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded columns\n",
    "df_procedures = pd.concat([concat_df, split_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c80f26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedures = df_procedures.drop(columns='icd_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5b32c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_procedures['chartdate'] = pd.to_datetime(df_procedures['chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5179703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>0039</th>\n",
       "      <th>0040</th>\n",
       "      <th>0041</th>\n",
       "      <th>0045</th>\n",
       "      <th>0051</th>\n",
       "      <th>0066</th>\n",
       "      <th>0069</th>\n",
       "      <th>0091</th>\n",
       "      <th>...</th>\n",
       "      <th>B41GYZZ</th>\n",
       "      <th>B518YZA</th>\n",
       "      <th>B51W1ZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>B54BZZA</th>\n",
       "      <th>BT1DYZZ</th>\n",
       "      <th>BT1FYZZ</th>\n",
       "      <th>D7021ZZ</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>2113-08-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>2143-09-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20199380</td>\n",
       "      <td>2144-10-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>2144-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>2137-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>29820177</td>\n",
       "      <td>2150-07-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>29839885</td>\n",
       "      <td>2170-10-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>29842315</td>\n",
       "      <td>2155-12-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>29974575</td>\n",
       "      <td>2131-02-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>29974575</td>\n",
       "      <td>2131-03-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  chartdate  0039  0040  0041  0045  0051  0066  0069  0091  ...  \\\n",
       "0    20044587 2113-08-25     0     0     0     0     0     0     0     0  ...   \n",
       "1    20093566 2143-09-27     0     0     0     0     0     0     0     0  ...   \n",
       "2    20199380 2144-10-29     0     0     0     0     0     0     0     0  ...   \n",
       "3    20199380 2144-10-31     0     0     0     0     0     0     0     0  ...   \n",
       "4    20214994 2137-02-25     0     0     0     0     0     0     0     0  ...   \n",
       "..        ...        ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "386  29820177 2150-07-10     0     0     0     0     0     0     0     0  ...   \n",
       "387  29839885 2170-10-08     0     0     0     0     1     0     0     0  ...   \n",
       "388  29842315 2155-12-05     0     0     0     0     0     0     0     0  ...   \n",
       "389  29974575 2131-02-27     0     0     0     0     0     0     0     0  ...   \n",
       "390  29974575 2131-03-03     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "     B41GYZZ  B518YZA  B51W1ZZ  B543ZZ3  B548ZZA  B54BZZA  BT1DYZZ  BT1FYZZ  \\\n",
       "0          0        0        0        0        0        0        0        0   \n",
       "1          0        0        0        0        0        0        0        0   \n",
       "2          0        0        0        0        0        0        0        0   \n",
       "3          0        0        0        0        0        0        0        0   \n",
       "4          0        0        0        0        0        0        0        0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "386        0        0        0        0        0        0        0        0   \n",
       "387        0        0        0        0        0        0        0        0   \n",
       "388        0        0        0        0        0        0        0        0   \n",
       "389        0        0        0        0        0        0        0        0   \n",
       "390        0        0        0        0        0        0        0        0   \n",
       "\n",
       "     D7021ZZ  DW021ZZ  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "..       ...      ...  \n",
       "386        0        0  \n",
       "387        0        0  \n",
       "388        0        0  \n",
       "389        0        0  \n",
       "390        0        0  \n",
       "\n",
       "[391 rows x 354 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86930ed0",
   "metadata": {},
   "source": [
    "#### Select 55 (20% of) admissions to use for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "eaf9a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d5a09ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27617929, 27553957, 20282368, 27296885, 24980601, 21133938, 25559382, 20611796, 28778757, 28723315, 28998349, 28676446, 29276678, 26842957, 21477991, 25922998, 26706939, 27993466, 28236161, 27259207, 20385771, 24540843, 20900955, 22413744, 27494880, 25103777, 21599196, 21540783, 22585261, 26275841, 22130791, 22490490, 25020332, 29279905, 29483621, 27167814, 25508812, 21607814, 20297618, 29974575, 24912093, 21255400, 29295881, 28829452, 24656677, 29858644, 23488445, 25970245, 22508257, 25742920, 25085565, 22228639, 27660781, 28335091, 27703517]\n"
     ]
    }
   ],
   "source": [
    "evaluation_admissions = df_admissions['hadm_id'].sample(n=55, random_state=42).tolist()\n",
    "\n",
    "# Any records belonging to these admissions will be removed before training \n",
    "print(evaluation_admissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7096dad",
   "metadata": {},
   "source": [
    "### Emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "62871fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/emar.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_emar = pd.read_csv(full_path)\n",
    "\n",
    "# records for 65 different patients \n",
    "# 181 unique admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f67d4",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "72b5be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = df_emar[df_emar['hadm_id'].isin(df_procedures['hadm_id'])]\n",
    "\n",
    "# For each sample, get the rows from df_procedures that have the same hadm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "f1e59b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = df_emar.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "dbaa82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_emar['charttime'] = pd.to_datetime(df_emar['charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "1aa83918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature called delay using scheduletime - charttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_emar['scheduletime'] = pd.to_datetime(df_emar['scheduletime'], format='%Y/%m/%d %H:%M')\n",
    "df_emar['charttime'] = pd.to_datetime(df_emar['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_emar['delay'] = df_emar['charttime'] - df_emar['scheduletime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_emar['delay'] = df_emar['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "86e29afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = df_emar.drop(columns=['subject_id','emar_id','poe_id','pharmacy_id',\n",
    "                               'event_txt','scheduletime','storetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "e7fe931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null with N/A and then one hot encode\n",
    "df_emar['enter_provider_id'] = df_emar['enter_provider_id'].fillna('N/A')\n",
    "df_emar['medication'] = df_emar['medication'].fillna('N/A')\n",
    "df_emar = pd.get_dummies(df_emar, columns=['enter_provider_id', 'medication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "7216d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_emar.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['charttime']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "07b251a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_emar['icd_code'] = float('nan')\n",
    "# for index, row in df_emar.iterrows():\n",
    "#     # Filter target df based on 'hadm_id'\n",
    "#     df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "\n",
    "#     datetime_value = row['charttime']\n",
    "    \n",
    "#     # Filter out datetime values in the second dataframe that are later than the datetime value in the first dataframe\n",
    "#     filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "#     if not filtered_procedures.empty:\n",
    "\n",
    "#         # Find the closest datetime value in the filtered second dataframe\n",
    "#         closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "#         # Get the id of the sample with the closest datetime value\n",
    "#         closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]['icd_code']\n",
    "#         code = pd.array(closest_id)[0]\n",
    "\n",
    "#         # Assign the id to the current row in the first dataframe\n",
    "#         df_emar.at[index, 'icd_code'] = str(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "1a7374c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "9bc7ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "\n",
    "df_emar_training = df_emar[~df_emar['hadm_id'].isin(evaluation_admissions)]\n",
    "df_emar_evaluation = df_emar[df_emar['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "633faaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_training_target = codes.loc[df_emar_training.index]\n",
    "df_emar_evaluation_target = codes.loc[df_emar_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "cf8aa874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>0039</th>\n",
       "      <th>0040</th>\n",
       "      <th>0041</th>\n",
       "      <th>0045</th>\n",
       "      <th>0051</th>\n",
       "      <th>0066</th>\n",
       "      <th>0069</th>\n",
       "      <th>0091</th>\n",
       "      <th>...</th>\n",
       "      <th>B41GYZZ</th>\n",
       "      <th>B518YZA</th>\n",
       "      <th>B51W1ZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>B54BZZA</th>\n",
       "      <th>BT1DYZZ</th>\n",
       "      <th>BT1FYZZ</th>\n",
       "      <th>D7021ZZ</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21322534</td>\n",
       "      <td>2155-05-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27738145</td>\n",
       "      <td>2187-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24104168</td>\n",
       "      <td>2169-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24104168</td>\n",
       "      <td>2169-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24104168</td>\n",
       "      <td>2169-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14231</th>\n",
       "      <td>27996267</td>\n",
       "      <td>2148-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14232</th>\n",
       "      <td>22429197</td>\n",
       "      <td>2148-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>22429197</td>\n",
       "      <td>2148-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14235</th>\n",
       "      <td>29366372</td>\n",
       "      <td>2167-05-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14236</th>\n",
       "      <td>27525946</td>\n",
       "      <td>2153-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10886 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  chartdate  0039  0040  0041  0045  0051  0066  0069  0091  \\\n",
       "0      21322534 2155-05-09     0     0     0     0     0     0     0     0   \n",
       "1      27738145 2187-02-11     0     0     0     0     0     0     0     0   \n",
       "2      24104168 2169-01-20     0     0     0     0     0     0     0     0   \n",
       "3      24104168 2169-01-20     0     0     0     0     0     0     0     0   \n",
       "4      24104168 2169-01-20     0     0     0     0     0     0     0     0   \n",
       "...         ...        ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "14231  27996267 2148-01-31     0     0     0     0     0     0     0     0   \n",
       "14232  22429197 2148-01-01     0     0     0     0     0     0     0     0   \n",
       "14233  22429197 2148-01-04     0     0     0     0     0     0     0     0   \n",
       "14235  29366372 2167-05-05     0     0     0     0     0     0     0     0   \n",
       "14236  27525946 2153-04-15     0     0     0     0     0     0     0     0   \n",
       "\n",
       "       ...  B41GYZZ  B518YZA  B51W1ZZ  B543ZZ3  B548ZZA  B54BZZA  BT1DYZZ  \\\n",
       "0      ...        0        0        0        0        0        0        0   \n",
       "1      ...        0        0        0        0        0        0        0   \n",
       "2      ...        0        0        0        0        0        0        0   \n",
       "3      ...        0        0        0        0        0        0        0   \n",
       "4      ...        0        0        0        0        0        0        0   \n",
       "...    ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "14231  ...        0        0        0        0        0        0        0   \n",
       "14232  ...        0        0        0        0        0        0        0   \n",
       "14233  ...        0        0        0        0        0        0        0   \n",
       "14235  ...        0        0        0        0        0        0        0   \n",
       "14236  ...        0        0        0        0        0        0        0   \n",
       "\n",
       "       BT1FYZZ  D7021ZZ  DW021ZZ  \n",
       "0            0        0        0  \n",
       "1            0        0        0  \n",
       "2            0        0        0  \n",
       "3            0        0        0  \n",
       "4            0        0        0  \n",
       "...        ...      ...      ...  \n",
       "14231        0        0        0  \n",
       "14232        0        0        0  \n",
       "14233        0        0        0  \n",
       "14235        0        0        0  \n",
       "14236        0        0        0  \n",
       "\n",
       "[10886 rows x 354 columns]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emar_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "405c4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_emar_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "ba5e26fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "96cec265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>021009W</th>\n",
       "      <th>02100A8</th>\n",
       "      <th>02100A9</th>\n",
       "      <th>02100Z9</th>\n",
       "      <th>02110Z3</th>\n",
       "      <th>02H633Z</th>\n",
       "      <th>02HV33Z</th>\n",
       "      <th>02RF38Z</th>\n",
       "      <th>...</th>\n",
       "      <th>B211YZZ</th>\n",
       "      <th>B214YZZ</th>\n",
       "      <th>B518YZA</th>\n",
       "      <th>B51W1ZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>BT1DYZZ</th>\n",
       "      <th>BT1FYZZ</th>\n",
       "      <th>D7021ZZ</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21322534</td>\n",
       "      <td>2155-05-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27738145</td>\n",
       "      <td>2187-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24104168</td>\n",
       "      <td>2169-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24104168</td>\n",
       "      <td>2169-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24104168</td>\n",
       "      <td>2169-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14231</th>\n",
       "      <td>27996267</td>\n",
       "      <td>2148-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14232</th>\n",
       "      <td>22429197</td>\n",
       "      <td>2148-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>22429197</td>\n",
       "      <td>2148-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14235</th>\n",
       "      <td>29366372</td>\n",
       "      <td>2167-05-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14236</th>\n",
       "      <td>27525946</td>\n",
       "      <td>2153-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10886 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  chartdate  021009W  02100A8  02100A9  02100Z9  02110Z3  \\\n",
       "0      21322534 2155-05-09        0        0        0        0        0   \n",
       "1      27738145 2187-02-11        0        0        0        0        0   \n",
       "2      24104168 2169-01-20        0        0        0        0        0   \n",
       "3      24104168 2169-01-20        0        0        0        0        0   \n",
       "4      24104168 2169-01-20        0        0        0        0        0   \n",
       "...         ...        ...      ...      ...      ...      ...      ...   \n",
       "14231  27996267 2148-01-31        0        0        0        0        0   \n",
       "14232  22429197 2148-01-01        0        0        0        0        0   \n",
       "14233  22429197 2148-01-04        0        0        0        0        0   \n",
       "14235  29366372 2167-05-05        1        1        1        0        0   \n",
       "14236  27525946 2153-04-15        0        0        0        0        0   \n",
       "\n",
       "       02H633Z  02HV33Z  02RF38Z  ...  B211YZZ  B214YZZ  B518YZA  B51W1ZZ  \\\n",
       "0            0        0        0  ...        0        0        0        0   \n",
       "1            0        0        0  ...        0        0        0        0   \n",
       "2            0        0        0  ...        0        0        0        0   \n",
       "3            0        0        0  ...        0        0        0        0   \n",
       "4            0        0        0  ...        0        0        0        0   \n",
       "...        ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "14231        0        0        0  ...        0        0        0        0   \n",
       "14232        0        0        0  ...        0        0        0        0   \n",
       "14233        0        0        0  ...        0        0        0        0   \n",
       "14235        0        0        0  ...        0        0        0        0   \n",
       "14236        0        0        0  ...        0        0        0        0   \n",
       "\n",
       "       B543ZZ3  B548ZZA  BT1DYZZ  BT1FYZZ  D7021ZZ  DW021ZZ  \n",
       "0            0        0        0        0        0        0  \n",
       "1            0        0        0        0        0        0  \n",
       "2            0        0        0        0        0        0  \n",
       "3            0        0        0        0        0        0  \n",
       "4            0        0        0        0        0        0  \n",
       "...        ...      ...      ...      ...      ...      ...  \n",
       "14231        0        0        0        0        0        0  \n",
       "14232        0        0        0        0        0        0  \n",
       "14233        0        0        0        0        0        0  \n",
       "14235        0        0        0        0        0        0  \n",
       "14236        0        0        0        0        0        0  \n",
       "\n",
       "[10886 rows x 143 columns]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "13e87fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_evaluation_target = df_emar_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "0d738a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_emar_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "# Keep only the columns in df1 that are also in df2\n",
    "df_emar_evaluation_target = df_emar_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "4e2ff6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the file path\n",
    "# file_path = os.path.join(folder_name, 'df_emar_evaluation_target.csv')\n",
    "\n",
    "# # Save the DataFrame to a CSV file in the specified folder\n",
    "# df_emar_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "40de7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_emar_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_emar_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "bbfd2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_emar_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_emar_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd0749",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "17c04456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_icustays_training.drop(columns=['hadm_id','icd_code'])\n",
    "# # target = pd.DataFrame(df_icustays_training['icd_code'])\n",
    "# target = codes\n",
    "\n",
    "data = df_emar_training.drop(columns=['hadm_id','charttime'])\n",
    "\n",
    "# target = df_icustays['icd_code']\n",
    "target = target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "a63766e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "data['delay']= data['delay'].astype(str)\n",
    "data['delay']= data['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee99e3",
   "metadata": {},
   "source": [
    "#### Multi output logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "47e43bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 573)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "3ff04f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 141)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "282b8908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_emar = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_emar.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e2411866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_emar.joblib']"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_emar.joblib')\n",
    "dump(logistic_clf_emar, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3662ee",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3497bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_emar_training.drop(columns=['hadm_id','charttime','icd_code'])\n",
    "# target = pd.DataFrame(df_emar_training['icd_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb8ac74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['delay']= data['delay'].astype(str)\n",
    "# data['delay']= data['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83dee016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', penalty=None,\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initialize and fit\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_emar = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
    "\n",
    "# logistic_clf_emar.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f14652",
   "metadata": {},
   "source": [
    "### microbiologyevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "0995c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/microbiologyevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_microbio = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad84d43",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "37d6ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio = df_microbio[df_microbio['hadm_id'].isin(df_procedures['hadm_id'])]\n",
    "\n",
    "# For each sample, get the rows from df_procedures that have the same hadm_id\n",
    "# Go through this list and if the event time is between the in and out transfer time, assign it the same icd_code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "62891ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_microbio['charttime'] = pd.to_datetime(df_microbio['charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "eb0e9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_microbio.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['charttime']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "8492c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "81dabc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make days_since_admission using charttime \n",
    "\n",
    "# Convert to datetime\n",
    "df_microbio['charttime'] = pd.to_datetime(df_microbio['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_microbio = df_microbio.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_microbio['days_since_admission'] = df_microbio['charttime'] - df_microbio['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_microbio['days_since_admission'] = df_microbio['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_microbio = df_microbio.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "2b94f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add storetime - charttime feature (call it delay)\n",
    "\n",
    "# Convert to datetime\n",
    "df_microbio['storetime'] = pd.to_datetime(df_microbio['storetime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_microbio['delay'] = df_microbio['storetime'] - df_microbio['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_microbio['delay'] = df_microbio['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c8bc9",
   "metadata": {},
   "source": [
    "Drop: microevent_id, subject_id, chartdate, charttime, test_seq, storedate, storetime, test_name and org_itemid (since info in name), quantity, ab_name, comments, micro_specimen_id (unique identifier for sample as some measurements are made on the same sample)\n",
    "Keep but categorical: order_provider_id, spec_type_desc, dilution_text, dilution_comparison\n",
    "Impute null with 0: order_provider_id, org_itemid, isolate_num, ab_itemid, dilution_value\n",
    "Impute with N/A and then one hot encode: interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "f3b970ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "# spec_itemid , test_itemid\n",
    "df_microbio = df_microbio.drop(columns=['microevent_id','subject_id','chartdate','charttime','test_seq','storedate',\n",
    "                                       'storetime','quantity','comments','ab_itemid',\n",
    "                                       'spec_itemid','test_itemid','org_itemid','micro_specimen_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "24d5d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute null with 0: order_provider_id, org_itemid, isolate_num, ab_itemid, dilution_value\n",
    "df_microbio['order_provider_id'] = df_microbio['order_provider_id'].fillna(0)\n",
    "df_microbio['isolate_num'] = df_microbio['isolate_num'].fillna(0)\n",
    "df_microbio['dilution_value'] = df_microbio['dilution_value'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "bdebc4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and then one hot encode: interpretation\n",
    "# encode test_name, ab_name\n",
    "\n",
    "df_microbio['interpretation'] = df_microbio['interpretation'].fillna('N/A')\n",
    "df_microbio['test_name'] = df_microbio['test_name'].fillna('N/A')\n",
    "df_microbio['ab_name'] = df_microbio['ab_name'].fillna('N/A')\n",
    "df_microbio['org_name'] = df_microbio['org_name'].fillna('None')\n",
    "df_microbio = pd.get_dummies(df_microbio, columns=['org_name','interpretation','ab_name','test_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "6d6482ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep but categorical: order_provider_id, spec_type_desc, dilution_text, dilution_comparison\n",
    "df_microbio = pd.get_dummies(df_microbio, columns=['order_provider_id','spec_type_desc','dilution_text',\n",
    "                                                  'dilution_comparison'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "0b9833ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio = df_microbio.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "de3561df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "\n",
    "df_microbio_training = df_microbio[~df_microbio['hadm_id'].isin(evaluation_admissions)]\n",
    "df_microbio_evaluation = df_microbio[df_microbio['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "8b65daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio_training_target = codes.loc[df_microbio_training.index]\n",
    "df_microbio_evaluation_target = codes.loc[df_microbio_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "b1b0631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_microbio_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "b32681df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "04adac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio_evaluation_target = df_microbio_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "b5419580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_microbio_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "# Keep only the columns in df1 that are also in df2\n",
    "df_microbio_evaluation_target = df_microbio_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "0ad0bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_microbio_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_microbio_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "f3a01d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_microbio_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_microbio_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7044596",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "6af22162",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_microbio_training.drop(columns=['hadm_id'])\n",
    "target = df_microbio_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "00d1ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "data['delay']= data['delay'].astype(str)\n",
    "data['delay']= data['delay'].apply(convert_to_days)\n",
    "data['days_since_admission'] = data['days_since_admission'].astype(str)\n",
    "data['days_since_admission'] = data['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae161b",
   "metadata": {},
   "source": [
    "#### Multi output logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "6dcfc4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 191)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "54394e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 127)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "57ce6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34f486eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(fit_intercept=False, multi_class='multinomial', penalty='l1',\n",
       "                   random_state=42, solver='saga')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initialize and fit\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_microbio = LogisticRegression(random_state = 42, fit_intercept=False,max_iter=100, multi_class='multinomial', \n",
    "#                                        solver='saga', penalty='l1')\n",
    "\n",
    "# logistic_clf_microbio.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "11a8178b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=&#x27;l1&#x27;,\n",
       "                                                   random_state=42,\n",
       "                                                   solver=&#x27;saga&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=&#x27;l1&#x27;,\n",
       "                                                   random_state=42,\n",
       "                                                   solver=&#x27;saga&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty='l1',\n",
       "                                                   random_state=42,\n",
       "                                                   solver='saga'))"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, fit_intercept=False,max_iter=100, multi_class='multinomial', \n",
    "                                       solver='saga', penalty='l1')\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_microbio = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_microbio.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "616379c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_microbio.joblib']"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners' \n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_microbio.joblib')\n",
    "dump(logistic_clf_microbio, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402355e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379b92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9aece3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f112e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd3588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01b297cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_microbio['icd_code'] = float('nan')\n",
    "# for index, row in df_microbio.iterrows():\n",
    "#     # Filter target df based on 'hadm_id'\n",
    "#     df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "\n",
    "#     datetime_value = row['charttime']\n",
    "    \n",
    "#     # Filter out datetime values in the second dataframe that are later than the datetime value in the first dataframe\n",
    "#     filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "#     if not filtered_procedures.empty:\n",
    "\n",
    "#         # Find the closest datetime value in the filtered second dataframe\n",
    "#         closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "#         # Get the id of the sample with the closest datetime value\n",
    "#         closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]['icd_code']\n",
    "#         code = pd.array(closest_id)[0]\n",
    "\n",
    "#         # Assign the id to the current row in the first dataframe\n",
    "#         df_microbio.at[index, 'icd_code'] = str(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b5b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebbaee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26573b64",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396d169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22fe2cbf",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "4e539eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_microbio_training.drop(columns=['hadm_id'])\n",
    "target = df_microbio_training_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b4b90",
   "metadata": {},
   "source": [
    "#### Multi output logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "b8417868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 191)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "72148342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 127)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "276ed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "6fac7e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, fit_intercept=False,max_iter=100, multi_class='multinomial', \n",
    "                                       solver='saga', penalty='l1')\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_microbio = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_microbio.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce84f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3c1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978fd876",
   "metadata": {},
   "source": [
    "### pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "a4f49daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/pharmacy.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_pharmacy = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11373ae0",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "4a3c7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharmacy = df_pharmacy[df_pharmacy['hadm_id'].isin(df_procedures['hadm_id'])]\n",
    "\n",
    "# For each sample, get the rows from df_procedures that have the same hadm_id\n",
    "# Go through this list and if the event time is between the in and out transfer time, assign it the same icd_code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "7e42abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoptime-starttime for a duration feature\n",
    "\n",
    "# Convert to datetime\n",
    "df_pharmacy['stoptime'] = pd.to_datetime(df_pharmacy['stoptime'], format='%Y/%m/%d %H:%M')\n",
    "df_pharmacy['starttime'] = pd.to_datetime(df_pharmacy['starttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "\n",
    "df_pharmacy['medication_duration'] = df_pharmacy['stoptime'] - df_pharmacy['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_pharmacy['medication_duration'] = df_pharmacy['medication_duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "c6f32d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiedtime - entertime for verification_delay feature \n",
    "\n",
    "# Convert to datetime\n",
    "df_pharmacy['verifiedtime'] = pd.to_datetime(df_pharmacy['verifiedtime'], format='%Y/%m/%d %H:%M')\n",
    "df_pharmacy['entertime'] = pd.to_datetime(df_pharmacy['entertime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_pharmacy['verification_delay'] = df_pharmacy['verifiedtime'] - df_pharmacy['entertime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_pharmacy['verification_delay'] = df_pharmacy['verification_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "653ae68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_value = [0] \n",
    "\n",
    "# Fill null values with the list\n",
    "df_pharmacy['disp_sched'] = df_pharmacy['disp_sched'].fillna(pd.Series([fill_value]*len(df_pharmacy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "901174da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categories to strings\n",
    "df_pharmacy['disp_sched'] = df_pharmacy['disp_sched'].astype(str)\n",
    "df_pharmacy['disp_sched'] = df_pharmacy['disp_sched'].apply(lambda x: [str(item) for item in x])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "encoded_feature = pd.DataFrame(mlb.fit_transform(df_pharmacy['disp_sched']),\n",
    "                               columns=mlb.classes_,\n",
    "                               index=df_pharmacy.index)\n",
    "\n",
    "df_pharmacy = pd.concat([df_pharmacy, encoded_feature], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "7fd92b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_pharmacy['entertime'] = pd.to_datetime(df_pharmacy['entertime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "e3318c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_pharmacy.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['entertime']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "13974320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharmacy = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649daaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "13ac695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pharmacy['icd_code'] = float('nan')\n",
    "# for index, row in df_pharmacy.iterrows():\n",
    "#     # Filter target df based on 'hadm_id'\n",
    "#     df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "\n",
    "#     datetime_value = row['entertime']\n",
    "    \n",
    "#     # Filter out datetime values in the second dataframe that are later than the datetime value in the first dataframe\n",
    "#     filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "#     if not filtered_procedures.empty:\n",
    "\n",
    "#         # Find the closest datetime value in the filtered second dataframe\n",
    "#         closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "#         # Get the id of the sample with the closest datetime value\n",
    "#         closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]['icd_code']\n",
    "#         code = pd.array(closest_id)[0]\n",
    "\n",
    "#         # Assign the id to the current row in the first dataframe\n",
    "#         df_pharmacy.at[index, 'icd_code'] = str(code)\n",
    "\n",
    "# df_pharmacy.dropna(subset=['icd_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "b1227d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>pharmacy_id</th>\n",
       "      <th>poe_id</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>medication</th>\n",
       "      <th>proc_type</th>\n",
       "      <th>status</th>\n",
       "      <th>entertime</th>\n",
       "      <th>...</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>[</th>\n",
       "      <th>]</th>\n",
       "      <th>a</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10027602</td>\n",
       "      <td>28166872</td>\n",
       "      <td>24340150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2201-10-30 12:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Midazolam</td>\n",
       "      <td>Miscellaneous Charges</td>\n",
       "      <td>Inactive (Due to a change order)</td>\n",
       "      <td>2201-10-30 12:32:11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027602</td>\n",
       "      <td>28166872</td>\n",
       "      <td>14435820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2201-10-30 12:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Midazolam</td>\n",
       "      <td>Miscellaneous Charges</td>\n",
       "      <td>Inactive (Due to a change order)</td>\n",
       "      <td>2201-10-30 12:54:34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10027602</td>\n",
       "      <td>28166872</td>\n",
       "      <td>40720238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2201-10-30 12:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Fentanyl Citrate</td>\n",
       "      <td>Miscellaneous Charges</td>\n",
       "      <td>Inactive (Due to a change order)</td>\n",
       "      <td>2201-10-30 12:32:11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10027602</td>\n",
       "      <td>28166872</td>\n",
       "      <td>27168639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2201-10-30 12:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Fentanyl Citrate</td>\n",
       "      <td>Miscellaneous Charges</td>\n",
       "      <td>Inactive (Due to a change order)</td>\n",
       "      <td>2201-10-30 12:54:34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10027602</td>\n",
       "      <td>28166872</td>\n",
       "      <td>62845687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2201-10-31 12:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Lorazepam</td>\n",
       "      <td>Miscellaneous Charges</td>\n",
       "      <td>Inactive (Due to a change order)</td>\n",
       "      <td>2201-10-31 12:02:42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6887</th>\n",
       "      <td>10014354</td>\n",
       "      <td>22508257</td>\n",
       "      <td>86519836</td>\n",
       "      <td>10014354-956</td>\n",
       "      <td>2148-05-15 10:00:00</td>\n",
       "      <td>2148-05-15 09:00:00</td>\n",
       "      <td>MoviPrep</td>\n",
       "      <td>Unit Dose</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>2148-05-15 09:11:01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>10014354</td>\n",
       "      <td>22508257</td>\n",
       "      <td>1794302</td>\n",
       "      <td>10014354-984</td>\n",
       "      <td>2148-05-16 13:00:00</td>\n",
       "      <td>2148-05-17 13:00:00</td>\n",
       "      <td>MoviPrep</td>\n",
       "      <td>Unit Dose</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>2148-05-16 12:05:01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>10014354</td>\n",
       "      <td>22508257</td>\n",
       "      <td>33207382</td>\n",
       "      <td>10014354-992</td>\n",
       "      <td>2148-05-17 09:00:00</td>\n",
       "      <td>2148-05-18 05:00:00</td>\n",
       "      <td>MoviPrep</td>\n",
       "      <td>Unit Dose</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>2148-05-17 08:56:51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>10014354</td>\n",
       "      <td>22508257</td>\n",
       "      <td>12690116</td>\n",
       "      <td>10014354-1000</td>\n",
       "      <td>2148-05-17 21:00:00</td>\n",
       "      <td>2148-05-18 05:00:00</td>\n",
       "      <td>MoviPrep</td>\n",
       "      <td>Unit Dose</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>2148-05-17 21:17:45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6891</th>\n",
       "      <td>10014354</td>\n",
       "      <td>22508257</td>\n",
       "      <td>99002619</td>\n",
       "      <td>10014354-1001</td>\n",
       "      <td>2148-05-18 06:00:00</td>\n",
       "      <td>2148-05-18 08:00:00</td>\n",
       "      <td>MoviPrep</td>\n",
       "      <td>Unit Dose</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>2148-05-18 05:31:43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6892 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject_id   hadm_id  pharmacy_id         poe_id           starttime  \\\n",
       "0       10027602  28166872     24340150            NaN 2201-10-30 12:00:00   \n",
       "1       10027602  28166872     14435820            NaN 2201-10-30 12:00:00   \n",
       "2       10027602  28166872     40720238            NaN 2201-10-30 12:00:00   \n",
       "3       10027602  28166872     27168639            NaN 2201-10-30 12:00:00   \n",
       "4       10027602  28166872     62845687            NaN 2201-10-31 12:00:00   \n",
       "...          ...       ...          ...            ...                 ...   \n",
       "6887    10014354  22508257     86519836   10014354-956 2148-05-15 10:00:00   \n",
       "6888    10014354  22508257      1794302   10014354-984 2148-05-16 13:00:00   \n",
       "6889    10014354  22508257     33207382   10014354-992 2148-05-17 09:00:00   \n",
       "6890    10014354  22508257     12690116  10014354-1000 2148-05-17 21:00:00   \n",
       "6891    10014354  22508257     99002619  10014354-1001 2148-05-18 06:00:00   \n",
       "\n",
       "                stoptime        medication              proc_type  \\\n",
       "0                    NaT         Midazolam  Miscellaneous Charges   \n",
       "1                    NaT         Midazolam  Miscellaneous Charges   \n",
       "2                    NaT  Fentanyl Citrate  Miscellaneous Charges   \n",
       "3                    NaT  Fentanyl Citrate  Miscellaneous Charges   \n",
       "4                    NaT         Lorazepam  Miscellaneous Charges   \n",
       "...                  ...               ...                    ...   \n",
       "6887 2148-05-15 09:00:00          MoviPrep              Unit Dose   \n",
       "6888 2148-05-17 13:00:00          MoviPrep              Unit Dose   \n",
       "6889 2148-05-18 05:00:00          MoviPrep              Unit Dose   \n",
       "6890 2148-05-18 05:00:00          MoviPrep              Unit Dose   \n",
       "6891 2148-05-18 08:00:00          MoviPrep              Unit Dose   \n",
       "\n",
       "                                status           entertime  ...  4  5  6  7  \\\n",
       "0     Inactive (Due to a change order) 2201-10-30 12:32:11  ...  0  0  0  0   \n",
       "1     Inactive (Due to a change order) 2201-10-30 12:54:34  ...  0  0  0  0   \n",
       "2     Inactive (Due to a change order) 2201-10-30 12:32:11  ...  0  0  0  0   \n",
       "3     Inactive (Due to a change order) 2201-10-30 12:54:34  ...  0  0  0  0   \n",
       "4     Inactive (Due to a change order) 2201-10-31 12:02:42  ...  0  0  0  0   \n",
       "...                                ...                 ...  ... .. .. .. ..   \n",
       "6887                      Discontinued 2148-05-15 09:11:01  ...  0  0  0  0   \n",
       "6888                      Discontinued 2148-05-16 12:05:01  ...  1  0  0  0   \n",
       "6889                      Discontinued 2148-05-17 08:56:51  ...  0  0  0  0   \n",
       "6890                      Discontinued 2148-05-17 21:17:45  ...  0  0  0  0   \n",
       "6891                      Discontinued 2148-05-18 05:31:43  ...  0  0  1  1   \n",
       "\n",
       "      8  9  [  ]  a  n  \n",
       "0     0  0  1  1  0  0  \n",
       "1     0  0  1  1  0  0  \n",
       "2     0  0  1  1  0  0  \n",
       "3     0  0  1  1  0  0  \n",
       "4     0  0  1  1  0  0  \n",
       "...  .. .. .. .. .. ..  \n",
       "6887  0  0  0  0  0  0  \n",
       "6888  0  0  0  0  0  0  \n",
       "6889  0  0  0  0  0  0  \n",
       "6890  0  0  0  0  0  0  \n",
       "6891  0  0  0  0  0  0  \n",
       "\n",
       "[6892 rows x 45 columns]"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "fb349aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_pharmacy = df_pharmacy.drop(columns=['subject_id','pharmacy_id','poe_id','starttime','stoptime','entertime',\n",
    "                                       'verifiedtime','expirationdate', 'fill_quantity','disp_sched'])\n",
    "# expiration date and fill quantity are all empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "a75e291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode: proc_type, status\n",
    "df_pharmacy = pd.get_dummies(df_pharmacy, columns=['proc_type','status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "8077420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_pharmacy['infusion_type'] = df_pharmacy['infusion_type'].fillna('N/A')\n",
    "df_pharmacy['sliding_scale'] = df_pharmacy['sliding_scale'].fillna('N/A')\n",
    "df_pharmacy['duration_interval'] = df_pharmacy['duration_interval'].fillna('N/A')\n",
    "df_pharmacy['expiration_unit'] = df_pharmacy['expiration_unit'].fillna('N/A')\n",
    "df_pharmacy['dispensation'] = df_pharmacy['dispensation'].fillna('N/A')\n",
    "df_pharmacy['medication'] = df_pharmacy['medication'].fillna('N/A')\n",
    "df_pharmacy['route'] = df_pharmacy['route'].fillna('N/A')\n",
    "df_pharmacy['frequency'] = df_pharmacy['frequency'].fillna('N/A')\n",
    "df_pharmacy = pd.get_dummies(df_pharmacy, columns=['infusion_type','sliding_scale','duration_interval','expiration_unit',\n",
    "                                                  'dispensation','medication','route','frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "6b667a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with 0: lockout_interval, doses_per_24_hrs, duration, expiration_value\n",
    "df_pharmacy['lockout_interval'] = df_pharmacy['lockout_interval'].fillna(0)\n",
    "df_pharmacy['doses_per_24_hrs'] = df_pharmacy['doses_per_24_hrs'].fillna(0)\n",
    "df_pharmacy['expiration_value'] = df_pharmacy['expiration_value'].fillna(0)\n",
    "df_pharmacy['basal_rate'] = df_pharmacy['basal_rate'].fillna(0)\n",
    "df_pharmacy['one_hr_max'] = df_pharmacy['one_hr_max'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "a54fcb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert timedeltas to floats\n",
    "def convert_timedelta_to_float(value):\n",
    "    if isinstance(value, pd.Timedelta):\n",
    "        return value.total_seconds()\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Apply the function to the column\n",
    "df_pharmacy['duration'] = df_pharmacy['duration'].apply(convert_timedelta_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6feb661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "861f0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "\n",
    "df_pharmacy_training = df_pharmacy[~df_pharmacy['hadm_id'].isin(evaluation_admissions)]\n",
    "df_pharmacy_evaluation = df_pharmacy[df_pharmacy['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "81d503bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharmacy_training_target = codes.loc[df_pharmacy_training.index]\n",
    "df_pharmacy_evaluation_target = codes.loc[df_pharmacy_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "e7933a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_pharmacy_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "1fb7e58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "242a0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharmacy_evaluation_target = df_pharmacy_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "c8b892fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_pharmacy_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "# Keep only the columns in df1 that are also in df2\n",
    "df_pharmacy_evaluation_target = df_pharmacy_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "a1a6df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_pharmacy_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_pharmacy_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "ca1ef66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_pharmacy_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_pharmacy_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bba333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "68e5c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save evaluation data for later \n",
    "# folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# # Define the file path\n",
    "# file_path = os.path.join(folder_name, 'df_pharmacy_evaluation.csv')\n",
    "\n",
    "# # Save the DataFrame to a CSV file in the specified folder\n",
    "# df_pharmacy_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565234e0",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "3ad1a5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lockout_interval</th>\n",
       "      <th>basal_rate</th>\n",
       "      <th>one_hr_max</th>\n",
       "      <th>doses_per_24_hrs</th>\n",
       "      <th>expiration_value</th>\n",
       "      <th>medication_duration</th>\n",
       "      <th>verification_delay</th>\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>frequency_QTHUR</th>\n",
       "      <th>frequency_TID</th>\n",
       "      <th>frequency_TID W/MEALS</th>\n",
       "      <th>frequency_TID:PRN</th>\n",
       "      <th>frequency_TITRATE TO</th>\n",
       "      <th>frequency_TITRATE TO RASS</th>\n",
       "      <th>frequency_X1</th>\n",
       "      <th>frequency_X1 PRN</th>\n",
       "      <th>frequency_X1:PRN</th>\n",
       "      <th>frequency_X2 PRN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>5.791667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>5.791667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5353 rows × 623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lockout_interval  basal_rate  one_hr_max  doses_per_24_hrs  \\\n",
       "0                  0.0         0.0         0.0               0.0   \n",
       "1                  0.0         0.0         0.0               0.0   \n",
       "2                  0.0         0.0         0.0               0.0   \n",
       "3                  0.0         0.0         0.0               0.0   \n",
       "4                  0.0         0.0         0.0               0.0   \n",
       "...                ...         ...         ...               ...   \n",
       "6873               0.0         0.0         0.0               0.0   \n",
       "6878               0.0         0.0         0.0               0.0   \n",
       "6879               0.0         0.0         0.0               0.0   \n",
       "6880               0.0         0.0         0.0               0.0   \n",
       "6881               0.0         0.0         0.0               0.0   \n",
       "\n",
       "      expiration_value  medication_duration  verification_delay     ,  0  ...  \\\n",
       "0                  0.0             0.000000                 0.0  0  0  1  ...   \n",
       "1                  0.0             0.000000                 0.0  0  0  1  ...   \n",
       "2                  0.0             0.000000                 0.0  0  0  1  ...   \n",
       "3                  0.0             0.000000                 0.0  0  0  1  ...   \n",
       "4                  0.0             0.000000                 0.0  0  0  1  ...   \n",
       "...                ...                  ...                 ... .. .. ..  ...   \n",
       "6873             365.0             1.875000                 0.0  0  0  0  ...   \n",
       "6878             365.0             5.791667                 0.0  0  0  0  ...   \n",
       "6879             365.0             5.791667                 0.0  0  0  0  ...   \n",
       "6880              36.0             4.916667                 0.0  0  0  0  ...   \n",
       "6881               0.0             4.250000                 0.0  0  0  0  ...   \n",
       "\n",
       "      frequency_QTHUR  frequency_TID  frequency_TID W/MEALS  \\\n",
       "0                   0              0                      0   \n",
       "1                   0              0                      0   \n",
       "2                   0              0                      0   \n",
       "3                   0              0                      0   \n",
       "4                   0              0                      0   \n",
       "...               ...            ...                    ...   \n",
       "6873                0              0                      0   \n",
       "6878                0              0                      0   \n",
       "6879                0              0                      0   \n",
       "6880                0              0                      0   \n",
       "6881                0              0                      0   \n",
       "\n",
       "      frequency_TID:PRN  frequency_TITRATE TO  frequency_TITRATE TO RASS  \\\n",
       "0                     0                     0                          0   \n",
       "1                     0                     0                          0   \n",
       "2                     0                     0                          0   \n",
       "3                     0                     0                          0   \n",
       "4                     0                     0                          0   \n",
       "...                 ...                   ...                        ...   \n",
       "6873                  0                     0                          1   \n",
       "6878                  0                     0                          1   \n",
       "6879                  0                     0                          1   \n",
       "6880                  0                     0                          1   \n",
       "6881                  0                     0                          0   \n",
       "\n",
       "      frequency_X1  frequency_X1 PRN  frequency_X1:PRN  frequency_X2 PRN  \n",
       "0                0                 0                 0                 0  \n",
       "1                0                 0                 0                 0  \n",
       "2                0                 0                 0                 0  \n",
       "3                0                 0                 0                 0  \n",
       "4                0                 0                 0                 0  \n",
       "...            ...               ...               ...               ...  \n",
       "6873             0                 0                 0                 0  \n",
       "6878             0                 0                 0                 0  \n",
       "6879             0                 0                 0                 0  \n",
       "6880             0                 0                 0                 0  \n",
       "6881             0                 0                 0                 0  \n",
       "\n",
       "[5353 rows x 623 columns]"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "c6366d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_pharmacy_training.drop(columns=['hadm_id','duration'])\n",
    "target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "549a2c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "data['medication_duration']= data['medication_duration'].astype(str)\n",
    "data['medication_duration']= data['medication_duration'].apply(convert_to_days)\n",
    "data['verification_delay'] = data['verification_delay'].astype(str)\n",
    "data['verification_delay'] = data['verification_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "8042850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize and fit\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_pharmacy = LogisticRegression(random_state = 42, fit_intercept=False, multi_class='multinomial', solver='lbfgs',\n",
    "#                           max_iter=1000)\n",
    "\n",
    "# logistic_clf_pharmacy.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "e072e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, fit_intercept=False, multi_class='multinomial', solver='lbfgs',\n",
    "                          max_iter=1000)\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_pharmacy = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_pharmacy.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "a1f13fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_pharmacy.joblib']"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners' \n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_pharmacy.joblib')\n",
    "dump(logistic_clf_pharmacy, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b247ff",
   "metadata": {},
   "source": [
    "### icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7572085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/icustays.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_icustays = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8c17c",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0b183248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icustays = df_icustays[df_icustays['hadm_id'].isin(df_procedures['hadm_id'])]\n",
    "\n",
    "# For each sample, get the rows from df_procedures that have the same hadm_id\n",
    "# Go through this list and if the event time is between the in and out transfer time, assign it the same icd_code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "2dcabb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_icustays['outtime'] = pd.to_datetime(df_icustays['outtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "29be6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_icustays.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['outtime']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "b5bfcf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_icustays['icd_code'] = float('nan')\n",
    "# for index, row in df_icustays.iterrows():\n",
    "#     # Filter target df based on 'hadm_id'\n",
    "#     df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "\n",
    "#     datetime_value = row['outtime']\n",
    "    \n",
    "#     # Filter out datetime values in the second dataframe that are later than the datetime value in the first dataframe\n",
    "#     filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "#     if not filtered_procedures.empty:\n",
    "\n",
    "#         # Find the closest datetime value in the filtered second dataframe\n",
    "#         closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "#         # Get the id of the sample with the closest datetime value\n",
    "#         closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]['icd_code']\n",
    "#         code = pd.array(closest_id)[0]\n",
    "\n",
    "#         # Assign the id to the current row in the first dataframe\n",
    "#         df_icustays.at[index, 'icd_code'] = str(code)\n",
    "\n",
    "# df_icustays.dropna(subset=['icd_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e848af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icustays = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "dbbb7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a feature called days_since_admission using intime-admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_icustays['intime'] = pd.to_datetime(df_icustays['intime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_icustays = df_icustays.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_icustays['days_since_admission'] = df_icustays['intime'] - df_icustays['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_icustays['days_since_admission'] = df_icustays['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_icustays = df_icustays.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "297a3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_icustays = df_icustays.drop(columns=['subject_id','stay_id','intime','outtime'])\n",
    "\n",
    "# Rename los to icu_los\n",
    "df_icustays = df_icustays.rename(columns={'los': 'icu_los'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "a4b6a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "df_icustays = pd.get_dummies(df_icustays, columns=['first_careunit','last_careunit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "28a61220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "\n",
    "df_icustays_training = df_icustays[~df_icustays['hadm_id'].isin(evaluation_admissions)]\n",
    "df_icustays_evaluation = df_icustays[df_icustays['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "3f83fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  4,  5,  6,  7,  9, 10, 12, 13, 15, 16, 17, 18, 19, 20,\n",
       "            21, 22, 23, 25, 26, 27, 28, 29, 30, 31],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_icustays_training.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "fc9b21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icustays_training_target = codes.loc[df_icustays_training.index]\n",
    "df_icustays_evaluation_target = codes.loc[df_icustays_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "22fadcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>0039</th>\n",
       "      <th>0040</th>\n",
       "      <th>0041</th>\n",
       "      <th>0045</th>\n",
       "      <th>0051</th>\n",
       "      <th>0066</th>\n",
       "      <th>0069</th>\n",
       "      <th>0091</th>\n",
       "      <th>...</th>\n",
       "      <th>B41GYZZ</th>\n",
       "      <th>B518YZA</th>\n",
       "      <th>B51W1ZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>B54BZZA</th>\n",
       "      <th>BT1DYZZ</th>\n",
       "      <th>BT1FYZZ</th>\n",
       "      <th>D7021ZZ</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28829452</td>\n",
       "      <td>2113-09-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25085565</td>\n",
       "      <td>2186-09-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27660781</td>\n",
       "      <td>2117-03-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29279905</td>\n",
       "      <td>2153-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hadm_id  chartdate  0039  0040  0041  0045  0051  0066  0069  0091  ...  \\\n",
       "3   28998349 2116-12-27     0     0     0     0     0     0     0     0  ...   \n",
       "8   28829452 2113-09-16     0     0     0     0     0     0     0     0  ...   \n",
       "11  25085565 2186-09-18     0     0     0     0     0     0     0     0  ...   \n",
       "14  27660781 2117-03-12     0     0     0     0     0     0     0     0  ...   \n",
       "24  29279905 2153-04-04     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "    B41GYZZ  B518YZA  B51W1ZZ  B543ZZ3  B548ZZA  B54BZZA  BT1DYZZ  BT1FYZZ  \\\n",
       "3         0        0        0        0        0        0        0        0   \n",
       "8         0        0        0        0        0        0        0        0   \n",
       "11        0        0        0        0        0        0        0        0   \n",
       "14        0        0        0        0        0        0        0        0   \n",
       "24        0        0        0        0        0        0        0        0   \n",
       "\n",
       "    D7021ZZ  DW021ZZ  \n",
       "3         0        0  \n",
       "8         0        0  \n",
       "11        0        0  \n",
       "14        0        0  \n",
       "24        0        0  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_icustays_evaluation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1fb0cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_icustays_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_icustays_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a473d74",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "50bd6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_icustays_training.drop(columns=['hadm_id','icd_code'])\n",
    "# # target = pd.DataFrame(df_icustays_training['icd_code'])\n",
    "# target = codes\n",
    "\n",
    "data = df_icustays_training.drop(columns=['hadm_id'])\n",
    "\n",
    "# target = df_icustays['icd_code']\n",
    "target = df_icustays_training_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fabf3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "data['days_since_admission']= data['days_since_admission'].astype(str)\n",
    "data['days_since_admission']= data['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c557d8",
   "metadata": {},
   "source": [
    "#### Multi output logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "aaeb811f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0039</th>\n",
       "      <th>0040</th>\n",
       "      <th>0041</th>\n",
       "      <th>0045</th>\n",
       "      <th>0051</th>\n",
       "      <th>0066</th>\n",
       "      <th>0069</th>\n",
       "      <th>0091</th>\n",
       "      <th>0096</th>\n",
       "      <th>009600Z</th>\n",
       "      <th>...</th>\n",
       "      <th>B41GYZZ</th>\n",
       "      <th>B518YZA</th>\n",
       "      <th>B51W1ZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>B54BZZA</th>\n",
       "      <th>BT1DYZZ</th>\n",
       "      <th>BT1FYZZ</th>\n",
       "      <th>D7021ZZ</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0039  0040  0041  0045  0051  0066  0069  0091  0096  009600Z  ...  \\\n",
       "0      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "1      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "2      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "4      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "5      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "6      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "7      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "9      0     0     0     0     0     0     0     0     0        0  ...   \n",
       "10     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "12     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "13     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "15     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "16     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "17     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "18     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "19     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "20     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "21     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "22     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "23     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "25     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "26     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "27     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "28     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "29     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "30     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "31     0     0     0     0     0     0     0     0     0        0  ...   \n",
       "\n",
       "    B41GYZZ  B518YZA  B51W1ZZ  B543ZZ3  B548ZZA  B54BZZA  BT1DYZZ  BT1FYZZ  \\\n",
       "0         0        0        0        0        0        0        0        0   \n",
       "1         0        0        0        0        0        0        0        0   \n",
       "2         0        0        0        0        0        0        0        0   \n",
       "4         0        0        0        0        0        0        0        0   \n",
       "5         0        0        0        0        0        0        0        0   \n",
       "6         0        0        0        0        0        0        0        0   \n",
       "7         0        0        0        0        0        0        0        0   \n",
       "9         0        0        0        0        0        0        0        0   \n",
       "10        0        0        0        0        0        0        0        0   \n",
       "12        0        0        0        0        0        0        0        0   \n",
       "13        0        0        0        0        0        0        0        0   \n",
       "15        0        0        0        0        0        0        0        0   \n",
       "16        0        0        0        0        0        0        0        0   \n",
       "17        0        0        0        0        0        0        0        0   \n",
       "18        0        0        0        0        0        0        0        0   \n",
       "19        0        0        0        0        0        0        0        0   \n",
       "20        0        0        0        0        0        0        0        0   \n",
       "21        0        0        0        0        0        0        0        0   \n",
       "22        0        0        0        0        0        0        0        0   \n",
       "23        0        0        0        0        0        0        0        0   \n",
       "25        0        0        0        0        0        0        0        0   \n",
       "26        0        0        0        0        0        0        0        0   \n",
       "27        0        0        0        0        0        0        0        0   \n",
       "28        0        0        0        0        0        0        0        0   \n",
       "29        0        0        0        0        0        0        0        0   \n",
       "30        0        0        0        0        0        0        0        0   \n",
       "31        0        0        0        0        0        0        0        0   \n",
       "\n",
       "    D7021ZZ  DW021ZZ  \n",
       "0         0        0  \n",
       "1         0        0  \n",
       "2         0        0  \n",
       "4         0        0  \n",
       "5         0        0  \n",
       "6         0        0  \n",
       "7         0        0  \n",
       "9         0        0  \n",
       "10        0        0  \n",
       "12        0        0  \n",
       "13        0        0  \n",
       "15        0        0  \n",
       "16        0        0  \n",
       "17        0        0  \n",
       "18        0        0  \n",
       "19        0        0  \n",
       "20        0        0  \n",
       "21        0        0  \n",
       "22        0        0  \n",
       "23        0        0  \n",
       "25        0        0  \n",
       "26        0        0  \n",
       "27        0        0  \n",
       "28        0        0  \n",
       "29        0        0  \n",
       "30        0        0  \n",
       "31        0        0  \n",
       "\n",
       "[27 rows x 352 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "b06cb037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    02H633Z  0BH17EZ  0D9630Z  0D963ZX  0DH63UZ  0DH98UZ  0DJ08ZZ  0JDM0ZZ  \\\n",
      "0         0        0        0        0        1        0        0        0   \n",
      "1         0        0        0        0        0        0        0        0   \n",
      "2         0        0        0        0        0        0        0        0   \n",
      "4         0        0        0        0        0        0        0        0   \n",
      "5         0        0        0        0        0        0        0        0   \n",
      "6         0        0        0        0        0        0        0        0   \n",
      "7         0        0        0        0        0        0        0        0   \n",
      "9         0        0        0        0        0        0        0        0   \n",
      "10        0        0        0        0        0        0        0        0   \n",
      "12        0        0        1        1        0        1        0        0   \n",
      "13        0        0        0        0        0        0        0        0   \n",
      "15        1        0        0        0        0        0        0        0   \n",
      "16        0        0        0        0        0        0        0        0   \n",
      "17        0        0        0        0        0        0        0        0   \n",
      "18        0        0        0        0        0        0        0        1   \n",
      "19        0        0        0        0        0        0        0        0   \n",
      "20        0        0        0        0        0        0        0        0   \n",
      "21        0        0        0        0        0        0        0        0   \n",
      "22        0        0        0        0        0        0        0        0   \n",
      "23        0        0        0        0        0        0        0        0   \n",
      "25        0        0        0        0        0        0        1        0   \n",
      "26        0        0        0        0        0        0        0        0   \n",
      "27        0        0        0        0        0        0        0        0   \n",
      "28        0        0        0        0        0        0        0        0   \n",
      "29        0        0        0        0        0        0        0        0   \n",
      "30        0        1        0        0        0        0        0        0   \n",
      "31        0        0        0        0        0        0        0        0   \n",
      "\n",
      "    0JDP0ZZ  0JH63XZ  ...  4523  5491  5A1945Z  5A1D70Z  8605  8628  9427  \\\n",
      "0         0        0  ...     0     0        0        0     0     0     0   \n",
      "1         0        0  ...     0     0        0        0     0     1     0   \n",
      "2         0        0  ...     0     0        0        0     0     0     0   \n",
      "4         0        0  ...     0     0        0        0     0     0     0   \n",
      "5         0        0  ...     0     0        0        0     0     0     0   \n",
      "6         0        0  ...     0     0        0        0     0     0     0   \n",
      "7         0        0  ...     0     1        0        0     0     0     0   \n",
      "9         0        0  ...     0     0        0        0     0     0     1   \n",
      "10        0        0  ...     0     0        0        0     0     0     0   \n",
      "12        0        0  ...     0     0        0        0     0     0     0   \n",
      "13        0        0  ...     0     0        0        0     0     0     0   \n",
      "15        0        1  ...     0     0        0        1     0     0     0   \n",
      "16        0        0  ...     0     0        0        1     0     0     0   \n",
      "17        0        0  ...     0     0        0        0     0     0     0   \n",
      "18        1        0  ...     0     0        0        0     0     0     0   \n",
      "19        0        0  ...     0     0        0        0     0     0     0   \n",
      "20        0        0  ...     0     0        0        0     0     0     0   \n",
      "21        0        0  ...     0     0        0        0     0     0     0   \n",
      "22        0        0  ...     0     0        0        0     0     0     0   \n",
      "23        0        0  ...     0     0        0        0     1     0     0   \n",
      "25        0        0  ...     0     0        0        0     0     0     0   \n",
      "26        0        0  ...     0     0        0        0     0     0     0   \n",
      "27        0        0  ...     1     0        0        0     0     0     0   \n",
      "28        0        0  ...     0     0        0        0     0     0     0   \n",
      "29        0        0  ...     0     0        0        0     0     0     0   \n",
      "30        0        0  ...     0     0        1        0     0     0     0   \n",
      "31        0        0  ...     0     0        0        0     0     0     0   \n",
      "\n",
      "    9604  966  9671  \n",
      "0      0    0     0  \n",
      "1      0    0     0  \n",
      "2      0    0     0  \n",
      "4      0    0     0  \n",
      "5      0    0     0  \n",
      "6      1    0     1  \n",
      "7      0    0     0  \n",
      "9      0    0     0  \n",
      "10     1    0     1  \n",
      "12     0    0     0  \n",
      "13     0    0     0  \n",
      "15     0    0     0  \n",
      "16     0    0     0  \n",
      "17     0    0     0  \n",
      "18     0    0     0  \n",
      "19     0    0     0  \n",
      "20     0    1     0  \n",
      "21     0    0     0  \n",
      "22     0    0     0  \n",
      "23     0    0     0  \n",
      "25     0    0     0  \n",
      "26     0    0     0  \n",
      "27     0    0     0  \n",
      "28     0    1     0  \n",
      "29     0    0     0  \n",
      "30     0    0     0  \n",
      "31     0    0     0  \n",
      "\n",
      "[27 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]\n",
    "\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "403b9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icustays_evaluation_target = df_icustays_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "6c17dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_icustays_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "# Keep only the columns in df1 that are also in df2\n",
    "df_icustays_evaluation_target = df_icustays_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "252c1325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02H633Z</th>\n",
       "      <th>0BH17EZ</th>\n",
       "      <th>0D9630Z</th>\n",
       "      <th>0D963ZX</th>\n",
       "      <th>0DH63UZ</th>\n",
       "      <th>0DH98UZ</th>\n",
       "      <th>0DJ08ZZ</th>\n",
       "      <th>0JDM0ZZ</th>\n",
       "      <th>0JDP0ZZ</th>\n",
       "      <th>0JH63XZ</th>\n",
       "      <th>...</th>\n",
       "      <th>4523</th>\n",
       "      <th>5491</th>\n",
       "      <th>5A1945Z</th>\n",
       "      <th>5A1D70Z</th>\n",
       "      <th>8605</th>\n",
       "      <th>8628</th>\n",
       "      <th>9427</th>\n",
       "      <th>9604</th>\n",
       "      <th>966</th>\n",
       "      <th>9671</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    02H633Z  0BH17EZ  0D9630Z  0D963ZX  0DH63UZ  0DH98UZ  0DJ08ZZ  0JDM0ZZ  \\\n",
       "3         0        0        0        0        0        0        0        0   \n",
       "8         0        0        0        0        0        0        0        0   \n",
       "11        0        0        0        0        0        0        0        0   \n",
       "14        0        0        0        0        0        0        0        0   \n",
       "24        0        0        0        0        0        0        0        0   \n",
       "\n",
       "    0JDP0ZZ  0JH63XZ  ...  4523  5491  5A1945Z  5A1D70Z  8605  8628  9427  \\\n",
       "3         0        0  ...     0     0        0        0     0     0     0   \n",
       "8         0        0  ...     0     0        0        0     0     0     0   \n",
       "11        0        0  ...     0     0        0        0     0     0     0   \n",
       "14        0        0  ...     0     1        0        0     0     0     0   \n",
       "24        0        0  ...     0     0        0        0     0     0     0   \n",
       "\n",
       "    9604  966  9671  \n",
       "3      0    0     0  \n",
       "8      0    0     0  \n",
       "11     0    0     0  \n",
       "14     0    0     0  \n",
       "24     0    0     0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_icustays_evaluation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "59641a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_icustays_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_icustays_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e588a733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 14)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "63033d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 30)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "abdf8a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "462a65a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "                            fit_intercept=False, solver='lbfgs', max_iter=100)\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_icustays = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_icustays.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "168f3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize and fit\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_icustays = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "#                            fit_intercept=False, solver='lbfgs', max_iter=100)\n",
    "\n",
    "# logistic_clf_icustays.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "67216a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_icustays.joblib']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners' \n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_icustays.joblib')\n",
    "dump(logistic_clf_icustays, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b2532",
   "metadata": {},
   "source": [
    "### inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "e6631681",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/inputevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_input = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0febce11",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3426b8bd",
   "metadata": {},
   "source": [
    "Drop: subject_id, starttime, endtime, storetime, orderid, linkorderid, continueinnextdept, stay_id, caregiver_id,\n",
    "totalamountuom\n",
    "Encode: amountuom, ordercategoryname, ordercomponenttypedescription, ordercategorydescription, statusdescription, itemid\n",
    "Impute with 0: rate, totalamount\n",
    "Impute with N/A and encode: rateuom, secondaryordercategoryname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "ec97da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_input[df_input['hadm_id'].isin(df_procedures['hadm_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "e6544315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_input['endtime'] = pd.to_datetime(df_input['endtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "9daf1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_input.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['endtime']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "e682d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "c58bf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a duration feature using endtime-starttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_input['endtime'] = pd.to_datetime(df_input['endtime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_input['starttime'] = pd.to_datetime(df_input['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "df_input['duration'] = df_input['endtime'] - df_input['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_input['duration'] = df_input['duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "b4b5c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a recording_delay feature using storetime-endtime\n",
    "\n",
    "# Convert to datetime\n",
    "df_input['storetime'] = pd.to_datetime(df_input['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_input['recording_delay'] = df_input['storetime'] - df_input['endtime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_input['recording_delay'] = df_input['recording_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "ad0edff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_input = df_input.drop(columns=['subject_id','stay_id','starttime','endtime','storetime','orderid','linkorderid',\n",
    "                                  'continueinnextdept','totalamountuom', 'stay_id','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "4be39a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_input['rateuom'] = df_input['rateuom'].fillna('N/A')\n",
    "df_input['secondaryordercategoryname'] = df_input['secondaryordercategoryname'].fillna('N/A')\n",
    "df_input = pd.get_dummies(df_input, columns=['rateuom','secondaryordercategoryname','amountuom','ordercategoryname',\n",
    "                                            'ordercomponenttypedescription','ordercategorydescription','statusdescription',\n",
    "                                            'itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "5f3781a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with 0\n",
    "df_input['rate'] = df_input['rate'].fillna(0)\n",
    "df_input['totalamount'] = df_input['totalamount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "605f7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_input.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "de8870de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "df_input['duration']= df_input['duration'].astype(str)\n",
    "df_input['duration']= df_input['duration'].apply(convert_to_days)\n",
    "df_input['recording_delay']= df_input['recording_delay'].astype(str)\n",
    "df_input['recording_delay']= df_input['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "1aeff7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "\n",
    "df_input_training = df_input[~df_input['hadm_id'].isin(evaluation_admissions)]\n",
    "df_input_evaluation = df_input[df_input['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "63ae8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_training_target = codes.loc[df_input_training.index]\n",
    "df_input_evaluation_target = codes.loc[df_input_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "e5c27e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_input_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "f504fabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "fc920b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_evaluation_target = df_input_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "89c64f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_input_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "# Keep only the columns in df1 that are also in df2\n",
    "df_input_evaluation_target = df_input_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "e78c5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_input_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_input_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "78f05fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_input_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_input_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c68089",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "ceedd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_input_training.drop(columns=['hadm_id','duration'])\n",
    "target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "750f455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "                                           solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_input = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_input.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "a213f87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_input.joblib']"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_input.joblib')\n",
    "dump(logistic_clf_input, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "501582c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', penalty=None,\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initialize and fit\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_input = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "#                                            solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# logistic_clf_input.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e502811f",
   "metadata": {},
   "source": [
    "### outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "3d797bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/outputevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_output = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09495e22",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "426a0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_output[df_output['hadm_id'].isin(df_procedures['hadm_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "e3a37787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_output['charttime'] = pd.to_datetime(df_output['charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "066cd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_output.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['charttime']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "1112c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "a8f9754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a days_since_admission feature using charttime-admittime \n",
    "\n",
    "# Convert to datetime\n",
    "df_output['charttime'] = pd.to_datetime(df_output['charttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_output = df_output.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "df_output['days_since_admission'] = df_output['charttime'] - df_output['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_output['days_since_admission'] = df_output['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_output = df_output.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "302e3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a recording_delay feature using storetime-charttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_output['storetime'] = pd.to_datetime(df_output['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_output['recording_delay'] = df_output['storetime'] - df_output['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_output['recording_delay'] = df_output['recording_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "e0fa1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_output = df_output.drop(columns=['subject_id','stay_id','charttime','storetime','storetime','valueuom','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "9f7c1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode\n",
    "df_output = pd.get_dummies(df_output, columns=['itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "48b7722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "\n",
    "df_output_training = df_output[~df_output['hadm_id'].isin(evaluation_admissions)]\n",
    "df_output_evaluation = df_output[df_output['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "afcbfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_training_target = codes.loc[df_output_training.index]\n",
    "df_output_evaluation_target = codes.loc[df_output_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "2582628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_output_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "198deebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "499bbfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>0039</th>\n",
       "      <th>0040</th>\n",
       "      <th>0041</th>\n",
       "      <th>0045</th>\n",
       "      <th>0051</th>\n",
       "      <th>0066</th>\n",
       "      <th>0069</th>\n",
       "      <th>0091</th>\n",
       "      <th>...</th>\n",
       "      <th>B41GYZZ</th>\n",
       "      <th>B518YZA</th>\n",
       "      <th>B51W1ZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>B54BZZA</th>\n",
       "      <th>BT1DYZZ</th>\n",
       "      <th>BT1FYZZ</th>\n",
       "      <th>D7021ZZ</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24540843</td>\n",
       "      <td>2117-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>975 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hadm_id  chartdate  0039  0040  0041  0045  0051  0066  0069  0091  \\\n",
       "1     24540843 2117-03-18     0     0     0     0     0     0     0     0   \n",
       "32    29276678 2116-03-04     0     0     0     0     0     0     0     0   \n",
       "33    29276678 2116-03-04     0     0     0     0     0     0     0     0   \n",
       "34    29276678 2116-03-02     0     0     0     0     0     0     0     0   \n",
       "35    29276678 2116-03-04     0     0     0     0     0     0     0     0   \n",
       "...        ...        ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "4719  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "4720  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "4721  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "4722  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "4723  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "\n",
       "      ...  B41GYZZ  B518YZA  B51W1ZZ  B543ZZ3  B548ZZA  B54BZZA  BT1DYZZ  \\\n",
       "1     ...        0        0        0        0        0        0        0   \n",
       "32    ...        0        0        0        0        0        0        0   \n",
       "33    ...        0        0        0        0        0        0        0   \n",
       "34    ...        0        0        0        0        0        0        0   \n",
       "35    ...        0        0        0        0        0        0        0   \n",
       "...   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "4719  ...        0        0        0        0        0        0        0   \n",
       "4720  ...        0        0        0        0        0        0        0   \n",
       "4721  ...        0        0        0        0        0        0        0   \n",
       "4722  ...        0        0        0        0        0        0        0   \n",
       "4723  ...        0        0        0        0        0        0        0   \n",
       "\n",
       "      BT1FYZZ  D7021ZZ  DW021ZZ  \n",
       "1           0        0        0  \n",
       "32          0        0        0  \n",
       "33          0        0        0  \n",
       "34          0        0        0  \n",
       "35          0        0        0  \n",
       "...       ...      ...      ...  \n",
       "4719        0        0        0  \n",
       "4720        0        0        0  \n",
       "4721        0        0        0  \n",
       "4722        0        0        0  \n",
       "4723        0        0        0  \n",
       "\n",
       "[975 rows x 354 columns]"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_evaluation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "1a3c32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_evaluation_target = df_output_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "1fcdd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_output_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "# Keep only the columns in df1 that are also in df2\n",
    "df_output_evaluation_target = df_output_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "a59356e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_output_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_output_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "fc02e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_output_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_output_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a994e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "41c371d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_output['icd_code'] = float('nan')\n",
    "# for index, row in df_output.iterrows():\n",
    "#     # Filter target df based on 'hadm_id'\n",
    "#     df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "\n",
    "#     datetime_value = row['charttime']\n",
    "    \n",
    "#     # Filter out datetime values in the second dataframe that are later than the datetime value in the first dataframe\n",
    "#     filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "#     if not filtered_procedures.empty:\n",
    "\n",
    "#         # Find the closest datetime value in the filtered second dataframe\n",
    "#         closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "#         # Get the id of the sample with the closest datetime value\n",
    "#         closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]['icd_code']\n",
    "#         code = pd.array(closest_id)[0]\n",
    "\n",
    "#         # Assign the id to the current row in the first dataframe\n",
    "#         df_output.at[index, 'icd_code'] = str(code)\n",
    "\n",
    "# df_output.dropna(subset=['icd_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c7a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "039cbea4",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "da10664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_output_training.drop(columns=['hadm_id'])\n",
    "# target = pd.DataFrame(df_output_training['icd_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "2fefc169",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['days_since_admission']= data['days_since_admission'].astype(str)\n",
    "data['days_since_admission']= data['days_since_admission'].apply(convert_to_days)\n",
    "data['recording_delay']= data['recording_delay'].astype(str)\n",
    "data['recording_delay']= data['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "e17caa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "cfc6e287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "                                           solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_output = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_output.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "78a7806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_output.joblib']"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners'\n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_output.joblib')\n",
    "dump(logistic_clf_output, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74170d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e5390200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', penalty=None,\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initialize and fit\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_output = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "#                                            solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# logistic_clf_output.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099792e",
   "metadata": {},
   "source": [
    "### procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "78dfe54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/procedureevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_procedure_events = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0385d",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69aa1a",
   "metadata": {},
   "source": [
    "Drop: subject_id, starttime, endtime, storetime, orderid, linkorderid, continueinnextdept, stay_id, caregiver_id\n",
    "Encode: valueuom, ordercategoryname, ordercategorydescription, statusdescription, itemid\n",
    "Impute with N/A and encode: location, locationcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "be7cd06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedure_events = df_procedure_events[df_procedure_events['hadm_id'].isin(df_procedures['hadm_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "51a5b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_procedure_events['endtime'] = pd.to_datetime(df_procedure_events['endtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "20d3f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_procedure_events.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['endtime']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "4ce50d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedure_events = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "34433323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a duration feature using endtime-starttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_procedure_events['endtime'] = pd.to_datetime(df_procedure_events['endtime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_procedure_events['starttime'] = pd.to_datetime(df_procedure_events['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "df_procedure_events['duration'] = df_procedure_events['endtime'] - df_procedure_events['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_procedure_events['duration'] = df_procedure_events['duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "e0dffacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a recording_delay feature using storetime-endtime\n",
    "\n",
    "# Convert to datetime\n",
    "df_procedure_events['storetime'] = pd.to_datetime(df_procedure_events['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_procedure_events['recording_delay'] = df_procedure_events['storetime'] - df_procedure_events['endtime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_procedure_events['recording_delay'] = df_procedure_events['recording_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "47c47582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_procedure_events = df_procedure_events.drop(columns=['subject_id','stay_id','starttime','endtime','storetime','orderid',\n",
    "                                                        'linkorderid','continueinnextdept','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "4c16cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_procedure_events['location'] = df_procedure_events['location'].fillna('N/A')\n",
    "df_procedure_events['locationcategory'] = df_procedure_events['locationcategory'].fillna('N/A')\n",
    "df_procedure_events = pd.get_dummies(df_procedure_events, columns=['location','locationcategory','valueuom',\n",
    "                                                                   'ordercategoryname','ordercategorydescription',\n",
    "                                                                   'statusdescription','itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "fe9c33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "df_procedure_events['duration']= df_procedure_events['duration'].astype(str)\n",
    "df_procedure_events['duration']= df_procedure_events['duration'].apply(convert_to_days)\n",
    "df_procedure_events['recording_delay']= df_procedure_events['recording_delay'].astype(str)\n",
    "df_procedure_events['recording_delay']= df_procedure_events['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "5afbc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "df_procedure_events_training = df_procedure_events[~df_procedure_events['hadm_id'].isin(evaluation_admissions)]\n",
    "df_procedure_events_evaluation = df_procedure_events[df_procedure_events['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "bb460fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedure_events_training_target = codes.loc[df_procedure_events_training.index]\n",
    "df_procedure_events_evaluation_target = codes.loc[df_procedure_events_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "41920f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_procedure_events_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "5429f389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "6e706075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0040</th>\n",
       "      <th>0045</th>\n",
       "      <th>0221</th>\n",
       "      <th>02C03ZZ</th>\n",
       "      <th>02H633Z</th>\n",
       "      <th>02HV33Z</th>\n",
       "      <th>0390</th>\n",
       "      <th>0391</th>\n",
       "      <th>03HY32Z</th>\n",
       "      <th>03LP3DZ</th>\n",
       "      <th>...</th>\n",
       "      <th>9462</th>\n",
       "      <th>9604</th>\n",
       "      <th>966</th>\n",
       "      <th>9671</th>\n",
       "      <th>9672</th>\n",
       "      <th>9910</th>\n",
       "      <th>B211YZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0040  0045  0221  02C03ZZ  02H633Z  02HV33Z  0390  0391  03HY32Z  \\\n",
       "0       0     0     0        0        0        0     0     0        0   \n",
       "1       0     0     0        0        0        0     0     0        0   \n",
       "2       0     0     0        0        0        0     0     0        0   \n",
       "3       0     0     0        0        0        0     0     0        0   \n",
       "4       0     0     0        0        0        0     0     0        0   \n",
       "..    ...   ...   ...      ...      ...      ...   ...   ...      ...   \n",
       "520     0     0     0        0        0        0     0     0        0   \n",
       "521     0     0     0        0        0        0     0     0        0   \n",
       "522     0     0     0        0        0        0     0     0        0   \n",
       "641     0     0     0        0        0        0     0     0        0   \n",
       "642     0     0     0        0        0        0     0     0        0   \n",
       "\n",
       "     03LP3DZ  ...  9462  9604  966  9671  9672  9910  B211YZZ  B543ZZ3  \\\n",
       "0          0  ...     0     0    1     0     0     0        0        0   \n",
       "1          0  ...     0     0    1     0     0     0        0        0   \n",
       "2          0  ...     0     0    1     0     0     0        0        0   \n",
       "3          0  ...     0     0    1     0     0     0        0        0   \n",
       "4          0  ...     0     0    0     0     0     0        0        0   \n",
       "..       ...  ...   ...   ...  ...   ...   ...   ...      ...      ...   \n",
       "520        0  ...     0     0    0     0     0     0        0        0   \n",
       "521        0  ...     0     0    0     0     0     0        0        0   \n",
       "522        0  ...     0     0    0     0     0     0        0        0   \n",
       "641        0  ...     0     0    0     0     0     0        0        0   \n",
       "642        0  ...     0     0    0     0     0     0        0        0   \n",
       "\n",
       "     B548ZZA  DW021ZZ  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "..       ...      ...  \n",
       "520        0        0  \n",
       "521        0        0  \n",
       "522        0        0  \n",
       "641        0        0  \n",
       "642        0        0  \n",
       "\n",
       "[147 rows x 107 columns]"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procedure_events_evaluation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "3d3c169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedure_events_evaluation_target = df_procedure_events_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "c0aa4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_procedure_events_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "df_procedure_events_evaluation_target = df_procedure_events_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "8c3f0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_procedure_events_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_procedure_events_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "6e808d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_procedure_events_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_procedure_events_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "795d58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_procedure_events_training.drop(columns=['hadm_id'])\n",
    "target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e2254",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "b48148ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "                                           solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_procedure_events = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_procedure_events.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "73e16e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_procedure_events.joblib']"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_procedure_events.joblib')\n",
    "dump(logistic_clf_procedure_events, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b52cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c5a9a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_procedure_events['icd_code'] = float('nan')\n",
    "# for index, row in df_procedure_events.iterrows():\n",
    "#     # Filter target df based on 'hadm_id'\n",
    "#     df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "\n",
    "#     datetime_value = row['endtime']\n",
    "    \n",
    "#     # Filter out datetime values in the second dataframe that are later than the datetime value in the first dataframe\n",
    "#     filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "#     if not filtered_procedures.empty:\n",
    "\n",
    "#         # Find the closest datetime value in the filtered second dataframe\n",
    "#         closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "#         # Get the id of the sample with the closest datetime value\n",
    "#         closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]['icd_code']\n",
    "#         code = pd.array(closest_id)[0]\n",
    "\n",
    "#         # Assign the id to the current row in the first dataframe\n",
    "#         df_procedure_events.at[index, 'icd_code'] = str(code)\n",
    "\n",
    "# df_procedure_events.dropna(subset=['icd_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "39f1070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', penalty=None,\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initialize and fit\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_procedure_events = LogisticRegression(random_state = 42, penalty = None, multi_class='multinomial', \n",
    "#                                            solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# logistic_clf_procedure_events.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1209923",
   "metadata": {},
   "source": [
    "### datetimeevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "3da621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/datetimeevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_datetime_events = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345cd28d",
   "metadata": {},
   "source": [
    "#### Preprocessing (on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "b3c600d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime_events = df_datetime_events[df_datetime_events['hadm_id'].isin(df_procedures['hadm_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "c126a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_datetime_events['value'] = pd.to_datetime(df_datetime_events['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "c6ab1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame()\n",
    "data_new = pd.DataFrame()\n",
    "\n",
    "for index, row in df_datetime_events.iterrows():\n",
    "#     print(row['outtime'])\n",
    "    # Filter procedures to have the same 'hadm_id' as that row in emar\n",
    "    df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "#     print(df_procedures_subset['chartdate'])\n",
    "    # Get the datetime value of that emar sample\n",
    "    datetime_value = row['value']\n",
    "    \n",
    "    # Filter out procedures that are later than the datetime value in emar\n",
    "    filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "    # if it is empty it means there are no procedures for that admission after this sample was taken \n",
    "    if not filtered_procedures.empty:\n",
    "#         print(filtered_procedures)\n",
    "#         print('next')\n",
    "        data_new = pd.concat([data_new, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Find the closest datetime value in the filtered second dataframe\n",
    "        # Closest to datetime_value\n",
    "        closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "        # Get the the sample with the closest datetime value\n",
    "        closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]\n",
    "#         codes = codes + pd.DataFrame(closest_id)\n",
    "        codes = pd.concat([codes, closest_id], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "254435e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime_events = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "7279a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_datetime_events = df_datetime_events.drop(columns=['warning','value','subject_id','stay_id','caregiver_id',\n",
    "                                                     'charttime','storetime','valueuom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "33ef9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "df_datetime_events = pd.get_dummies(df_datetime_events, columns=['itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "fb0e254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into training and evaluation sets \n",
    "df_datetime_events_training = df_datetime_events[~df_datetime_events['hadm_id'].isin(evaluation_admissions)]\n",
    "df_datetime_events_evaluation = df_datetime_events[df_datetime_events['hadm_id'].isin(evaluation_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "5a2bc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime_events_training_target = codes.loc[df_datetime_events_training.index]\n",
    "df_datetime_events_evaluation_target = codes.loc[df_datetime_events_evaluation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "f95142bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_datetime_events_training_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "19177b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with all zeros\n",
    "target = target.loc[:, (target != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "86800750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>0039</th>\n",
       "      <th>0040</th>\n",
       "      <th>0041</th>\n",
       "      <th>0045</th>\n",
       "      <th>0051</th>\n",
       "      <th>0066</th>\n",
       "      <th>0069</th>\n",
       "      <th>0091</th>\n",
       "      <th>...</th>\n",
       "      <th>B41GYZZ</th>\n",
       "      <th>B518YZA</th>\n",
       "      <th>B51W1ZZ</th>\n",
       "      <th>B543ZZ3</th>\n",
       "      <th>B548ZZA</th>\n",
       "      <th>B54BZZA</th>\n",
       "      <th>BT1DYZZ</th>\n",
       "      <th>BT1FYZZ</th>\n",
       "      <th>D7021ZZ</th>\n",
       "      <th>DW021ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-02-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-02-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-02-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-02-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>29276678</td>\n",
       "      <td>2116-02-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10570</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10571</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10572</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10573</th>\n",
       "      <td>28998349</td>\n",
       "      <td>2116-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2451 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  chartdate  0039  0040  0041  0045  0051  0066  0069  0091  \\\n",
       "163    29276678 2116-02-29     0     0     0     0     0     0     0     0   \n",
       "164    29276678 2116-02-29     0     0     0     0     0     0     0     0   \n",
       "165    29276678 2116-02-29     0     0     0     0     0     0     0     0   \n",
       "166    29276678 2116-02-29     0     0     0     0     0     0     0     0   \n",
       "167    29276678 2116-02-29     0     0     0     0     0     0     0     0   \n",
       "...         ...        ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "10569  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "10570  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "10571  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "10572  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "10573  28998349 2116-12-07     0     0     0     0     0     0     0     0   \n",
       "\n",
       "       ...  B41GYZZ  B518YZA  B51W1ZZ  B543ZZ3  B548ZZA  B54BZZA  BT1DYZZ  \\\n",
       "163    ...        0        0        0        0        0        0        0   \n",
       "164    ...        0        0        0        0        0        0        0   \n",
       "165    ...        0        0        0        0        0        0        0   \n",
       "166    ...        0        0        0        0        0        0        0   \n",
       "167    ...        0        0        0        0        0        0        0   \n",
       "...    ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "10569  ...        0        0        0        0        0        0        0   \n",
       "10570  ...        0        0        0        0        0        0        0   \n",
       "10571  ...        0        0        0        0        0        0        0   \n",
       "10572  ...        0        0        0        0        0        0        0   \n",
       "10573  ...        0        0        0        0        0        0        0   \n",
       "\n",
       "       BT1FYZZ  D7021ZZ  DW021ZZ  \n",
       "163          0        0        0  \n",
       "164          0        0        0  \n",
       "165          0        0        0  \n",
       "166          0        0        0  \n",
       "167          0        0        0  \n",
       "...        ...      ...      ...  \n",
       "10569        0        0        0  \n",
       "10570        0        0        0  \n",
       "10571        0        0        0  \n",
       "10572        0        0        0  \n",
       "10573        0        0        0  \n",
       "\n",
       "[2451 rows x 354 columns]"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datetime_events_evaluation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "1deefd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime_events_evaluation_target = df_datetime_events_evaluation_target.drop(columns=['hadm_id', 'chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "9d8b9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of columns between the two DataFrames\n",
    "common_columns = df_datetime_events_evaluation_target.columns.intersection(target.columns)\n",
    "\n",
    "df_datetime_events_evaluation_target = df_datetime_events_evaluation_target[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "31c1b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data for later \n",
    "folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_datetime_events_evaluation.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_datetime_events_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "ec3f64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(folder_name, 'df_datetime_events_evaluation_target.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "df_datetime_events_evaluation_target.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "aecd684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_datetime_events_training.drop(columns=['hadm_id'])\n",
    "target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3591ea",
   "metadata": {},
   "source": [
    "#### Training the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "e71e0658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(multi_class='multinomial',\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "logistic_reg = LogisticRegression(random_state = 42, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Wrap logistic regression classifier in MultiOutputClassifier\n",
    "logistic_clf_datetime_events = MultiOutputClassifier(logistic_reg)\n",
    "\n",
    "# Train the multi-output logistic regression model\n",
    "logistic_clf_datetime_events.fit(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "e6b9c6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procedures_learners\\\\logistic_clf_datetime_events.joblib']"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to folder\n",
    "\n",
    "output_folder = 'procedures_learners'\n",
    "\n",
    "# Save the trained model to a file in the new folder\n",
    "model_file = os.path.join(output_folder, 'logistic_clf_datetime_events.joblib')\n",
    "dump(logistic_clf_datetime_events, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d6f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9bdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9e1a61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_datetime_events['icd_code'] = float('nan')\n",
    "# for index, row in df_datetime_events.iterrows():\n",
    "#     # Filter target df based on 'hadm_id'\n",
    "#     df_procedures_subset = df_procedures[df_procedures['hadm_id'] == row['hadm_id']]\n",
    "\n",
    "#     datetime_value = row['value']\n",
    "    \n",
    "#     # Filter out datetime values in the second dataframe that are later than the datetime value in the first dataframe\n",
    "#     filtered_procedures = df_procedures_subset[df_procedures_subset['chartdate'] > datetime_value]\n",
    "    \n",
    "#     if not filtered_procedures.empty:\n",
    "\n",
    "#         # Find the closest datetime value in the filtered second dataframe\n",
    "#         closest_datetime = filtered_procedures['chartdate'].min()\n",
    "\n",
    "#         # Get the id of the sample with the closest datetime value\n",
    "#         closest_id = filtered_procedures[filtered_procedures['chartdate'] == closest_datetime]['icd_code']\n",
    "#         code = pd.array(closest_id)[0]\n",
    "\n",
    "#         # Assign the id to the current row in the first dataframe\n",
    "#         df_datetime_events.at[index, 'icd_code'] = str(code)\n",
    "\n",
    "# df_datetime_events.dropna(subset=['icd_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4144332a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=42)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initialize and fit\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # # Instantiate the logistic regression model\n",
    "# logistic_clf_datetime_events = LogisticRegression(random_state = 42, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# logistic_clf_datetime_events.fit(data, np.ravel(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a3e10350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save evaluation data for later \n",
    "# folder_name = 'EnsembleEvaluationData'\n",
    "\n",
    "# # Define the file path\n",
    "# file_path = os.path.join(folder_name, 'df_datetime_events_evaluation.csv')\n",
    "\n",
    "# # Save the DataFrame to a CSV file in the specified folder\n",
    "# df_datetime_events_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a69b7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_datetime_events_training.drop(columns=['icd_code','hadm_id'])\n",
    "# target = pd.DataFrame(df_datetime_events_training['icd_code'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
