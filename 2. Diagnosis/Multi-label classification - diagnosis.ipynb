{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397b0aa8",
   "metadata": {},
   "source": [
    "#### Notes from phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff09fa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\jenni\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48bf5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for each table was split into train and test\n",
    "# To get the target labels, search and filter the diagnoses dataframes (saved) for the hadm_ids present in the train / test\n",
    "# set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8636aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.24.3\n",
      "Pandas version: 1.5.3\n",
      "Scikit version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# External libraries for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "#To render graphs within notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Versions of libraries\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Scikit version: {}\".format(sk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93008b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df208946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_days(duration_str):\n",
    "    parts = duration_str.split(' days ')  # Split string into form ['22', '20:55:00']\n",
    "    days = float(parts[0])  # Extract number of days and convert to float\n",
    "    time_parts = parts[1].split(':')  # Split time part (hh:mm:ss) ['20', '55', '00']\n",
    "    hours = float(time_parts[0])  # Extract hours and convert to float\n",
    "    minutes = float(time_parts[1])  # Extract minutes and convert to float\n",
    "    seconds = float(time_parts[2])  # Extract seconds and convert to float\n",
    "    total_days = days + (hours / 24) + (minutes / (24 * 60)) + (seconds / (24 * 3600))  # Calculate total days\n",
    "    return total_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d22e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a6b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)\n",
    "\n",
    "df_admissions['dischtime'] = pd.to_datetime(df_admissions['dischtime'], format='%d/%m/%Y %H:%M')\n",
    "df_admissions['admittime'] = pd.to_datetime(df_admissions['admittime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_admittime= pd.DataFrame()\n",
    "df_admittime['hadm_id'] = df_admissions['hadm_id']\n",
    "df_admittime['admittime'] = df_admissions['admittime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03dcef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/diagnoses_icd.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_diagnoses = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e9311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses = df_diagnoses.drop(columns=['subject_id','seq_num','icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9952635",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_diagnoses['icd_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_diagnoses[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b134c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>00845</th>\n",
       "      <th>0088</th>\n",
       "      <th>0380</th>\n",
       "      <th>0383</th>\n",
       "      <th>03842</th>\n",
       "      <th>03843</th>\n",
       "      <th>03849</th>\n",
       "      <th>0388</th>\n",
       "      <th>0389</th>\n",
       "      <th>...</th>\n",
       "      <th>Z95810</th>\n",
       "      <th>Z95820</th>\n",
       "      <th>Z961</th>\n",
       "      <th>Z96651</th>\n",
       "      <th>Z980</th>\n",
       "      <th>Z981</th>\n",
       "      <th>Z9884</th>\n",
       "      <th>Z9911</th>\n",
       "      <th>Z992</th>\n",
       "      <th>Z9981</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>29820177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  00845  0088  0380  0383  03842  03843  03849  0388  0389  ...  \\\n",
       "0    20044587      0     0     0     0      0      0      0     0     0  ...   \n",
       "1    20093566      0     0     0     0      0      0      0     0     0  ...   \n",
       "2    20192635      0     0     0     0      0      0      0     0     0  ...   \n",
       "3    20199380      0     0     0     0      0      0      0     0     0  ...   \n",
       "4    20214994      0     0     0     0      0      0      0     0     0  ...   \n",
       "..        ...    ...   ...   ...   ...    ...    ...    ...   ...   ...  ...   \n",
       "270  29820177      0     0     0     0      0      0      0     0     0  ...   \n",
       "271  29839885      0     0     0     0      0      0      0     0     0  ...   \n",
       "272  29842315      0     0     0     0      0      0      0     0     0  ...   \n",
       "273  29858644      0     0     0     0      0      0      0     0     0  ...   \n",
       "274  29974575      0     0     0     0      0      0      1     0     0  ...   \n",
       "\n",
       "     Z95810  Z95820  Z961  Z96651  Z980  Z981  Z9884  Z9911  Z992  Z9981  \n",
       "0         0       0     0       0     0     0      0      0     0      0  \n",
       "1         0       0     0       0     0     0      1      0     1      0  \n",
       "2         0       0     0       0     0     0      0      0     0      0  \n",
       "3         0       0     0       0     0     0      0      0     0      0  \n",
       "4         0       0     0       0     0     0      0      0     0      0  \n",
       "..      ...     ...   ...     ...   ...   ...    ...    ...   ...    ...  \n",
       "270       0       0     0       0     0     0      0      0     0      0  \n",
       "271       0       0     0       0     0     0      0      0     0      0  \n",
       "272       0       0     0       0     0     0      0      0     1      1  \n",
       "273       0       0     0       0     0     0      0      0     0      0  \n",
       "274       0       0     0       0     0     0      0      0     0      0  \n",
       "\n",
       "[275 rows x 1473 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diagnoses = df_aggregated\n",
    "df_diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b17e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/drgcodes.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_drgcodes = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329d7c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22187210    2\n",
       "27505812    2\n",
       "25926192    2\n",
       "27089790    2\n",
       "24490144    2\n",
       "           ..\n",
       "22539296    1\n",
       "20385771    1\n",
       "20199380    1\n",
       "20973395    1\n",
       "23559586    1\n",
       "Name: hadm_id, Length: 233, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes['hadm_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37288755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>drg_type</th>\n",
       "      <th>drg_code</th>\n",
       "      <th>description</th>\n",
       "      <th>drg_severity</th>\n",
       "      <th>drg_mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004235</td>\n",
       "      <td>22187210</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>864</td>\n",
       "      <td>FEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026255</td>\n",
       "      <td>22059910</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>180</td>\n",
       "      <td>RESPIRATORY NEOPLASMS W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10032725</td>\n",
       "      <td>20611640</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>54</td>\n",
       "      <td>NERVOUS SYSTEM NEOPLASMS W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005866</td>\n",
       "      <td>21636229</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>393</td>\n",
       "      <td>OTHER DIGESTIVE SYSTEM DIAGNOSES W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10008454</td>\n",
       "      <td>20291550</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>956</td>\n",
       "      <td>LIMB REATTACHMENT, HIP &amp; FEMUR PROC FOR MULTIP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id drg_type  drg_code  \\\n",
       "0    10004235  22187210     HCFA       864   \n",
       "1    10026255  22059910     HCFA       180   \n",
       "2    10032725  20611640     HCFA        54   \n",
       "3    10005866  21636229     HCFA       393   \n",
       "4    10008454  20291550     HCFA       956   \n",
       "\n",
       "                                         description  drg_severity  \\\n",
       "0                                              FEVER           NaN   \n",
       "1                        RESPIRATORY NEOPLASMS W MCC           NaN   \n",
       "2                     NERVOUS SYSTEM NEOPLASMS W MCC           NaN   \n",
       "3             OTHER DIGESTIVE SYSTEM DIAGNOSES W MCC           NaN   \n",
       "4  LIMB REATTACHMENT, HIP & FEMUR PROC FOR MULTIP...           NaN   \n",
       "\n",
       "   drg_mortality  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d4236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drgcodes = df_drgcodes.drop(columns=['subject_id','drg_type','description','drg_severity','drg_mortality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0836367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_drgcodes['drg_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_drgcodes[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e6caaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>29802992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0    20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1    20093566   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2    20192635   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3    20199380   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4    20214994   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "..        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "228  29802992   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "229  29839885   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "230  29842315   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "231  29858644   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "232  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "     957  981  982  983  987  988  \n",
       "0      0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  \n",
       "228    0    0    0    0    0    0  \n",
       "229    0    0    0    0    0    0  \n",
       "230    0    0    0    0    0    0  \n",
       "231    0    0    0    0    0    0  \n",
       "232    0    0    0    0    0    0  \n",
       "\n",
       "[233 rows x 241 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes = df_aggregated\n",
    "df_drgcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5d829",
   "metadata": {},
   "source": [
    "### microbiologyevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e402c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"microbio_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"microbio_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3d367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddcff0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "816b6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "200a82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f125b3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1540 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0     20093566   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1     20199380   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2     20214994   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3     20214994   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4     20214994   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "...        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "1535  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1536  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1537  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1538  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1539  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "      957  981  982  983  987  988  \n",
       "0       0    0    0    0    0    0  \n",
       "1       0    0    0    0    0    0  \n",
       "2       0    0    0    0    0    0  \n",
       "3       0    0    0    0    0    0  \n",
       "4       0    0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  ...  \n",
       "1535    0    0    0    0    0    0  \n",
       "1536    0    0    0    0    0    0  \n",
       "1537    0    0    0    0    0    0  \n",
       "1538    0    0    0    0    0    0  \n",
       "1539    0    0    0    0    0    0  \n",
       "\n",
       "[1540 rows x 241 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = merged_df\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79c133b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "713c744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b15d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee426675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b70e8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baa02a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "389b87c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1540, 240), (386, 240))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf330577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique label classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42581e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique rows in y_train: 125\n",
      "Number of unique rows in y_test: 81\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique rows\n",
    "num_unique_rows = y_train.drop_duplicates().shape[0]\n",
    "\n",
    "print(\"Number of unique rows in y_train:\", num_unique_rows)\n",
    "\n",
    "num_unique_rows = y_test.drop_duplicates().shape[0]\n",
    "\n",
    "print(\"Number of unique rows in y_test:\", num_unique_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce95a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56dbe5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65060db",
   "metadata": {},
   "source": [
    "There are several ways to measure a classifier’s generalization quality:\n",
    "\n",
    "Hamming loss measures how well the classifier predicts each of the labels, averaged over samples, then over labels\n",
    "accuracy score measures how well the classifier predicts label combinations, averaged over samples\n",
    "\n",
    "jaccard similarity measures the proportion of predicted labels for a sample to its correct assignment, averaged over samples\n",
    "\n",
    "precision measures how many samples with ,\n",
    "\n",
    "recall measures how many samples ,\n",
    "\n",
    "F1 score measures a weighted average of precision and recall, where both have the same impact on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5c86d097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLARAM Accuracy: 0.06476683937823834\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.08      0.31      0.12        13\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         9\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.14      0.36      0.20        33\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.00      0.00      0.00         7\n",
      "          46       0.00      0.00      0.00         4\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         7\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.00      0.00      0.00         5\n",
      "          61       0.00      0.00      0.00         7\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.14      0.34      0.20        35\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         5\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         5\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00        12\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.15      0.90      0.25        41\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         7\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         7\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         3\n",
      "         106       0.00      0.00      0.00         8\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         3\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00        13\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00        12\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         4\n",
      "         147       0.00      0.00      0.00         3\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.14      0.87      0.25        31\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00        15\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         6\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.00      0.00      0.00         3\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         2\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         5\n",
      "         172       0.00      0.00      0.00         8\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         4\n",
      "         183       0.00      0.00      0.00         8\n",
      "         184       0.00      0.00      0.00         2\n",
      "         185       0.00      0.00      0.00         9\n",
      "         186       0.22      0.24      0.23        21\n",
      "         187       0.21      0.33      0.26        48\n",
      "         188       0.00      0.00      0.00        12\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.02      0.25      0.03         4\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         7\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         2\n",
      "         208       0.00      0.00      0.00         6\n",
      "         209       0.00      0.00      0.00         9\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.22      0.24      0.23        21\n",
      "         212       0.00      0.00      0.00         6\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.33      0.15      0.21        13\n",
      "         216       0.14      0.28      0.18        29\n",
      "         217       0.00      0.00      0.00         4\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.05      0.14      0.07        14\n",
      "         226       0.00      0.00      0.00         3\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         6\n",
      "         230       0.00      0.00      0.00        13\n",
      "         231       0.02      0.14      0.03         7\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.05      0.13      0.07        15\n",
      "         235       0.00      0.00      0.00        13\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.10      0.18      0.13       763\n",
      "   macro avg       0.01      0.02      0.01       763\n",
      "weighted avg       0.07      0.18      0.09       763\n",
      " samples avg       0.12      0.17      0.13       763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLARAM\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# MLARAM classifier\n",
    "classifier = MLARAM()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"MLARAM Accuracy:\", accuracy)\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eff1c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Generate sample multilabel dataset\n",
    "# X, y = make_multilabel_classification(n_samples=1000, n_features=20, n_classes=5, n_labels=2, random_state=42)\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Multi-Label Stochastic Gradient Descent (ML-SGD) with Label Powerset\n",
    "classifier = LabelPowerset(SGDClassifier())\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "12b1bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.012022760646108663\n",
      "Accuracy: 0.2511013215859031\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.50      0.07      0.12        15\n",
      "           2       0.50      0.09      0.15        11\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.36      0.33      0.35        24\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       1.00      0.50      0.67         4\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.36      0.33      0.35        24\n",
      "          71       0.00      0.00      0.00         3\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       1.00      0.67      0.80         3\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         5\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         3\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         3\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.35      0.61      0.45        31\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.04      0.60      0.07         5\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.67      0.67      0.67         3\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         3\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         3\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.37      0.67      0.48        24\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         4\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.04      0.75      0.07         4\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.67      0.50      0.57         4\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.67      0.67      0.67         3\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       0.00      0.00      0.00         3\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         6\n",
      "         184       0.00      0.00      0.00         3\n",
      "         185       0.60      0.30      0.40        10\n",
      "         186       1.00      0.50      0.67        20\n",
      "         187       0.36      0.41      0.38        22\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.20      0.14      0.17         7\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         5\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         3\n",
      "         208       1.00      1.00      1.00         2\n",
      "         209       0.60      0.30      0.40        10\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       1.00      0.50      0.67        20\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       1.00      0.57      0.73         7\n",
      "         216       0.19      0.33      0.24        12\n",
      "         217       0.00      0.00      0.00         3\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00        15\n",
      "         226       0.00      0.00      0.00         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      1.00      1.00         2\n",
      "         230       0.67      0.20      0.31        10\n",
      "         231       0.20      0.09      0.13        11\n",
      "         232       0.00      0.00      0.00         2\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       1.00      0.06      0.11        17\n",
      "         235       0.67      0.18      0.29        11\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         8\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.27      0.28      0.27       447\n",
      "   macro avg       0.07      0.05      0.05       447\n",
      "weighted avg       0.39      0.28      0.28       447\n",
      " samples avg       0.27      0.27      0.27       447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "hamming_loss = metrics.hamming_loss(y_test, predictions)\n",
    "print(\"Hamming loss:\", hamming_loss)\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will take 50 minutes to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "41d352c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [16:39:46<00:00, 599.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3876651982378855\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.33      0.50        15\n",
      "           2       1.00      0.36      0.53        11\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       1.00      0.20      0.33         5\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.33      0.50         3\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      0.33      0.50         3\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.73      0.79      0.76        24\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       1.00      0.75      0.86         4\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       1.00      1.00      1.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.73      0.67      0.70        24\n",
      "          71       0.00      0.00      0.00         3\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       1.00      0.33      0.50         3\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.50      0.20      0.29         5\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         3\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         3\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.84      0.52      0.64        31\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.50      0.40      0.44         5\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.75      1.00      0.86         3\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         3\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         3\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.88      0.58      0.70        24\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.50      0.25      0.33         4\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         4\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.67      0.50      0.57         4\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.75      1.00      0.86         3\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       1.00      1.00      1.00         3\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       1.00      0.17      0.29         6\n",
      "         184       0.00      0.00      0.00         3\n",
      "         185       0.50      0.30      0.37        10\n",
      "         186       1.00      0.70      0.82        20\n",
      "         187       0.59      0.45      0.51        22\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       1.00      0.14      0.25         7\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       1.00      0.20      0.33         5\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         3\n",
      "         208       1.00      0.50      0.67         2\n",
      "         209       0.43      0.30      0.35        10\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       1.00      0.70      0.82        20\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       1.00      0.71      0.83         7\n",
      "         216       0.38      0.25      0.30        12\n",
      "         217       0.00      0.00      0.00         3\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       1.00      0.47      0.64        15\n",
      "         226       0.00      0.00      0.00         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      0.50      0.67         2\n",
      "         230       0.88      0.70      0.78        10\n",
      "         231       1.00      0.27      0.43        11\n",
      "         232       0.00      0.00      0.00         2\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.82      0.53      0.64        17\n",
      "         235       1.00      0.64      0.78        11\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         8\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.80      0.43      0.56       447\n",
      "   macro avg       0.14      0.09      0.11       447\n",
      "weighted avg       0.68      0.43      0.50       447\n",
      " samples avg       0.45      0.42      0.43       447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the base classifier (Random Forest)\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# Initialize the RAkEL classifier with the base classifier\n",
    "classifier = RakelD(base_classifier, labelset_size=3)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89911efe",
   "metadata": {},
   "source": [
    "#### Multi-output decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "96655603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=50)\n",
    "\n",
    "# Initialize the multi-output classifier with the decision tree as the base estimator\n",
    "multi_output_tree = MultiOutputClassifier(decision_tree, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "5c8bb1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=DecisionTreeClassifier(max_depth=50), n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=DecisionTreeClassifier(max_depth=50), n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=50)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=50)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=DecisionTreeClassifier(max_depth=50), n_jobs=-1)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the multi-output classifier\n",
    "multi_output_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "14b448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the outputs for the test set\n",
    "y_pred = multi_output_tree.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fdc3c8fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1540, 277)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b270fff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1540, 240)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "d05cd23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 277)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b331fa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 240)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "7e884715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 240)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "0a32220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 240)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ff579c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.007102763385146805\n"
     ]
    }
   ],
   "source": [
    "# Hamming loss measures the fraction of labels that are incorrectly predicted, averaged over all samples\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test.values, y_pred_multilabel)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "96c1c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example thresholding (adjust threshold as needed)\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Now, both y_test.values and y_pred_multilabel should be in the multilabel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b1c2fff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4481865284974093\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.60      0.69      0.64        13\n",
      "           2       0.50      1.00      0.67         5\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.33      1.00      0.50         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       1.00      0.44      0.62         9\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.55      0.67      0.60         9\n",
      "          14       1.00      0.50      0.67         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.60      0.67      0.63         9\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       1.00      0.50      0.67         2\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.50      0.25      0.33         4\n",
      "          28       0.67      0.61      0.63        33\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.17      0.17      0.17         6\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.71      0.71      0.71         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.50      0.50      0.50         4\n",
      "          45       0.50      0.57      0.53         7\n",
      "          46       0.60      0.75      0.67         4\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.67      0.86      0.75         7\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       1.00      0.50      0.67         2\n",
      "          59       0.86      1.00      0.92         6\n",
      "          60       0.00      0.00      0.00         5\n",
      "          61       0.71      0.71      0.71         7\n",
      "          62       0.20      0.50      0.29         2\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.54      0.63      0.58        35\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         5\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         5\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.40      0.50      0.44        12\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.67      0.57      0.62         7\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.84      0.76      0.79        41\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       1.00      0.86      0.92         7\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.40      0.57      0.47         7\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       1.00      0.67      0.80         3\n",
      "         106       1.00      0.88      0.93         8\n",
      "         107       0.55      0.86      0.67         7\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         3\n",
      "         116       0.67      1.00      0.80         2\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.70      0.54      0.61        13\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.40      1.00      0.57         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.83      0.42      0.56        12\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.60      0.75      0.67         4\n",
      "         147       0.50      0.33      0.40         3\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.96      0.77      0.86        31\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.62      0.67      0.65        15\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.43      0.50      0.46         6\n",
      "         157       1.00      0.50      0.67         2\n",
      "         158       0.33      0.33      0.33         3\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.33      0.50      0.40         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.67      1.00      0.80         2\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.67      0.40      0.50         5\n",
      "         172       1.00      0.88      0.93         8\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       1.00      1.00      1.00         4\n",
      "         183       0.20      0.25      0.22         8\n",
      "         184       0.50      0.50      0.50         2\n",
      "         185       0.57      0.44      0.50         9\n",
      "         186       0.75      0.86      0.80        21\n",
      "         187       0.48      0.44      0.46        48\n",
      "         188       1.00      0.83      0.91        12\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.50      0.75      0.60         4\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.33      0.43      0.38         7\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.50      0.50      0.50         2\n",
      "         208       1.00      0.67      0.80         6\n",
      "         209       0.50      0.44      0.47         9\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.75      0.86      0.80        21\n",
      "         212       1.00      1.00      1.00         6\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.75      0.46      0.57        13\n",
      "         216       0.50      0.34      0.41        29\n",
      "         217       0.00      0.00      0.00         4\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.64      0.64      0.64        14\n",
      "         226       1.00      0.33      0.50         3\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      0.67      0.80         6\n",
      "         230       0.62      0.62      0.62        13\n",
      "         231       0.31      0.57      0.40         7\n",
      "         232       0.62      0.71      0.67         7\n",
      "         233       1.00      0.50      0.67         2\n",
      "         234       0.57      0.53      0.55        15\n",
      "         235       0.64      0.69      0.67        13\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.67      0.86      0.75         7\n",
      "         239       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.57      0.55      0.56       763\n",
      "   macro avg       0.20      0.19      0.19       763\n",
      "weighted avg       0.58      0.55      0.55       763\n",
      " samples avg       0.54      0.55      0.54       763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test.values, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test.values, y_pred_multilabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07412848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to work out which label is which for write up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a11555",
   "metadata": {},
   "source": [
    "#### Random forest for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "17ce6079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2616580310880829\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.14      0.08      0.10        13\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.56      0.71         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      0.56      0.71         9\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.67      0.30      0.42        33\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.20      0.14      0.17         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.00      0.00      0.00         7\n",
      "          46       1.00      0.25      0.40         4\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       1.00      0.71      0.83         7\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       0.50      0.50      0.50         2\n",
      "          59       1.00      0.83      0.91         6\n",
      "          60       0.00      0.00      0.00         5\n",
      "          61       1.00      0.57      0.73         7\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.67      0.29      0.40        35\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         5\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         5\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.75      0.25      0.38        12\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.73      0.27      0.39        41\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       1.00      0.71      0.83         7\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       1.00      0.29      0.44         7\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       1.00      0.33      0.50         3\n",
      "         106       0.86      0.75      0.80         8\n",
      "         107       1.00      0.57      0.73         7\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         3\n",
      "         116       1.00      0.50      0.67         2\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.71      0.38      0.50        13\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       1.00      0.50      0.67         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.75      0.25      0.38        12\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         4\n",
      "         147       0.00      0.00      0.00         3\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.78      0.45      0.57        31\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       1.00      0.07      0.12        15\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         6\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       1.00      0.33      0.50         3\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       1.00      0.50      0.67         2\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.50      0.20      0.29         5\n",
      "         172       1.00      0.75      0.86         8\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       1.00      0.50      0.67         4\n",
      "         183       1.00      0.12      0.22         8\n",
      "         184       1.00      0.50      0.67         2\n",
      "         185       1.00      0.22      0.36         9\n",
      "         186       0.94      0.76      0.84        21\n",
      "         187       0.43      0.21      0.28        48\n",
      "         188       0.75      0.75      0.75        12\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         4\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       1.00      0.14      0.25         7\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       1.00      0.50      0.67         2\n",
      "         208       1.00      0.67      0.80         6\n",
      "         209       1.00      0.22      0.36         9\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.94      0.76      0.84        21\n",
      "         212       0.86      1.00      0.92         6\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       1.00      0.31      0.47        13\n",
      "         216       0.09      0.03      0.05        29\n",
      "         217       0.00      0.00      0.00         4\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.50      0.14      0.22        14\n",
      "         226       0.00      0.00      0.00         3\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      0.67      0.80         6\n",
      "         230       0.67      0.31      0.42        13\n",
      "         231       0.00      0.00      0.00         7\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.50      0.13      0.21        15\n",
      "         235       0.67      0.31      0.42        13\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.33      0.14      0.20         7\n",
      "         239       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.68      0.27      0.39       763\n",
      "   macro avg       0.17      0.09      0.11       763\n",
      "weighted avg       0.55      0.27      0.35       763\n",
      " samples avg       0.29      0.27      0.28       763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a multi-output Random Forest classifier\n",
    "forest_classifier = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# Train the classifier\n",
    "forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = forest_classifier.predict(X_test)\n",
    "\n",
    "# Example thresholding (adjust threshold as needed)\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Now, both y_test.values and y_pred_multilabel should be in the multilabel format\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_multilabel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c7a40",
   "metadata": {},
   "source": [
    "#### Classifier Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "6bd1b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize a base classifier (Random Forest in this case)\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# Initialize the Classifier Chain classifier with the base classifier\n",
    "classifier = ClassifierChain(classifier=base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b3cec6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "ccd1c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3549222797927461\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      0.15      0.24        13\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       1.00      0.22      0.36         9\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.56      0.71         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      0.56      0.71         9\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.65      0.33      0.44        33\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.33      0.43      0.38         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.25      0.14      0.18         7\n",
      "          46       0.60      0.75      0.67         4\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       1.00      0.86      0.92         7\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       1.00      0.50      0.67         2\n",
      "          59       1.00      1.00      1.00         6\n",
      "          60       0.00      0.00      0.00         5\n",
      "          61       1.00      0.71      0.83         7\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.65      0.31      0.42        35\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.50      0.20      0.29         5\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         5\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.67      0.17      0.27        12\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       1.00      0.14      0.25         7\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.71      0.41      0.52        41\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       1.00      0.86      0.92         7\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.67      0.29      0.40         7\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       1.00      0.33      0.50         3\n",
      "         106       1.00      0.88      0.93         8\n",
      "         107       1.00      0.71      0.83         7\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         3\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.83      0.38      0.53        13\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       1.00      0.50      0.67         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.67      0.17      0.27        12\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         4\n",
      "         147       1.00      0.33      0.50         3\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.80      0.52      0.63        31\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.83      0.33      0.48        15\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.25      0.17      0.20         6\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       1.00      0.33      0.50         3\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       1.00      1.00      1.00         2\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       1.00      0.20      0.33         5\n",
      "         172       1.00      0.62      0.77         8\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       1.00      0.50      0.67         4\n",
      "         183       0.67      0.25      0.36         8\n",
      "         184       1.00      0.50      0.67         2\n",
      "         185       1.00      0.33      0.50         9\n",
      "         186       0.95      0.86      0.90        21\n",
      "         187       0.36      0.40      0.38        48\n",
      "         188       0.82      0.75      0.78        12\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         4\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.67      0.29      0.40         7\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       1.00      0.50      0.67         2\n",
      "         208       1.00      0.50      0.67         6\n",
      "         209       1.00      0.33      0.50         9\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.95      0.86      0.90        21\n",
      "         212       1.00      1.00      1.00         6\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.67      0.31      0.42        13\n",
      "         216       0.15      0.21      0.17        29\n",
      "         217       0.50      0.25      0.33         4\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.32      0.43      0.36        14\n",
      "         226       0.00      0.00      0.00         3\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      0.50      0.67         6\n",
      "         230       0.80      0.62      0.70        13\n",
      "         231       1.00      0.14      0.25         7\n",
      "         232       0.50      0.14      0.22         7\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.30      0.40      0.34        15\n",
      "         235       0.80      0.62      0.70        13\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.22      0.29      0.25         7\n",
      "         239       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.62      0.37      0.46       763\n",
      "   macro avg       0.20      0.12      0.14       763\n",
      "weighted avg       0.58      0.37      0.43       763\n",
      " samples avg       0.37      0.37      0.37       763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Example thresholding (adjust threshold as needed)\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_multilabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "139e1e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44052863436123346\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.40      0.57        15\n",
      "           2       0.83      0.45      0.59        11\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       1.00      0.20      0.33         5\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.33      0.50         3\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      0.33      0.50         3\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.76      0.67      0.71        24\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       1.00      0.50      0.67         4\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       1.00      1.00      1.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.73      0.67      0.70        24\n",
      "          71       0.00      0.00      0.00         3\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       1.00      0.67      0.80         3\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         5\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         3\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         3\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.77      0.65      0.70        31\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.33      0.40      0.36         5\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.75      1.00      0.86         3\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         3\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         3\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.81      0.71      0.76        24\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.67      0.50      0.57         4\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         4\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.50      0.50      0.50         4\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.75      1.00      0.86         3\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       1.00      0.67      0.80         3\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       1.00      0.17      0.29         6\n",
      "         184       0.00      0.00      0.00         3\n",
      "         185       0.50      0.40      0.44        10\n",
      "         186       1.00      0.70      0.82        20\n",
      "         187       0.45      0.64      0.53        22\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       1.00      0.14      0.25         7\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       1.00      0.20      0.33         5\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         3\n",
      "         208       1.00      0.50      0.67         2\n",
      "         209       0.50      0.40      0.44        10\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       1.00      0.70      0.82        20\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.78      1.00      0.88         7\n",
      "         216       0.24      0.33      0.28        12\n",
      "         217       0.20      0.33      0.25         3\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.64      0.47      0.54        15\n",
      "         226       0.00      0.00      0.00         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      0.50      0.67         2\n",
      "         230       0.78      0.70      0.74        10\n",
      "         231       0.75      0.27      0.40        11\n",
      "         232       0.00      0.00      0.00         2\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.58      0.41      0.48        17\n",
      "         235       0.78      0.64      0.70        11\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         8\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.66      0.45      0.54       447\n",
      "   macro avg       0.13      0.09      0.10       447\n",
      "weighted avg       0.61      0.45      0.50       447\n",
      " samples avg       0.45      0.45      0.45       447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize a base classifier (Random Forest in this case)\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# Initialize the Classifier Chain classifier with the base classifier\n",
    "classifier = ClassifierChain(classifier=base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce63e76",
   "metadata": {},
   "source": [
    "#### \tProbabilistic graphical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint inference of multiple diagnoses (Bayesian Networks or Markov Random Fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "608f89e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 2s 15ms/step - loss: 0.6546 - accuracy: 0.0365 - val_loss: 0.5472 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.0390 - val_loss: 0.4033 - val_accuracy: 0.0130\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.0471 - val_loss: 0.3242 - val_accuracy: 0.0227\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2801 - accuracy: 0.0568 - val_loss: 0.2788 - val_accuracy: 0.0227\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.0609 - val_loss: 0.2510 - val_accuracy: 0.0227\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2067 - accuracy: 0.0633 - val_loss: 0.2329 - val_accuracy: 0.0292\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.1848 - accuracy: 0.0739 - val_loss: 0.2208 - val_accuracy: 0.0292\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.0828 - val_loss: 0.2117 - val_accuracy: 0.0260\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.0893 - val_loss: 0.2052 - val_accuracy: 0.0292\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.0950 - val_loss: 0.2004 - val_accuracy: 0.0325\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 1.0000\n",
      "Accuracy: [0.2706722915172577, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the Bernoulli Naive Bayes model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(277,)),      # Input layer with 277 features\n",
    "    tf.keras.layers.Dense(240, activation='sigmoid')  # Output layer with 240 units (one for each label)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = model.evaluate(X_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291861e",
   "metadata": {},
   "source": [
    "#### K nearest radius neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b966b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelPowerset(classifier=RadiusNeighborsClassifier(radius=13),\n",
       "              require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelPowerset</label><div class=\"sk-toggleable__content\"><pre>LabelPowerset(classifier=RadiusNeighborsClassifier(radius=13),\n",
       "              require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RadiusNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>RadiusNeighborsClassifier(radius=13)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RadiusNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>RadiusNeighborsClassifier(radius=13)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelPowerset(classifier=RadiusNeighborsClassifier(radius=13),\n",
       "              require_dense=[True, True])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "# Initialize the RadiusNeighborsClassifier\n",
    "radius_classifier = RadiusNeighborsClassifier(radius=13) # Any smaller radius and no neighbours is found\n",
    "\n",
    "# Wrap the RadiusNeighborsClassifier with LabelPowerset for multi-label classification\n",
    "classifier = LabelPowerset(radius_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5a49602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "835754df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         9\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.10      1.00      0.18        33\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         5\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       0.00      0.00      0.00         4\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         7\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         2\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.00      0.00      0.00         5\n",
      "          61       0.00      0.00      0.00         7\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.11      1.00      0.19        35\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         4\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         5\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00        12\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.27      0.17      0.21        41\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         7\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         7\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         3\n",
      "         106       0.00      0.00      0.00         8\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         3\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00        13\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00        12\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         4\n",
      "         147       0.00      0.00      0.00         3\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.24      0.26      0.25        31\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00        15\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         6\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.00      0.00      0.00         3\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         2\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         5\n",
      "         172       0.14      0.12      0.13         8\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         4\n",
      "         183       0.00      0.00      0.00         8\n",
      "         184       0.00      0.00      0.00         2\n",
      "         185       0.00      0.00      0.00         9\n",
      "         186       0.17      0.05      0.07        21\n",
      "         187       0.00      0.00      0.00        48\n",
      "         188       0.00      0.00      0.00        12\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         4\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         7\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         2\n",
      "         208       0.00      0.00      0.00         6\n",
      "         209       0.00      0.00      0.00         9\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.17      0.05      0.07        21\n",
      "         212       0.00      0.00      0.00         6\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00        13\n",
      "         216       0.00      0.00      0.00        29\n",
      "         217       0.00      0.00      0.00         4\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00        14\n",
      "         226       0.00      0.00      0.00         3\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         6\n",
      "         230       0.00      0.00      0.00        13\n",
      "         231       0.00      0.00      0.00         7\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.00      0.00      0.00        15\n",
      "         235       0.00      0.00      0.00        13\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.11      0.12      0.11       745\n",
      "   macro avg       0.00      0.01      0.00       745\n",
      "weighted avg       0.05      0.12      0.04       745\n",
      " samples avg       0.11      0.11      0.11       745\n",
      "\n",
      "Accuracy: 0.11140583554376658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19928725",
   "metadata": {},
   "source": [
    "#### Adaboost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "90de5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3964757709251101\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.60      0.75        15\n",
      "           2       0.89      0.73      0.80        11\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.80      0.80      0.80         5\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.50      0.67      0.57         3\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.50      0.67      0.57         3\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.89      0.67      0.76        24\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.67      0.50      0.57         4\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       1.00      1.00      1.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.94      0.62      0.75        24\n",
      "          71       0.00      0.00      0.00         3\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       1.00      1.00      1.00         1\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       1.00      0.40      0.57         5\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         3\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       1.00      0.67      0.80         3\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.73      0.52      0.60        31\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.50      0.60      0.55         5\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       1.00      1.00      1.00         3\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       1.00      0.67      0.80         3\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       1.00      1.00      1.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         3\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.90      0.75      0.82        24\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.50      0.50      0.50         4\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       1.00      0.25      0.40         4\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.50      0.50      0.50         4\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       1.00      1.00      1.00         3\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       1.00      1.00      1.00         3\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       1.00      0.17      0.29         6\n",
      "         184       0.00      0.00      0.00         3\n",
      "         185       0.67      0.40      0.50        10\n",
      "         186       1.00      0.75      0.86        20\n",
      "         187       0.73      0.36      0.48        22\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.75      0.43      0.55         7\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.50      0.20      0.29         5\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       1.00      1.00      1.00         1\n",
      "         207       0.00      0.00      0.00         3\n",
      "         208       1.00      0.50      0.67         2\n",
      "         209       0.67      0.40      0.50        10\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       1.00      0.75      0.86        20\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.88      1.00      0.93         7\n",
      "         216       0.50      0.17      0.25        12\n",
      "         217       0.67      0.67      0.67         3\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.71      0.33      0.45        15\n",
      "         226       1.00      1.00      1.00         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      0.50      0.67         2\n",
      "         230       0.88      0.70      0.78        10\n",
      "         231       0.50      0.09      0.15        11\n",
      "         232       0.00      0.00      0.00         2\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.73      0.47      0.57        17\n",
      "         235       0.70      0.64      0.67        11\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         8\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.73      0.49      0.58       447\n",
      "   macro avg       0.17      0.14      0.15       447\n",
      "weighted avg       0.70      0.49      0.56       447\n",
      " samples avg       0.51      0.48      0.49       447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Initialize the base classifier (Gradient Boosting Classifier)\n",
    "base_classifier = AdaBoostClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "815c3acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.25      0.36      0.30        11\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.14      0.80      0.24         5\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.01      1.00      0.03         3\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.01      1.00      0.03         3\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.12      0.08      0.10        24\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       1.00      1.00      1.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.12      0.58      0.20        24\n",
      "          71       0.00      0.00      0.00         3\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         3\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         5\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         3\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       1.00      0.67      0.80         3\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.51      0.65      0.57        31\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.20      0.40      0.27         5\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         3\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.40      0.67      0.50         3\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         3\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.12      0.67      0.20         3\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.12      0.62      0.20        24\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.02      0.75      0.04         4\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         4\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.07      0.25      0.11         4\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         3\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.40      0.67      0.50         3\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       0.02      1.00      0.05         3\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         6\n",
      "         184       0.00      0.00      0.00         3\n",
      "         185       0.30      0.30      0.30        10\n",
      "         186       0.57      0.60      0.59        20\n",
      "         187       1.00      0.18      0.31        22\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.05      0.14      0.08         7\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.40      0.40      0.40         5\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         3\n",
      "         208       1.00      1.00      1.00         2\n",
      "         209       0.30      0.30      0.30        10\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.57      0.60      0.59        20\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.40      0.86      0.55         7\n",
      "         216       0.20      0.17      0.18        12\n",
      "         217       0.00      0.00      0.00         3\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.15      0.80      0.26        15\n",
      "         226       0.03      0.50      0.06         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      1.00      1.00         2\n",
      "         230       0.04      0.10      0.06        10\n",
      "         231       0.00      0.00      0.00        11\n",
      "         232       0.00      0.00      0.00         2\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.67      0.12      0.20        17\n",
      "         235       0.00      0.00      0.00        11\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         8\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.33      0.15       447\n",
      "   macro avg       0.05      0.08      0.05       447\n",
      "weighted avg       0.25      0.33      0.23       447\n",
      " samples avg       0.09      0.33      0.14       447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Initialize the base classifier (Gradient Boosting Classifier)\n",
    "base_classifier = AdaBoostClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_multilabel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2bae5",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "320000b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_multilabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da425d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c115797c",
   "metadata": {},
   "source": [
    "### emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "3a2c0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27540, 650)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "d58acbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27540, 240)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "475cb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"emar_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7da4b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b830d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f193981",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280f629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b378cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1ff7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11ca6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02ce9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4726d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc6778f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c343439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6844</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6876 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      14   20   21   22   23   24   25   26   27   39   ...  950  951  952  \\\n",
       "0       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "19      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "21      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "22      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "23      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "6845    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6844    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6874    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6858    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "6875    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "      956  957  981  982  983  987  988  \n",
       "0       0    0    0    0    0    0    0  \n",
       "19      0    0    0    0    0    0    0  \n",
       "21      0    0    0    0    0    0    0  \n",
       "22      0    0    0    0    0    0    0  \n",
       "23      0    0    0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "6845    0    0    0    0    0    0    0  \n",
       "6844    0    0    0    0    0    0    0  \n",
       "6874    0    0    0    0    0    0    0  \n",
       "6858    0    0    0    0    0    0    0  \n",
       "6875    0    0    0    0    0    0    0  \n",
       "\n",
       "[6876 rows x 240 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da98e7",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "606e8c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3261090909090909\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.80      0.32      0.45       111\n",
      "           2       0.73      0.26      0.38        74\n",
      "           3       0.89      0.39      0.54        62\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.88      0.30      0.45       117\n",
      "           6       0.84      0.25      0.39       122\n",
      "           7       0.60      0.33      0.43        18\n",
      "           8       0.83      0.21      0.33        24\n",
      "           9       0.67      0.20      0.31        10\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.67      0.29      0.40         7\n",
      "          13       0.94      0.27      0.42       115\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.67      0.17      0.27        12\n",
      "          17       0.70      0.29      0.41        24\n",
      "          18       0.70      0.29      0.41        24\n",
      "          19       0.67      0.29      0.40         7\n",
      "          20       0.87      0.27      0.41       101\n",
      "          21       1.00      0.57      0.73        14\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.67      0.17      0.27        12\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.77      0.32      0.45        31\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.77      0.50      0.61       118\n",
      "          28       0.74      0.39      0.51       571\n",
      "          29       0.67      0.42      0.51        48\n",
      "          30       0.60      0.24      0.35        37\n",
      "          31       0.33      0.07      0.12        14\n",
      "          32       1.00      0.07      0.12        15\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.77      0.42      0.55        40\n",
      "          35       0.79      0.61      0.69       131\n",
      "          36       0.58      0.48      0.53        29\n",
      "          37       0.86      0.41      0.56        29\n",
      "          38       0.79      0.44      0.56        71\n",
      "          39       0.77      0.32      0.45        31\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.67      0.18      0.29        33\n",
      "          42       0.73      0.35      0.47       141\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.68      0.22      0.34        58\n",
      "          45       0.64      0.11      0.19       185\n",
      "          46       0.82      0.47      0.60        30\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.61      0.31      0.42        35\n",
      "          49       0.62      0.11      0.19        71\n",
      "          50       0.33      0.07      0.12        14\n",
      "          51       0.77      0.42      0.55        40\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.69      0.48      0.56        23\n",
      "          54       1.00      0.07      0.12        15\n",
      "          55       0.86      0.41      0.56        29\n",
      "          56       0.67      0.18      0.29        22\n",
      "          57       0.73      0.33      0.45        73\n",
      "          58       0.73      0.23      0.35        47\n",
      "          59       0.43      0.13      0.20        23\n",
      "          60       0.79      0.61      0.69       131\n",
      "          61       0.92      0.27      0.41       494\n",
      "          62       0.81      0.21      0.33        62\n",
      "          63       1.00      0.18      0.31        38\n",
      "          64       0.17      0.09      0.12        11\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.78      0.31      0.44        81\n",
      "          68       0.88      0.54      0.67        41\n",
      "          69       0.00      0.00      0.00        15\n",
      "          70       0.77      0.37      0.50       676\n",
      "          71       0.43      0.20      0.27        15\n",
      "          72       0.67      0.18      0.29        33\n",
      "          73       0.54      0.17      0.26        81\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.77      0.46      0.58       168\n",
      "          76       0.63      0.27      0.38        44\n",
      "          77       0.90      0.31      0.46        84\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       1.00      0.67      0.80         3\n",
      "          80       0.63      0.35      0.45        55\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.71      0.26      0.38        46\n",
      "          83       0.85      0.09      0.16       121\n",
      "          84       0.58      0.17      0.27        64\n",
      "          85       0.94      0.37      0.53        46\n",
      "          86       0.85      0.86      0.85        51\n",
      "          87       0.57      0.36      0.44        45\n",
      "          88       0.62      0.16      0.25        63\n",
      "          89       0.71      0.34      0.46       106\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.50      0.67      0.57         3\n",
      "          92       0.82      1.00      0.90        14\n",
      "          93       0.69      0.48      0.56        23\n",
      "          94       0.88      0.40      0.55       109\n",
      "          95       0.70      0.23      0.35        61\n",
      "          96       0.50      0.08      0.14        25\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.55      0.33      0.41        18\n",
      "          99       0.83      0.37      0.51       368\n",
      "         100       0.62      0.11      0.19        71\n",
      "         101       0.50      0.30      0.37        10\n",
      "         102       0.20      0.06      0.09        17\n",
      "         103       0.83      0.56      0.67        27\n",
      "         104       0.82      0.80      0.81        56\n",
      "         105       0.88      0.25      0.39        55\n",
      "         106       0.68      0.21      0.33        70\n",
      "         107       0.90      0.36      0.51       347\n",
      "         108       0.75      0.31      0.43       173\n",
      "         109       0.69      0.39      0.50        23\n",
      "         110       1.00      0.18      0.31        38\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.17      0.09      0.12        11\n",
      "         113       0.85      0.38      0.52        74\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.71      0.20      0.31       145\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       1.00      0.21      0.35        28\n",
      "         118       0.78      0.39      0.52        18\n",
      "         119       0.54      0.23      0.32        31\n",
      "         120       0.83      0.46      0.59        76\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.48      0.22      0.30        46\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.79      0.70      0.74        37\n",
      "         125       0.67      0.13      0.22        30\n",
      "         126       0.90      0.31      0.46        84\n",
      "         127       0.63      0.27      0.38        44\n",
      "         128       1.00      0.67      0.80         3\n",
      "         129       0.77      0.46      0.58       168\n",
      "         130       0.84      0.74      0.79       125\n",
      "         131       0.71      0.34      0.46       106\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.89      0.37      0.52        46\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.55      0.19      0.28        95\n",
      "         136       0.88      0.45      0.60        99\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.84      0.90      0.87        48\n",
      "         139       1.00      0.25      0.40        12\n",
      "         140       0.38      0.18      0.24        17\n",
      "         141       0.71      0.21      0.32        24\n",
      "         142       0.67      0.75      0.71         8\n",
      "         143       0.82      1.00      0.90        14\n",
      "         144       0.77      0.36      0.49        47\n",
      "         145       0.50      0.25      0.33        24\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.50      0.08      0.14        25\n",
      "         148       0.55      0.33      0.41        18\n",
      "         149       0.72      0.26      0.38       282\n",
      "         150       0.82      0.26      0.39        35\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.82      0.80      0.81        56\n",
      "         156       0.85      0.71      0.78       124\n",
      "         157       0.57      0.21      0.31        19\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.75      0.46      0.57        26\n",
      "         160       0.76      0.27      0.40        48\n",
      "         161       0.54      0.23      0.32        31\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.95      0.90      0.92        61\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.60      0.23      0.34        64\n",
      "         166       0.78      0.39      0.52        18\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       1.00      0.25      0.40        12\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.84      0.74      0.79       125\n",
      "         172       0.91      0.53      0.67        19\n",
      "         173       0.87      0.32      0.46       196\n",
      "         174       0.82      0.26      0.39        35\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.94      0.46      0.62        35\n",
      "         177       1.00      0.14      0.25         7\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       1.00      0.33      0.50         3\n",
      "         180       0.83      0.57      0.68        42\n",
      "         181       0.93      0.67      0.78       114\n",
      "         182       0.33      0.40      0.36         5\n",
      "         183       0.77      0.45      0.57       127\n",
      "         184       0.89      0.75      0.81       154\n",
      "         185       0.63      0.13      0.22       144\n",
      "         186       0.84      0.87      0.86       142\n",
      "         187       0.78      0.20      0.31       331\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.33      0.12      0.18         8\n",
      "         190       0.90      0.39      0.55        46\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.88      0.71      0.79        31\n",
      "         195       1.00      0.44      0.62         9\n",
      "         196       0.50      0.12      0.20         8\n",
      "         197       0.00      0.00      0.00         1\n",
      "         198       0.80      0.41      0.55       292\n",
      "         199       0.94      0.46      0.62        35\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       1.00      0.33      0.50         3\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.77      0.45      0.57       127\n",
      "         207       0.89      0.75      0.81       154\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.63      0.13      0.22       144\n",
      "         210       0.90      0.47      0.62        19\n",
      "         211       0.84      0.87      0.86       142\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.33      0.12      0.18         8\n",
      "         214       0.90      0.39      0.55        46\n",
      "         215       0.82      0.56      0.67        32\n",
      "         216       0.60      0.15      0.24       190\n",
      "         217       0.71      0.30      0.42        90\n",
      "         218       0.88      0.71      0.79        31\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       1.00      0.44      0.62         9\n",
      "         222       0.00      0.00      0.00         1\n",
      "         223       0.50      0.12      0.20         8\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         0\n",
      "         226       0.71      0.28      0.40       163\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.91      0.33      0.49        90\n",
      "         231       0.89      0.34      0.50       662\n",
      "         232       0.67      0.08      0.14        25\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.70      0.23      0.34       115\n",
      "         235       0.96      0.43      0.59        61\n",
      "         236       0.88      0.60      0.71       144\n",
      "         237       0.62      0.17      0.26        30\n",
      "         238       0.52      0.26      0.35        88\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.79      0.37      0.50     13510\n",
      "   macro avg       0.54      0.26      0.33     13510\n",
      "weighted avg       0.78      0.37      0.48     13510\n",
      " samples avg       0.39      0.37      0.38     13510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d7ff661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.005964242424242424\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2bf34",
   "metadata": {},
   "source": [
    "### Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "08a759fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 44)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "86495245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 240)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "aba4d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"admissions_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"admissions_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "271050a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>ed_duration</th>\n",
       "      <th>admission_type_AMBULATORY OBSERVATION</th>\n",
       "      <th>admission_type_DIRECT EMER.</th>\n",
       "      <th>admission_type_DIRECT OBSERVATION</th>\n",
       "      <th>admission_type_ELECTIVE</th>\n",
       "      <th>admission_type_EU OBSERVATION</th>\n",
       "      <th>admission_type_EW EMER.</th>\n",
       "      <th>admission_type_OBSERVATION ADMIT</th>\n",
       "      <th>admission_type_SURGICAL SAME DAY ADMISSION</th>\n",
       "      <th>...</th>\n",
       "      <th>race_HISPANIC/LATINO - PUERTO RICAN</th>\n",
       "      <th>race_HISPANIC/LATINO - SALVADORAN</th>\n",
       "      <th>race_OTHER</th>\n",
       "      <th>race_PATIENT DECLINED TO ANSWER</th>\n",
       "      <th>race_PORTUGUESE</th>\n",
       "      <th>race_UNABLE TO OBTAIN</th>\n",
       "      <th>race_UNKNOWN</th>\n",
       "      <th>race_WHITE</th>\n",
       "      <th>race_WHITE - BRAZILIAN</th>\n",
       "      <th>race_WHITE - OTHER EUROPEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24256866</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26924951</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23403708</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22733922</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24928679</td>\n",
       "      <td>0 days 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id      ed_duration  admission_type_AMBULATORY OBSERVATION  \\\n",
       "0  24256866  0 days 00:00:00                                      0   \n",
       "1  26924951  0 days 00:00:00                                      0   \n",
       "2  23403708  0 days 00:00:00                                      0   \n",
       "3  22733922  0 days 00:00:00                                      0   \n",
       "4  24928679  0 days 10:00:00                                      0   \n",
       "\n",
       "   admission_type_DIRECT EMER.  admission_type_DIRECT OBSERVATION  \\\n",
       "0                            0                                  0   \n",
       "1                            0                                  0   \n",
       "2                            0                                  0   \n",
       "3                            0                                  0   \n",
       "4                            0                                  0   \n",
       "\n",
       "   admission_type_ELECTIVE  admission_type_EU OBSERVATION  \\\n",
       "0                        0                              0   \n",
       "1                        0                              0   \n",
       "2                        0                              0   \n",
       "3                        0                              0   \n",
       "4                        0                              0   \n",
       "\n",
       "   admission_type_EW EMER.  admission_type_OBSERVATION ADMIT  \\\n",
       "0                        0                                 0   \n",
       "1                        0                                 0   \n",
       "2                        0                                 0   \n",
       "3                        0                                 0   \n",
       "4                        0                                 1   \n",
       "\n",
       "   admission_type_SURGICAL SAME DAY ADMISSION  ...  \\\n",
       "0                                           0  ...   \n",
       "1                                           1  ...   \n",
       "2                                           1  ...   \n",
       "3                                           0  ...   \n",
       "4                                           0  ...   \n",
       "\n",
       "   race_HISPANIC/LATINO - PUERTO RICAN  race_HISPANIC/LATINO - SALVADORAN  \\\n",
       "0                                    0                                  0   \n",
       "1                                    0                                  0   \n",
       "2                                    0                                  0   \n",
       "3                                    0                                  0   \n",
       "4                                    0                                  0   \n",
       "\n",
       "   race_OTHER  race_PATIENT DECLINED TO ANSWER  race_PORTUGUESE  \\\n",
       "0           0                                0                0   \n",
       "1           0                                0                0   \n",
       "2           0                                0                0   \n",
       "3           0                                0                0   \n",
       "4           0                                0                0   \n",
       "\n",
       "   race_UNABLE TO OBTAIN  race_UNKNOWN  race_WHITE  race_WHITE - BRAZILIAN  \\\n",
       "0                      0             1           0                       0   \n",
       "1                      1             0           0                       0   \n",
       "2                      0             0           1                       0   \n",
       "3                      0             0           0                       0   \n",
       "4                      0             0           0                       0   \n",
       "\n",
       "   race_WHITE - OTHER EUROPEAN  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "78e6314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['ed_duration']= X_train['ed_duration'].apply(convert_to_days)\n",
    "X_test['ed_duration']= X_test['ed_duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "5be1715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "09c152e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "eb42467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "43466fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "feb2faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "79570b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "2d5e8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "37713276",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4cc0e",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "6c677d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [12:08<00:00,  7.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "587c69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.50      1.00      0.67         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         1\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.00      0.00      0.00         2\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.00      0.00      0.00         2\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         2\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       0.00      0.00      0.00         5\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         1\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         0\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         2\n",
      "         216       0.50      0.50      0.50         2\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         0\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         0\n",
      "         239       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.20      0.02      0.04        94\n",
      "   macro avg       0.00      0.01      0.00        94\n",
      "weighted avg       0.02      0.02      0.02        94\n",
      " samples avg       0.04      0.02      0.03        94\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "d7114f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.008680555555555556\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b6f9e",
   "metadata": {},
   "source": [
    "### hcpcsevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "db85b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 13)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "268c6ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 1472)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4832ea5",
   "metadata": {},
   "source": [
    "For some reason, none of the hadm_ids from this df appear in the drgcodes table so using diagnoses instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "71dad259",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"hcpcsevents_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"hcpcsevents_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "a73e49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to integers\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "5e9b1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['admittime'])\n",
    "X_test = X_test.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "22bfec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_diagnoses[df_diagnoses['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_diagnoses[df_diagnoses['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "ce51f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_diagnoses[df_diagnoses['hadm_id']==29654498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "ef29ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "6d65e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "ae7b9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "20734be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>00845</th>\n",
       "      <th>0088</th>\n",
       "      <th>0380</th>\n",
       "      <th>0383</th>\n",
       "      <th>03842</th>\n",
       "      <th>03843</th>\n",
       "      <th>03849</th>\n",
       "      <th>0388</th>\n",
       "      <th>0389</th>\n",
       "      <th>...</th>\n",
       "      <th>Z95810</th>\n",
       "      <th>Z95820</th>\n",
       "      <th>Z961</th>\n",
       "      <th>Z96651</th>\n",
       "      <th>Z980</th>\n",
       "      <th>Z981</th>\n",
       "      <th>Z9884</th>\n",
       "      <th>Z9911</th>\n",
       "      <th>Z992</th>\n",
       "      <th>Z9981</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20282368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20457729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20846853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20900955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21039249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21039249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22228639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22380825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22416954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22502504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22607171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22896692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22999601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23143086</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23199774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23720373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24096336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25166559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25559382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25559382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25561728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25797028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26173805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26549334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26722126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26739864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26739864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27125816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27125816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27494880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27504040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>27504040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>27670224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>27962747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>28477649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>28543425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28676446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>28697806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>28778757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>28778757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>29176490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>29176490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29176490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>29654498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>29654498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>29820177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>29820177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>29820177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hadm_id  00845  0088  0380  0383  03842  03843  03849  0388  0389  ...  \\\n",
       "0   20282368      0     0     0     0      0      0      0     0     0  ...   \n",
       "1   20457729      0     0     0     0      0      0      0     0     0  ...   \n",
       "2   20846853      0     0     0     0      0      0      0     0     0  ...   \n",
       "3   20900955      0     0     0     0      0      0      0     0     0  ...   \n",
       "4   21039249      0     0     0     0      0      0      0     0     0  ...   \n",
       "5   21039249      0     0     0     0      0      0      0     0     0  ...   \n",
       "6   22228639      0     0     0     0      0      0      0     0     0  ...   \n",
       "7   22380825      0     0     0     0      0      0      0     0     0  ...   \n",
       "8   22416954      0     0     0     0      0      0      0     0     0  ...   \n",
       "9   22502504      0     0     0     0      0      0      0     0     0  ...   \n",
       "10  22607171      0     0     0     0      0      0      0     0     0  ...   \n",
       "11  22896692      0     0     0     0      0      0      0     0     0  ...   \n",
       "12  22999601      0     0     0     0      0      0      0     0     0  ...   \n",
       "13  23143086      0     0     0     0      0      0      0     0     0  ...   \n",
       "14  23199774      0     0     0     0      0      0      0     0     0  ...   \n",
       "15  23720373      0     0     0     0      0      0      0     0     0  ...   \n",
       "16  24096336      0     0     0     0      0      0      0     0     0  ...   \n",
       "17  25166559      0     0     0     0      0      0      0     0     0  ...   \n",
       "18  25559382      0     0     0     0      0      0      0     0     0  ...   \n",
       "19  25559382      0     0     0     0      0      0      0     0     0  ...   \n",
       "20  25561728      0     0     0     0      0      0      0     0     0  ...   \n",
       "21  25797028      0     0     0     0      0      0      0     0     0  ...   \n",
       "22  26173805      0     0     0     0      0      0      0     0     0  ...   \n",
       "23  26549334      0     0     0     0      0      0      0     0     0  ...   \n",
       "24  26722126      0     0     0     0      0      0      0     0     0  ...   \n",
       "25  26739864      0     0     0     0      0      0      0     0     0  ...   \n",
       "26  26739864      0     0     0     0      0      0      0     0     0  ...   \n",
       "27  27125816      0     0     0     0      0      0      0     0     0  ...   \n",
       "28  27125816      0     0     0     0      0      0      0     0     0  ...   \n",
       "29  27494880      0     0     0     0      0      0      0     0     0  ...   \n",
       "30  27504040      0     0     0     0      0      0      0     0     0  ...   \n",
       "31  27504040      0     0     0     0      0      0      0     0     0  ...   \n",
       "32  27670224      0     0     0     0      0      0      0     0     0  ...   \n",
       "33  27962747      0     0     0     0      0      0      0     0     0  ...   \n",
       "34  28477649      0     0     0     0      0      0      0     0     0  ...   \n",
       "35  28543425      0     0     0     0      0      0      0     0     0  ...   \n",
       "36  28676446      0     0     0     0      0      0      0     0     0  ...   \n",
       "37  28697806      0     0     0     0      0      0      0     0     0  ...   \n",
       "38  28778757      0     0     0     0      0      0      0     0     0  ...   \n",
       "39  28778757      0     0     0     0      0      0      0     0     0  ...   \n",
       "40  29176490      0     0     0     0      0      0      0     0     0  ...   \n",
       "41  29176490      0     0     0     0      0      0      0     0     0  ...   \n",
       "42  29176490      0     0     0     0      0      0      0     0     0  ...   \n",
       "43  29654498      0     0     0     0      0      0      0     0     0  ...   \n",
       "44  29654498      0     0     0     0      0      0      0     0     0  ...   \n",
       "45  29820177      0     0     0     0      0      0      0     0     0  ...   \n",
       "46  29820177      0     0     0     0      0      0      0     0     0  ...   \n",
       "47  29820177      0     0     0     0      0      0      0     0     0  ...   \n",
       "\n",
       "    Z95810  Z95820  Z961  Z96651  Z980  Z981  Z9884  Z9911  Z992  Z9981  \n",
       "0        0       0     0       0     0     0      0      0     0      0  \n",
       "1        0       1     0       0     0     0      0      0     0      0  \n",
       "2        0       0     0       0     0     0      0      0     0      0  \n",
       "3        0       0     0       0     0     0      0      0     0      0  \n",
       "4        0       0     0       0     0     0      0      0     0      0  \n",
       "5        0       0     0       0     0     0      0      0     0      0  \n",
       "6        0       0     0       0     0     0      0      0     0      0  \n",
       "7        0       0     0       0     0     0      0      0     0      0  \n",
       "8        0       0     0       0     0     0      0      0     1      0  \n",
       "9        0       0     0       0     0     0      0      0     0      0  \n",
       "10       0       0     0       0     0     0      0      0     0      0  \n",
       "11       0       0     0       0     0     0      0      0     0      0  \n",
       "12       0       0     0       0     0     0      0      0     1      0  \n",
       "13       0       0     0       0     0     0      0      0     0      0  \n",
       "14       0       0     0       0     0     0      0      0     0      0  \n",
       "15       0       0     0       0     0     0      0      0     0      0  \n",
       "16       0       0     0       0     0     0      0      0     0      0  \n",
       "17       0       0     0       0     0     0      0      0     0      0  \n",
       "18       0       0     0       0     0     0      0      0     0      0  \n",
       "19       0       0     0       0     0     0      0      0     0      0  \n",
       "20       0       0     0       0     0     0      0      0     0      0  \n",
       "21       0       0     0       0     0     0      0      0     0      0  \n",
       "22       0       0     0       0     0     0      0      0     0      0  \n",
       "23       0       0     1       0     0     0      0      0     0      0  \n",
       "24       0       0     0       0     0     0      0      0     0      0  \n",
       "25       0       0     0       0     0     0      0      0     0      0  \n",
       "26       0       0     0       0     0     0      0      0     0      0  \n",
       "27       0       0     0       0     0     0      0      0     0      0  \n",
       "28       0       0     0       0     0     0      0      0     0      0  \n",
       "29       0       0     0       0     0     0      0      0     0      0  \n",
       "30       0       0     0       0     0     0      0      0     1      0  \n",
       "31       0       0     0       0     0     0      0      0     1      0  \n",
       "32       0       0     0       0     0     0      0      0     0      0  \n",
       "33       0       0     0       0     0     0      0      0     0      0  \n",
       "34       0       0     0       0     0     0      0      0     0      0  \n",
       "35       0       0     0       0     0     0      0      0     0      0  \n",
       "36       0       0     0       0     0     0      0      0     0      0  \n",
       "37       0       0     0       0     0     0      0      0     0      0  \n",
       "38       0       0     0       0     0     0      0      0     0      0  \n",
       "39       0       0     0       0     0     0      0      0     0      0  \n",
       "40       0       0     0       0     0     0      0      0     0      0  \n",
       "41       0       0     0       0     0     0      0      0     0      0  \n",
       "42       0       0     0       0     0     0      0      0     0      0  \n",
       "43       0       0     0       0     0     0      0      0     0      0  \n",
       "44       0       0     0       0     0     0      0      0     0      0  \n",
       "45       0       0     0       0     0     0      0      0     0      0  \n",
       "46       0       0     0       0     0     0      0      0     0      0  \n",
       "47       0       0     0       0     0     0      0      0     0      0  \n",
       "\n",
       "[48 rows x 1473 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "5cb6a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "50ed2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "7dcb16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "d16b5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "1d783beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 13 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "f12be384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "[0.43713458 0.24268566 0.10206493 0.05400726 0.03833628 0.02801852\n",
      " 0.02066158 0.01412175 0.01418972]\n",
      "\n",
      " Amount of original variance conserved: 0.9512202809282059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 9\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "X_train = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "5176fa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "[5.01651929e-01 1.96707388e-01 1.09078544e-01 4.81326185e-02\n",
      " 4.55111394e-02 4.61980609e-02 4.72757336e-02 5.44458714e-03\n",
      " 1.09168733e-33]\n",
      "\n",
      " Amount of original variance conserved: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Number of desired features (components)\n",
    "n_components = 9\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_test)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb10a7d",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e075b",
   "metadata": {},
   "source": [
    "Don't run it again it took ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "9d22db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:00:23<00:00, 36.23s/it]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "e856103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:29<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.50      0.50      0.50         2\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         4\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         2\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         2\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       0.00      0.00      0.00         0\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         0\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         3\n",
      "         209       0.00      0.00      0.00         0\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         1\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         0\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       0.00      0.00      0.00         0\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         0\n",
      "         235       0.00      0.00      0.00         0\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         0\n",
      "         239       0.00      0.00      0.00         0\n",
      "         240       0.00      0.00      0.00         0\n",
      "         241       0.00      0.00      0.00         0\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       0.00      0.00      0.00         0\n",
      "         244       0.00      0.00      0.00         0\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.00      0.00      0.00         0\n",
      "         247       0.00      0.00      0.00         0\n",
      "         248       0.00      0.00      0.00         0\n",
      "         249       0.00      0.00      0.00         0\n",
      "         250       0.00      0.00      0.00         0\n",
      "         251       0.00      0.00      0.00         0\n",
      "         252       0.00      0.00      0.00         0\n",
      "         253       0.00      0.00      0.00         0\n",
      "         254       0.00      0.00      0.00         0\n",
      "         255       0.00      0.00      0.00         0\n",
      "         256       0.00      0.00      0.00         0\n",
      "         257       0.00      0.00      0.00         0\n",
      "         258       0.00      0.00      0.00         0\n",
      "         259       0.00      0.00      0.00         0\n",
      "         260       0.00      0.00      0.00         0\n",
      "         261       0.00      0.00      0.00         0\n",
      "         262       0.00      0.00      0.00         0\n",
      "         263       0.00      0.00      0.00         0\n",
      "         264       0.00      0.00      0.00         0\n",
      "         265       0.00      0.00      0.00         0\n",
      "         266       0.00      0.00      0.00         0\n",
      "         267       0.00      0.00      0.00         0\n",
      "         268       0.00      0.00      0.00         0\n",
      "         269       0.00      0.00      0.00         0\n",
      "         270       0.00      0.00      0.00         0\n",
      "         271       0.00      0.00      0.00         0\n",
      "         272       0.00      0.00      0.00         0\n",
      "         273       0.00      0.00      0.00         0\n",
      "         274       0.00      0.00      0.00         0\n",
      "         275       0.00      0.00      0.00         0\n",
      "         276       0.00      0.00      0.00         0\n",
      "         277       0.00      0.00      0.00         0\n",
      "         278       0.00      0.00      0.00         0\n",
      "         279       0.00      0.00      0.00         0\n",
      "         280       0.00      0.00      0.00         0\n",
      "         281       0.00      0.00      0.00         0\n",
      "         282       0.00      0.00      0.00         0\n",
      "         283       0.00      0.00      0.00         0\n",
      "         284       0.00      0.00      0.00         0\n",
      "         285       0.00      0.00      0.00         0\n",
      "         286       0.00      0.00      0.00         0\n",
      "         287       0.00      0.00      0.00         0\n",
      "         288       0.00      0.00      0.00         0\n",
      "         289       0.00      0.00      0.00         0\n",
      "         290       0.00      0.00      0.00         0\n",
      "         291       0.00      0.00      0.00         0\n",
      "         292       0.00      0.00      0.00         0\n",
      "         293       0.00      0.00      0.00         0\n",
      "         294       0.00      0.00      0.00         0\n",
      "         295       0.00      0.00      0.00         0\n",
      "         296       0.00      0.00      0.00         0\n",
      "         297       0.00      0.00      0.00         0\n",
      "         298       0.00      0.00      0.00         0\n",
      "         299       0.00      0.00      0.00         0\n",
      "         300       0.00      0.00      0.00         0\n",
      "         301       0.00      0.00      0.00         0\n",
      "         302       0.00      0.00      0.00         1\n",
      "         303       0.00      0.00      0.00         0\n",
      "         304       0.00      0.00      0.00         0\n",
      "         305       0.00      0.00      0.00         0\n",
      "         306       0.00      0.00      0.00         0\n",
      "         307       0.00      0.00      0.00         0\n",
      "         308       0.00      0.00      0.00         0\n",
      "         309       0.00      0.00      0.00         0\n",
      "         310       0.00      0.00      0.00         0\n",
      "         311       0.00      0.00      0.00         0\n",
      "         312       0.00      0.00      0.00         0\n",
      "         313       0.00      0.00      0.00         0\n",
      "         314       0.00      0.00      0.00         0\n",
      "         315       0.00      0.00      0.00         0\n",
      "         316       0.00      0.00      0.00         0\n",
      "         317       0.00      0.00      0.00         0\n",
      "         318       0.00      0.00      0.00         0\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.00      0.00      0.00         0\n",
      "         321       0.00      0.00      0.00         0\n",
      "         322       0.00      0.00      0.00         0\n",
      "         323       0.00      0.00      0.00         0\n",
      "         324       0.00      0.00      0.00         1\n",
      "         325       0.00      0.00      0.00         0\n",
      "         326       0.00      0.00      0.00         0\n",
      "         327       0.00      0.00      0.00         0\n",
      "         328       0.00      0.00      0.00         0\n",
      "         329       0.00      0.00      0.00         0\n",
      "         330       0.00      0.00      0.00         0\n",
      "         331       0.00      0.00      0.00         0\n",
      "         332       0.00      0.00      0.00         0\n",
      "         333       0.00      0.00      0.00         0\n",
      "         334       0.00      0.00      0.00         0\n",
      "         335       0.00      0.00      0.00         0\n",
      "         336       0.00      0.00      0.00         0\n",
      "         337       0.00      0.00      0.00         0\n",
      "         338       0.00      0.00      0.00         0\n",
      "         339       0.00      0.00      0.00         0\n",
      "         340       0.00      0.00      0.00         0\n",
      "         341       0.00      0.00      0.00         0\n",
      "         342       0.00      0.00      0.00         0\n",
      "         343       0.00      0.00      0.00         0\n",
      "         344       0.00      0.00      0.00         0\n",
      "         345       0.00      0.00      0.00         0\n",
      "         346       0.00      0.00      0.00         0\n",
      "         347       0.00      0.00      0.00         0\n",
      "         348       0.00      0.00      0.00         0\n",
      "         349       0.00      0.00      0.00         0\n",
      "         350       0.00      0.00      0.00         0\n",
      "         351       0.00      0.00      0.00         0\n",
      "         352       0.00      0.00      0.00         0\n",
      "         353       0.00      0.00      0.00         0\n",
      "         354       0.00      0.00      0.00         0\n",
      "         355       0.00      0.00      0.00         0\n",
      "         356       0.00      0.00      0.00         0\n",
      "         357       0.00      0.00      0.00         0\n",
      "         358       0.00      0.00      0.00         0\n",
      "         359       0.00      0.00      0.00         0\n",
      "         360       0.00      0.00      0.00         0\n",
      "         361       0.00      0.00      0.00         0\n",
      "         362       0.00      0.00      0.00         0\n",
      "         363       0.00      0.00      0.00         0\n",
      "         364       0.00      0.00      0.00         0\n",
      "         365       0.00      0.00      0.00         0\n",
      "         366       0.00      0.00      0.00         0\n",
      "         367       0.00      0.00      0.00         0\n",
      "         368       0.00      0.00      0.00         1\n",
      "         369       0.00      0.00      0.00         0\n",
      "         370       0.00      0.00      0.00         0\n",
      "         371       0.00      0.00      0.00         0\n",
      "         372       0.00      0.00      0.00         0\n",
      "         373       0.00      0.00      0.00         1\n",
      "         374       0.00      0.00      0.00         0\n",
      "         375       0.00      0.00      0.00         0\n",
      "         376       0.00      0.00      0.00         0\n",
      "         377       0.00      0.00      0.00         0\n",
      "         378       0.00      0.00      0.00         0\n",
      "         379       0.00      0.00      0.00         0\n",
      "         380       0.00      0.00      0.00         0\n",
      "         381       0.00      0.00      0.00         0\n",
      "         382       0.00      0.00      0.00         0\n",
      "         383       0.00      0.00      0.00         0\n",
      "         384       0.00      0.00      0.00         0\n",
      "         385       0.00      0.00      0.00         0\n",
      "         386       0.00      0.00      0.00         0\n",
      "         387       0.00      0.00      0.00         0\n",
      "         388       0.00      0.00      0.00         0\n",
      "         389       0.00      0.00      0.00         0\n",
      "         390       0.00      0.00      0.00         0\n",
      "         391       0.00      0.00      0.00         0\n",
      "         392       0.00      0.00      0.00         1\n",
      "         393       0.00      0.00      0.00         0\n",
      "         394       0.00      0.00      0.00         0\n",
      "         395       0.00      0.00      0.00         0\n",
      "         396       0.00      0.00      0.00         0\n",
      "         397       0.00      0.00      0.00         0\n",
      "         398       0.00      0.00      0.00         0\n",
      "         399       0.00      0.00      0.00         0\n",
      "         400       0.00      0.00      0.00         0\n",
      "         401       0.00      0.00      0.00         0\n",
      "         402       0.00      0.00      0.00         0\n",
      "         403       0.00      0.00      0.00         0\n",
      "         404       0.00      0.00      0.00         0\n",
      "         405       0.00      0.00      0.00         0\n",
      "         406       0.00      0.00      0.00         0\n",
      "         407       0.00      0.00      0.00         0\n",
      "         408       0.00      0.00      0.00         0\n",
      "         409       0.00      0.00      0.00         0\n",
      "         410       0.00      0.00      0.00         0\n",
      "         411       0.00      0.00      0.00         0\n",
      "         412       0.00      0.00      0.00         0\n",
      "         413       0.00      0.00      0.00         0\n",
      "         414       0.00      0.00      0.00         0\n",
      "         415       0.00      0.00      0.00         0\n",
      "         416       0.00      0.00      0.00         1\n",
      "         417       0.00      0.00      0.00         0\n",
      "         418       0.00      0.00      0.00         0\n",
      "         419       0.00      0.00      0.00         0\n",
      "         420       0.00      0.00      0.00         0\n",
      "         421       0.00      0.00      0.00         0\n",
      "         422       0.00      0.00      0.00         0\n",
      "         423       0.00      0.00      0.00         0\n",
      "         424       0.00      0.00      0.00         1\n",
      "         425       0.00      0.00      0.00         0\n",
      "         426       0.00      0.00      0.00         0\n",
      "         427       0.00      0.00      0.00         0\n",
      "         428       0.00      0.00      0.00         0\n",
      "         429       0.00      0.00      0.00         0\n",
      "         430       0.00      0.00      0.00         0\n",
      "         431       0.00      0.00      0.00         0\n",
      "         432       0.00      0.00      0.00         0\n",
      "         433       0.00      0.00      0.00         0\n",
      "         434       0.00      0.00      0.00         0\n",
      "         435       0.00      0.00      0.00         0\n",
      "         436       0.00      0.00      0.00         0\n",
      "         437       0.00      0.00      0.00         0\n",
      "         438       0.00      0.00      0.00         0\n",
      "         439       0.00      0.00      0.00         0\n",
      "         440       0.00      0.00      0.00         0\n",
      "         441       0.00      0.00      0.00         0\n",
      "         442       0.00      0.00      0.00         0\n",
      "         443       0.00      0.00      0.00         0\n",
      "         444       0.00      0.00      0.00         0\n",
      "         445       0.00      0.00      0.00         0\n",
      "         446       0.00      0.00      0.00         0\n",
      "         447       0.00      0.00      0.00         0\n",
      "         448       0.00      0.00      0.00         0\n",
      "         449       0.00      0.00      0.00         0\n",
      "         450       0.00      0.00      0.00         0\n",
      "         451       0.00      0.00      0.00         0\n",
      "         452       0.00      0.00      0.00         0\n",
      "         453       0.00      0.00      0.00         0\n",
      "         454       0.00      0.00      0.00         0\n",
      "         455       0.00      0.00      0.00         0\n",
      "         456       0.00      0.00      0.00         0\n",
      "         457       0.00      0.00      0.00         0\n",
      "         458       0.00      0.00      0.00         0\n",
      "         459       0.00      0.00      0.00         0\n",
      "         460       0.00      0.00      0.00         0\n",
      "         461       0.00      0.00      0.00         0\n",
      "         462       0.00      0.00      0.00         1\n",
      "         463       0.00      0.00      0.00         0\n",
      "         464       0.00      0.00      0.00         0\n",
      "         465       0.00      0.00      0.00         0\n",
      "         466       0.00      0.00      0.00         0\n",
      "         467       0.00      0.00      0.00         0\n",
      "         468       0.00      0.00      0.00         0\n",
      "         469       0.00      0.00      0.00         0\n",
      "         470       0.00      0.00      0.00         0\n",
      "         471       0.00      0.00      0.00         0\n",
      "         472       0.00      0.00      0.00         0\n",
      "         473       0.00      0.00      0.00         0\n",
      "         474       0.00      0.00      0.00         0\n",
      "         475       0.00      0.00      0.00         0\n",
      "         476       0.00      0.00      0.00         0\n",
      "         477       0.00      0.00      0.00         0\n",
      "         478       0.00      0.00      0.00         0\n",
      "         479       0.00      0.00      0.00         0\n",
      "         480       0.00      0.00      0.00         0\n",
      "         481       0.00      0.00      0.00         0\n",
      "         482       0.00      0.00      0.00         0\n",
      "         483       0.00      0.00      0.00         0\n",
      "         484       0.00      0.00      0.00         0\n",
      "         485       0.00      0.00      0.00         0\n",
      "         486       0.00      0.00      0.00         0\n",
      "         487       0.00      0.00      0.00         0\n",
      "         488       0.00      0.00      0.00         0\n",
      "         489       0.00      0.00      0.00         0\n",
      "         490       0.00      0.00      0.00         0\n",
      "         491       0.00      0.00      0.00         0\n",
      "         492       0.00      0.00      0.00         0\n",
      "         493       0.00      0.00      0.00         0\n",
      "         494       0.00      0.00      0.00         0\n",
      "         495       0.00      0.00      0.00         0\n",
      "         496       0.00      0.00      0.00         0\n",
      "         497       0.00      0.00      0.00         0\n",
      "         498       0.00      0.00      0.00         0\n",
      "         499       0.00      0.00      0.00         0\n",
      "         500       0.00      0.00      0.00         0\n",
      "         501       0.00      0.00      0.00         0\n",
      "         502       0.00      0.00      0.00         0\n",
      "         503       0.00      0.00      0.00         0\n",
      "         504       0.00      0.00      0.00         0\n",
      "         505       0.00      0.00      0.00         0\n",
      "         506       0.00      0.00      0.00         0\n",
      "         507       0.00      0.00      0.00         0\n",
      "         508       0.00      0.00      0.00         0\n",
      "         509       0.00      0.00      0.00         0\n",
      "         510       0.00      0.00      0.00         0\n",
      "         511       0.00      0.00      0.00         0\n",
      "         512       0.00      0.00      0.00         1\n",
      "         513       0.00      0.00      0.00         0\n",
      "         514       0.00      0.00      0.00         0\n",
      "         515       0.00      0.00      0.00         0\n",
      "         516       0.00      0.00      0.00         0\n",
      "         517       0.00      0.00      0.00         0\n",
      "         518       0.00      0.00      0.00         0\n",
      "         519       0.00      0.00      0.00         0\n",
      "         520       0.00      0.00      0.00         0\n",
      "         521       0.00      0.00      0.00         0\n",
      "         522       0.00      0.00      0.00         0\n",
      "         523       0.00      0.00      0.00         0\n",
      "         524       0.00      0.00      0.00         0\n",
      "         525       0.00      0.00      0.00         0\n",
      "         526       0.00      0.00      0.00         0\n",
      "         527       0.00      0.00      0.00         0\n",
      "         528       0.00      0.00      0.00         0\n",
      "         529       0.00      0.00      0.00         0\n",
      "         530       0.00      0.00      0.00         0\n",
      "         531       0.00      0.00      0.00         0\n",
      "         532       0.00      0.00      0.00         0\n",
      "         533       0.00      0.00      0.00         0\n",
      "         534       0.00      0.00      0.00         0\n",
      "         535       0.00      0.00      0.00         0\n",
      "         536       0.00      0.00      0.00         0\n",
      "         537       0.00      0.00      0.00         0\n",
      "         538       0.00      0.00      0.00         1\n",
      "         539       0.00      0.00      0.00         0\n",
      "         540       0.00      0.00      0.00         0\n",
      "         541       0.00      0.00      0.00         0\n",
      "         542       0.00      0.00      0.00         0\n",
      "         543       0.00      0.00      0.00         0\n",
      "         544       0.00      0.00      0.00         0\n",
      "         545       0.00      0.00      0.00         0\n",
      "         546       0.00      0.00      0.00         0\n",
      "         547       0.00      0.00      0.00         0\n",
      "         548       0.00      0.00      0.00         0\n",
      "         549       0.00      0.00      0.00         0\n",
      "         550       0.00      0.00      0.00         0\n",
      "         551       0.00      0.00      0.00         0\n",
      "         552       0.00      0.00      0.00         0\n",
      "         553       0.00      0.00      0.00         0\n",
      "         554       0.00      0.00      0.00         0\n",
      "         555       0.00      0.00      0.00         0\n",
      "         556       0.00      0.00      0.00         0\n",
      "         557       0.00      0.00      0.00         0\n",
      "         558       0.00      0.00      0.00         0\n",
      "         559       0.00      0.00      0.00         0\n",
      "         560       0.00      0.00      0.00         0\n",
      "         561       0.00      0.00      0.00         0\n",
      "         562       0.00      0.00      0.00         0\n",
      "         563       0.00      0.00      0.00         0\n",
      "         564       0.00      0.00      0.00         0\n",
      "         565       0.00      0.00      0.00         0\n",
      "         566       0.00      0.00      0.00         0\n",
      "         567       0.00      0.00      0.00         0\n",
      "         568       0.00      0.00      0.00         0\n",
      "         569       0.00      0.00      0.00         0\n",
      "         570       0.00      0.00      0.00         0\n",
      "         571       0.00      0.00      0.00         0\n",
      "         572       0.00      0.00      0.00         0\n",
      "         573       0.00      0.00      0.00         0\n",
      "         574       0.00      0.00      0.00         0\n",
      "         575       0.00      0.00      0.00         0\n",
      "         576       0.00      0.00      0.00         0\n",
      "         577       0.00      0.00      0.00         0\n",
      "         578       0.00      0.00      0.00         0\n",
      "         579       0.00      0.00      0.00         0\n",
      "         580       0.00      0.00      0.00         0\n",
      "         581       0.00      0.00      0.00         0\n",
      "         582       0.00      0.00      0.00         0\n",
      "         583       0.00      0.00      0.00         0\n",
      "         584       0.00      0.00      0.00         0\n",
      "         585       0.00      0.00      0.00         0\n",
      "         586       0.00      0.00      0.00         0\n",
      "         587       0.00      0.00      0.00         0\n",
      "         588       0.00      0.00      0.00         0\n",
      "         589       0.00      0.00      0.00         0\n",
      "         590       0.00      0.00      0.00         0\n",
      "         591       0.00      0.00      0.00         0\n",
      "         592       0.00      0.00      0.00         0\n",
      "         593       0.00      0.00      0.00         0\n",
      "         594       0.00      0.00      0.00         0\n",
      "         595       0.00      0.00      0.00         0\n",
      "         596       0.00      0.00      0.00         0\n",
      "         597       0.00      0.00      0.00         0\n",
      "         598       0.00      0.00      0.00         0\n",
      "         599       0.00      0.00      0.00         0\n",
      "         600       0.00      0.00      0.00         0\n",
      "         601       0.00      0.00      0.00         0\n",
      "         602       0.00      0.00      0.00         0\n",
      "         603       0.00      0.00      0.00         0\n",
      "         604       0.00      0.00      0.00         0\n",
      "         605       0.00      0.00      0.00         0\n",
      "         606       0.00      0.00      0.00         0\n",
      "         607       0.00      0.00      0.00         0\n",
      "         608       0.00      0.00      0.00         0\n",
      "         609       0.00      0.00      0.00         0\n",
      "         610       0.00      0.00      0.00         0\n",
      "         611       0.00      0.00      0.00         0\n",
      "         612       0.00      0.00      0.00         0\n",
      "         613       0.00      0.00      0.00         0\n",
      "         614       0.00      0.00      0.00         0\n",
      "         615       0.00      0.00      0.00         0\n",
      "         616       0.00      0.00      0.00         0\n",
      "         617       0.00      0.00      0.00         0\n",
      "         618       0.00      0.00      0.00         0\n",
      "         619       0.00      0.00      0.00         0\n",
      "         620       0.00      0.00      0.00         0\n",
      "         621       0.00      0.00      0.00         0\n",
      "         622       0.00      0.00      0.00         0\n",
      "         623       0.00      0.00      0.00         0\n",
      "         624       0.00      0.00      0.00         0\n",
      "         625       0.00      0.00      0.00         0\n",
      "         626       0.00      0.00      0.00         0\n",
      "         627       0.00      0.00      0.00         1\n",
      "         628       0.00      0.00      0.00         0\n",
      "         629       0.00      0.00      0.00         0\n",
      "         630       0.00      0.00      0.00         0\n",
      "         631       0.00      0.00      0.00         0\n",
      "         632       0.00      0.00      0.00         0\n",
      "         633       0.00      0.00      0.00         0\n",
      "         634       0.00      0.00      0.00         0\n",
      "         635       0.00      0.00      0.00         0\n",
      "         636       0.00      0.00      0.00         0\n",
      "         637       0.00      0.00      0.00         0\n",
      "         638       0.00      0.00      0.00         0\n",
      "         639       0.00      0.00      0.00         0\n",
      "         640       0.00      0.00      0.00         0\n",
      "         641       0.00      0.00      0.00         0\n",
      "         642       0.00      0.00      0.00         0\n",
      "         643       0.00      0.00      0.00         0\n",
      "         644       0.00      0.00      0.00         0\n",
      "         645       0.00      0.00      0.00         0\n",
      "         646       0.00      0.00      0.00         0\n",
      "         647       0.00      0.00      0.00         0\n",
      "         648       0.00      0.00      0.00         0\n",
      "         649       0.00      0.00      0.00         0\n",
      "         650       0.00      0.00      0.00         0\n",
      "         651       0.00      0.00      0.00         0\n",
      "         652       0.00      0.00      0.00         0\n",
      "         653       0.00      0.00      0.00         2\n",
      "         654       0.00      0.00      0.00         0\n",
      "         655       0.00      0.00      0.00         0\n",
      "         656       0.00      0.00      0.00         0\n",
      "         657       0.00      0.00      0.00         0\n",
      "         658       0.00      0.00      0.00         0\n",
      "         659       0.00      0.00      0.00         0\n",
      "         660       0.00      0.00      0.00         0\n",
      "         661       0.00      0.00      0.00         2\n",
      "         662       0.00      0.00      0.00         0\n",
      "         663       0.00      0.00      0.00         0\n",
      "         664       0.00      0.00      0.00         0\n",
      "         665       0.00      0.00      0.00         0\n",
      "         666       0.00      0.00      0.00         0\n",
      "         667       0.00      0.00      0.00         1\n",
      "         668       0.00      0.00      0.00         0\n",
      "         669       0.00      0.00      0.00         0\n",
      "         670       0.00      0.00      0.00         3\n",
      "         671       0.00      0.00      0.00         0\n",
      "         672       0.00      0.00      0.00         0\n",
      "         673       0.00      0.00      0.00         0\n",
      "         674       0.00      0.00      0.00         0\n",
      "         675       0.00      0.00      0.00         0\n",
      "         676       0.00      0.00      0.00         0\n",
      "         677       0.00      0.00      0.00         0\n",
      "         678       0.00      0.00      0.00         0\n",
      "         679       0.00      0.00      0.00         0\n",
      "         680       0.00      0.00      0.00         0\n",
      "         681       0.00      0.00      0.00         0\n",
      "         682       0.00      0.00      0.00         0\n",
      "         683       0.00      0.00      0.00         0\n",
      "         684       0.00      0.00      0.00         0\n",
      "         685       0.00      0.00      0.00         0\n",
      "         686       0.00      0.00      0.00         0\n",
      "         687       0.00      0.00      0.00         0\n",
      "         688       0.00      0.00      0.00         1\n",
      "         689       0.00      0.00      0.00         0\n",
      "         690       0.00      0.00      0.00         0\n",
      "         691       0.00      0.00      0.00         2\n",
      "         692       0.00      0.00      0.00         0\n",
      "         693       0.00      0.00      0.00         0\n",
      "         694       0.00      0.00      0.00         0\n",
      "         695       0.00      0.00      0.00         0\n",
      "         696       0.00      0.00      0.00         0\n",
      "         697       0.00      0.00      0.00         0\n",
      "         698       0.00      0.00      0.00         0\n",
      "         699       0.00      0.00      0.00         0\n",
      "         700       0.00      0.00      0.00         0\n",
      "         701       0.00      0.00      0.00         0\n",
      "         702       0.00      0.00      0.00         0\n",
      "         703       0.00      0.00      0.00         2\n",
      "         704       0.00      0.00      0.00         0\n",
      "         705       0.00      0.00      0.00         2\n",
      "         706       0.00      0.00      0.00         0\n",
      "         707       0.00      0.00      0.00         0\n",
      "         708       0.00      0.00      0.00         0\n",
      "         709       0.00      0.00      0.00         0\n",
      "         710       0.00      0.00      0.00         0\n",
      "         711       0.00      0.00      0.00         0\n",
      "         712       0.00      0.00      0.00         0\n",
      "         713       0.00      0.00      0.00         0\n",
      "         714       0.00      0.00      0.00         0\n",
      "         715       0.00      0.00      0.00         0\n",
      "         716       0.00      0.00      0.00         0\n",
      "         717       0.00      0.00      0.00         0\n",
      "         718       0.00      0.00      0.00         0\n",
      "         719       0.00      0.00      0.00         0\n",
      "         720       0.00      0.00      0.00         0\n",
      "         721       0.00      0.00      0.00         0\n",
      "         722       0.00      0.00      0.00         0\n",
      "         723       0.00      0.00      0.00         0\n",
      "         724       0.00      0.00      0.00         1\n",
      "         725       0.00      0.00      0.00         0\n",
      "         726       0.00      0.00      0.00         0\n",
      "         727       0.00      0.00      0.00         0\n",
      "         728       0.00      0.00      0.00         0\n",
      "         729       0.00      0.00      0.00         0\n",
      "         730       0.00      0.00      0.00         0\n",
      "         731       0.00      0.00      0.00         0\n",
      "         732       0.00      0.00      0.00         0\n",
      "         733       0.00      0.00      0.00         0\n",
      "         734       0.00      0.00      0.00         0\n",
      "         735       0.00      0.00      0.00         0\n",
      "         736       0.00      0.00      0.00         0\n",
      "         737       0.00      0.00      0.00         0\n",
      "         738       0.00      0.00      0.00         0\n",
      "         739       0.00      0.00      0.00         0\n",
      "         740       0.00      0.00      0.00         0\n",
      "         741       0.00      0.00      0.00         1\n",
      "         742       0.00      0.00      0.00         0\n",
      "         743       0.00      0.00      0.00         0\n",
      "         744       0.00      0.00      0.00         0\n",
      "         745       0.00      0.00      0.00         0\n",
      "         746       0.00      0.00      0.00         0\n",
      "         747       0.00      0.00      0.00         0\n",
      "         748       0.00      0.00      0.00         0\n",
      "         749       0.00      0.00      0.00         0\n",
      "         750       0.00      0.00      0.00         0\n",
      "         751       0.00      0.00      0.00         0\n",
      "         752       0.00      0.00      0.00         0\n",
      "         753       0.00      0.00      0.00         0\n",
      "         754       0.00      0.00      0.00         0\n",
      "         755       0.00      0.00      0.00         0\n",
      "         756       0.00      0.00      0.00         0\n",
      "         757       0.00      0.00      0.00         0\n",
      "         758       0.00      0.00      0.00         0\n",
      "         759       0.00      0.00      0.00         0\n",
      "         760       0.00      0.00      0.00         0\n",
      "         761       0.00      0.00      0.00         0\n",
      "         762       0.00      0.00      0.00         0\n",
      "         763       0.00      0.00      0.00         0\n",
      "         764       0.00      0.00      0.00         0\n",
      "         765       0.00      0.00      0.00         0\n",
      "         766       0.00      0.00      0.00         0\n",
      "         767       0.00      0.00      0.00         0\n",
      "         768       0.00      0.00      0.00         0\n",
      "         769       0.00      0.00      0.00         0\n",
      "         770       0.00      0.00      0.00         0\n",
      "         771       0.00      0.00      0.00         0\n",
      "         772       0.00      0.00      0.00         0\n",
      "         773       0.00      0.00      0.00         0\n",
      "         774       0.00      0.00      0.00         0\n",
      "         775       0.00      0.00      0.00         0\n",
      "         776       0.00      0.00      0.00         0\n",
      "         777       0.00      0.00      0.00         0\n",
      "         778       0.00      0.00      0.00         0\n",
      "         779       0.00      0.00      0.00         0\n",
      "         780       0.00      0.00      0.00         0\n",
      "         781       0.00      0.00      0.00         0\n",
      "         782       0.00      0.00      0.00         0\n",
      "         783       0.00      0.00      0.00         4\n",
      "         784       0.00      0.00      0.00         0\n",
      "         785       0.00      0.00      0.00         0\n",
      "         786       0.00      0.00      0.00         0\n",
      "         787       0.00      0.00      0.00         0\n",
      "         788       0.00      0.00      0.00         0\n",
      "         789       0.00      0.00      0.00         0\n",
      "         790       0.00      0.00      0.00         0\n",
      "         791       0.00      0.00      0.00         1\n",
      "         792       0.00      0.00      0.00         0\n",
      "         793       0.00      0.00      0.00         0\n",
      "         794       0.00      0.00      0.00         0\n",
      "         795       0.00      0.00      0.00         0\n",
      "         796       0.00      0.00      0.00         0\n",
      "         797       0.00      0.00      0.00         0\n",
      "         798       0.00      0.00      0.00         0\n",
      "         799       0.00      0.00      0.00         1\n",
      "         800       0.00      0.00      0.00         0\n",
      "         801       0.00      0.00      0.00         0\n",
      "         802       0.00      0.00      0.00         0\n",
      "         803       0.00      0.00      0.00         0\n",
      "         804       0.00      0.00      0.00         0\n",
      "         805       0.00      0.00      0.00         0\n",
      "         806       0.00      0.00      0.00         0\n",
      "         807       0.00      0.00      0.00         0\n",
      "         808       0.00      0.00      0.00         0\n",
      "         809       0.00      0.00      0.00         0\n",
      "         810       0.00      0.00      0.00         1\n",
      "         811       0.00      0.00      0.00         0\n",
      "         812       0.00      0.00      0.00         0\n",
      "         813       0.00      0.00      0.00         0\n",
      "         814       0.00      0.00      0.00         0\n",
      "         815       0.00      0.00      0.00         0\n",
      "         816       0.00      0.00      0.00         0\n",
      "         817       0.00      0.00      0.00         0\n",
      "         818       0.00      0.00      0.00         0\n",
      "         819       0.00      0.00      0.00         0\n",
      "         820       0.00      0.00      0.00         0\n",
      "         821       0.00      0.00      0.00         0\n",
      "         822       0.00      0.00      0.00         0\n",
      "         823       0.00      0.00      0.00         0\n",
      "         824       0.00      0.00      0.00         0\n",
      "         825       0.00      0.00      0.00         0\n",
      "         826       0.00      0.00      0.00         0\n",
      "         827       0.00      0.00      0.00         0\n",
      "         828       0.00      0.00      0.00         0\n",
      "         829       0.00      0.00      0.00         0\n",
      "         830       0.00      0.00      0.00         0\n",
      "         831       0.00      0.00      0.00         0\n",
      "         832       0.00      0.00      0.00         0\n",
      "         833       0.00      0.00      0.00         0\n",
      "         834       0.00      0.00      0.00         0\n",
      "         835       0.00      0.00      0.00         0\n",
      "         836       0.00      0.00      0.00         0\n",
      "         837       0.00      0.00      0.00         0\n",
      "         838       0.00      0.00      0.00         0\n",
      "         839       0.00      0.00      0.00         0\n",
      "         840       0.00      0.00      0.00         0\n",
      "         841       0.00      0.00      0.00         0\n",
      "         842       0.00      0.00      0.00         2\n",
      "         843       0.00      0.00      0.00         2\n",
      "         844       0.00      0.00      0.00         2\n",
      "         845       0.00      0.00      0.00         0\n",
      "         846       0.00      0.00      0.00         0\n",
      "         847       0.00      0.00      0.00         0\n",
      "         848       0.00      0.00      0.00         0\n",
      "         849       0.00      0.00      0.00         0\n",
      "         850       0.00      0.00      0.00         1\n",
      "         851       0.00      0.00      0.00         1\n",
      "         852       0.00      0.00      0.00         0\n",
      "         853       0.00      0.00      0.00         0\n",
      "         854       0.00      0.00      0.00         0\n",
      "         855       0.00      0.00      0.00         0\n",
      "         856       0.00      0.00      0.00         0\n",
      "         857       0.00      0.00      0.00         0\n",
      "         858       0.00      0.00      0.00         0\n",
      "         859       0.00      0.00      0.00         1\n",
      "         860       0.00      0.00      0.00         0\n",
      "         861       0.00      0.00      0.00         0\n",
      "         862       0.00      0.00      0.00         0\n",
      "         863       0.00      0.00      0.00         0\n",
      "         864       0.00      0.00      0.00         0\n",
      "         865       0.00      0.00      0.00         0\n",
      "         866       0.00      0.00      0.00         0\n",
      "         867       0.00      0.00      0.00         1\n",
      "         868       0.00      0.00      0.00         0\n",
      "         869       0.00      0.00      0.00         0\n",
      "         870       0.00      0.00      0.00         0\n",
      "         871       0.00      0.00      0.00         0\n",
      "         872       0.00      0.00      0.00         0\n",
      "         873       0.00      0.00      0.00         0\n",
      "         874       0.00      0.00      0.00         0\n",
      "         875       0.00      0.00      0.00         0\n",
      "         876       0.00      0.00      0.00         0\n",
      "         877       0.00      0.00      0.00         0\n",
      "         878       0.00      0.00      0.00         1\n",
      "         879       0.00      0.00      0.00         0\n",
      "         880       0.00      0.00      0.00         0\n",
      "         881       0.00      0.00      0.00         0\n",
      "         882       0.00      0.00      0.00         1\n",
      "         883       0.00      0.00      0.00         0\n",
      "         884       0.00      0.00      0.00         0\n",
      "         885       0.00      0.00      0.00         0\n",
      "         886       0.00      0.00      0.00         1\n",
      "         887       0.00      0.00      0.00         0\n",
      "         888       0.00      0.00      0.00         0\n",
      "         889       0.00      0.00      0.00         0\n",
      "         890       0.00      0.00      0.00         0\n",
      "         891       0.00      0.00      0.00         0\n",
      "         892       0.00      0.00      0.00         0\n",
      "         893       0.00      0.00      0.00         1\n",
      "         894       0.00      0.00      0.00         0\n",
      "         895       0.00      0.00      0.00         0\n",
      "         896       0.00      0.00      0.00         0\n",
      "         897       0.00      0.00      0.00         0\n",
      "         898       0.00      0.00      0.00         1\n",
      "         899       0.00      0.00      0.00         0\n",
      "         900       0.00      0.00      0.00         0\n",
      "         901       0.00      0.00      0.00         0\n",
      "         902       0.00      0.00      0.00         0\n",
      "         903       0.00      0.00      0.00         1\n",
      "         904       0.00      0.00      0.00         0\n",
      "         905       0.00      0.00      0.00         0\n",
      "         906       0.00      0.00      0.00         0\n",
      "         907       0.00      0.00      0.00         0\n",
      "         908       0.00      0.00      0.00         0\n",
      "         909       0.00      0.00      0.00         0\n",
      "         910       0.00      0.00      0.00         0\n",
      "         911       0.00      0.00      0.00         0\n",
      "         912       0.00      0.00      0.00         0\n",
      "         913       0.00      0.00      0.00         1\n",
      "         914       0.00      0.00      0.00         0\n",
      "         915       0.00      0.00      0.00         0\n",
      "         916       0.00      0.00      0.00         0\n",
      "         917       0.00      0.00      0.00         0\n",
      "         918       0.00      0.00      0.00         0\n",
      "         919       0.00      0.00      0.00         0\n",
      "         920       0.00      0.00      0.00         0\n",
      "         921       0.00      0.00      0.00         0\n",
      "         922       0.00      0.00      0.00         0\n",
      "         923       0.00      0.00      0.00         0\n",
      "         924       0.00      0.00      0.00         0\n",
      "         925       0.00      0.00      0.00         0\n",
      "         926       0.00      0.00      0.00         0\n",
      "         927       0.00      0.00      0.00         0\n",
      "         928       0.00      0.00      0.00         0\n",
      "         929       0.00      0.00      0.00         0\n",
      "         930       0.00      0.00      0.00         0\n",
      "         931       0.00      0.00      0.00         0\n",
      "         932       0.00      0.00      0.00         0\n",
      "         933       0.00      0.00      0.00         0\n",
      "         934       0.00      0.00      0.00         0\n",
      "         935       0.00      0.00      0.00         0\n",
      "         936       0.00      0.00      0.00         0\n",
      "         937       0.00      0.00      0.00         0\n",
      "         938       0.00      0.00      0.00         0\n",
      "         939       0.00      0.00      0.00         0\n",
      "         940       0.00      0.00      0.00         0\n",
      "         941       0.00      0.00      0.00         0\n",
      "         942       0.00      0.00      0.00         0\n",
      "         943       0.00      0.00      0.00         1\n",
      "         944       0.00      0.00      0.00         3\n",
      "         945       0.00      0.00      0.00         0\n",
      "         946       0.00      0.00      0.00         0\n",
      "         947       0.00      0.00      0.00         0\n",
      "         948       0.00      0.00      0.00         1\n",
      "         949       0.00      0.00      0.00         0\n",
      "         950       0.00      0.00      0.00         0\n",
      "         951       0.00      0.00      0.00         0\n",
      "         952       0.00      0.00      0.00         0\n",
      "         953       0.00      0.00      0.00         0\n",
      "         954       0.00      0.00      0.00         0\n",
      "         955       0.00      0.00      0.00         0\n",
      "         956       0.00      0.00      0.00         0\n",
      "         957       0.00      0.00      0.00         0\n",
      "         958       0.00      0.00      0.00         0\n",
      "         959       0.00      0.00      0.00         0\n",
      "         960       0.00      0.00      0.00         0\n",
      "         961       0.00      0.00      0.00         0\n",
      "         962       0.00      0.00      0.00         0\n",
      "         963       0.00      0.00      0.00         0\n",
      "         964       0.00      0.00      0.00         0\n",
      "         965       0.00      0.00      0.00         0\n",
      "         966       0.00      0.00      0.00         0\n",
      "         967       0.00      0.00      0.00         0\n",
      "         968       0.00      0.00      0.00         0\n",
      "         969       0.00      0.00      0.00         0\n",
      "         970       0.00      0.00      0.00         0\n",
      "         971       0.00      0.00      0.00         0\n",
      "         972       0.00      0.00      0.00         0\n",
      "         973       0.00      0.00      0.00         0\n",
      "         974       0.00      0.00      0.00         0\n",
      "         975       0.00      0.00      0.00         0\n",
      "         976       0.00      0.00      0.00         0\n",
      "         977       0.00      0.00      0.00         0\n",
      "         978       0.00      0.00      0.00         0\n",
      "         979       0.00      0.00      0.00         0\n",
      "         980       0.00      0.00      0.00         0\n",
      "         981       0.00      0.00      0.00         0\n",
      "         982       0.00      0.00      0.00         0\n",
      "         983       0.00      0.00      0.00         0\n",
      "         984       0.00      0.00      0.00         0\n",
      "         985       0.00      0.00      0.00         0\n",
      "         986       0.00      0.00      0.00         0\n",
      "         987       0.00      0.00      0.00         0\n",
      "         988       0.00      0.00      0.00         0\n",
      "         989       0.00      0.00      0.00         0\n",
      "         990       0.00      0.00      0.00         0\n",
      "         991       0.00      0.00      0.00         0\n",
      "         992       0.00      0.00      0.00         0\n",
      "         993       0.00      0.00      0.00         0\n",
      "         994       0.00      0.00      0.00         0\n",
      "         995       0.00      0.00      0.00         0\n",
      "         996       0.00      0.00      0.00         0\n",
      "         997       0.00      0.00      0.00         0\n",
      "         998       0.00      0.00      0.00         0\n",
      "         999       0.00      0.00      0.00         0\n",
      "        1000       0.00      0.00      0.00         0\n",
      "        1001       0.00      0.00      0.00         2\n",
      "        1002       0.00      0.00      0.00         0\n",
      "        1003       0.00      0.00      0.00         2\n",
      "        1004       0.00      0.00      0.00         0\n",
      "        1005       0.00      0.00      0.00         0\n",
      "        1006       0.00      0.00      0.00         0\n",
      "        1007       0.00      0.00      0.00         0\n",
      "        1008       0.00      0.00      0.00         0\n",
      "        1009       0.00      0.00      0.00         0\n",
      "        1010       0.00      0.00      0.00         0\n",
      "        1011       0.00      0.00      0.00         0\n",
      "        1012       0.00      0.00      0.00         0\n",
      "        1013       0.00      0.00      0.00         2\n",
      "        1014       0.00      0.00      0.00         0\n",
      "        1015       0.00      0.00      0.00         0\n",
      "        1016       0.00      0.00      0.00         0\n",
      "        1017       0.00      0.00      0.00         0\n",
      "        1018       0.00      0.00      0.00         0\n",
      "        1019       0.00      0.00      0.00         2\n",
      "        1020       0.00      0.00      0.00         0\n",
      "        1021       0.00      0.00      0.00         0\n",
      "        1022       0.00      0.00      0.00         0\n",
      "        1023       0.00      0.00      0.00         0\n",
      "        1024       0.00      0.00      0.00         0\n",
      "        1025       0.00      0.00      0.00         0\n",
      "        1026       0.00      0.00      0.00         0\n",
      "        1027       0.00      0.00      0.00         0\n",
      "        1028       0.00      0.00      0.00         0\n",
      "        1029       0.00      0.00      0.00         0\n",
      "        1030       0.00      0.00      0.00         0\n",
      "        1031       0.00      0.00      0.00         0\n",
      "        1032       0.00      0.00      0.00         0\n",
      "        1033       0.00      0.00      0.00         0\n",
      "        1034       0.00      0.00      0.00         0\n",
      "        1035       0.00      0.00      0.00         0\n",
      "        1036       0.00      0.00      0.00         0\n",
      "        1037       0.00      0.00      0.00         0\n",
      "        1038       0.00      0.00      0.00         0\n",
      "        1039       0.00      0.00      0.00         0\n",
      "        1040       0.00      0.00      0.00         0\n",
      "        1041       0.00      0.00      0.00         0\n",
      "        1042       0.00      0.00      0.00         0\n",
      "        1043       0.00      0.00      0.00         0\n",
      "        1044       0.00      0.00      0.00         0\n",
      "        1045       0.00      0.00      0.00         0\n",
      "        1046       0.00      0.00      0.00         2\n",
      "        1047       0.00      0.00      0.00         0\n",
      "        1048       0.00      0.00      0.00         0\n",
      "        1049       0.00      0.00      0.00         0\n",
      "        1050       0.00      0.00      0.00         0\n",
      "        1051       0.00      0.00      0.00         0\n",
      "        1052       0.00      0.00      0.00         0\n",
      "        1053       0.00      0.00      0.00         0\n",
      "        1054       0.00      0.00      0.00         0\n",
      "        1055       0.00      0.00      0.00         0\n",
      "        1056       0.00      0.00      0.00         0\n",
      "        1057       0.00      0.00      0.00         0\n",
      "        1058       0.00      0.00      0.00         0\n",
      "        1059       0.00      0.00      0.00         0\n",
      "        1060       0.00      0.00      0.00         0\n",
      "        1061       0.00      0.00      0.00         0\n",
      "        1062       0.00      0.00      0.00         0\n",
      "        1063       0.00      0.00      0.00         0\n",
      "        1064       0.00      0.00      0.00         0\n",
      "        1065       0.00      0.00      0.00         0\n",
      "        1066       0.00      0.00      0.00         0\n",
      "        1067       0.00      0.00      0.00         0\n",
      "        1068       0.00      0.00      0.00         0\n",
      "        1069       0.00      0.00      0.00         0\n",
      "        1070       0.00      0.00      0.00         0\n",
      "        1071       0.00      0.00      0.00         0\n",
      "        1072       0.00      0.00      0.00         0\n",
      "        1073       0.00      0.00      0.00         0\n",
      "        1074       0.00      0.00      0.00         0\n",
      "        1075       0.00      0.00      0.00         0\n",
      "        1076       0.00      0.00      0.00         0\n",
      "        1077       0.00      0.00      0.00         0\n",
      "        1078       0.00      0.00      0.00         0\n",
      "        1079       0.00      0.00      0.00         0\n",
      "        1080       0.00      0.00      0.00         0\n",
      "        1081       0.00      0.00      0.00         0\n",
      "        1082       0.00      0.00      0.00         0\n",
      "        1083       0.00      0.00      0.00         0\n",
      "        1084       0.00      0.00      0.00         0\n",
      "        1085       0.00      0.00      0.00         0\n",
      "        1086       0.00      0.00      0.00         0\n",
      "        1087       0.00      0.00      0.00         0\n",
      "        1088       0.00      0.00      0.00         1\n",
      "        1089       0.00      0.00      0.00         0\n",
      "        1090       0.00      0.00      0.00         0\n",
      "        1091       0.00      0.00      0.00         2\n",
      "        1092       0.00      0.00      0.00         0\n",
      "        1093       0.00      0.00      0.00         0\n",
      "        1094       0.00      0.00      0.00         0\n",
      "        1095       0.00      0.00      0.00         1\n",
      "        1096       0.00      0.00      0.00         0\n",
      "        1097       0.00      0.00      0.00         0\n",
      "        1098       0.00      0.00      0.00         0\n",
      "        1099       0.00      0.00      0.00         0\n",
      "        1100       0.00      0.00      0.00         0\n",
      "        1101       0.00      0.00      0.00         0\n",
      "        1102       0.00      0.00      0.00         0\n",
      "        1103       0.00      0.00      0.00         0\n",
      "        1104       0.00      0.00      0.00         0\n",
      "        1105       0.00      0.00      0.00         0\n",
      "        1106       0.00      0.00      0.00         0\n",
      "        1107       0.00      0.00      0.00         0\n",
      "        1108       0.00      0.00      0.00         0\n",
      "        1109       0.00      0.00      0.00         0\n",
      "        1110       0.00      0.00      0.00         0\n",
      "        1111       0.00      0.00      0.00         0\n",
      "        1112       0.00      0.00      0.00         0\n",
      "        1113       0.00      0.00      0.00         0\n",
      "        1114       0.00      0.00      0.00         0\n",
      "        1115       0.00      0.00      0.00         0\n",
      "        1116       0.00      0.00      0.00         0\n",
      "        1117       0.00      0.00      0.00         0\n",
      "        1118       0.00      0.00      0.00         0\n",
      "        1119       0.00      0.00      0.00         0\n",
      "        1120       0.00      0.00      0.00         0\n",
      "        1121       0.00      0.00      0.00         0\n",
      "        1122       0.00      0.00      0.00         0\n",
      "        1123       0.00      0.00      0.00         0\n",
      "        1124       0.00      0.00      0.00         1\n",
      "        1125       0.00      0.00      0.00         0\n",
      "        1126       0.00      0.00      0.00         0\n",
      "        1127       0.00      0.00      0.00         0\n",
      "        1128       0.00      0.00      0.00         0\n",
      "        1129       0.00      0.00      0.00         0\n",
      "        1130       0.00      0.00      0.00         0\n",
      "        1131       0.00      0.00      0.00         0\n",
      "        1132       0.00      0.00      0.00         0\n",
      "        1133       0.00      0.00      0.00         0\n",
      "        1134       0.00      0.00      0.00         0\n",
      "        1135       0.00      0.00      0.00         0\n",
      "        1136       0.00      0.00      0.00         0\n",
      "        1137       0.00      0.00      0.00         0\n",
      "        1138       0.00      0.00      0.00         0\n",
      "        1139       0.00      0.00      0.00         0\n",
      "        1140       0.00      0.00      0.00         0\n",
      "        1141       0.00      0.00      0.00         0\n",
      "        1142       0.00      0.00      0.00         0\n",
      "        1143       0.00      0.00      0.00         0\n",
      "        1144       0.00      0.00      0.00         0\n",
      "        1145       0.00      0.00      0.00         0\n",
      "        1146       0.00      0.00      0.00         0\n",
      "        1147       0.00      0.00      0.00         0\n",
      "        1148       0.00      0.00      0.00         0\n",
      "        1149       0.00      0.00      0.00         0\n",
      "        1150       0.00      0.00      0.00         0\n",
      "        1151       0.00      0.00      0.00         0\n",
      "        1152       0.00      0.00      0.00         0\n",
      "        1153       0.00      0.00      0.00         0\n",
      "        1154       0.00      0.00      0.00         0\n",
      "        1155       0.00      0.00      0.00         0\n",
      "        1156       0.00      0.00      0.00         0\n",
      "        1157       0.00      0.00      0.00         0\n",
      "        1158       0.00      0.00      0.00         0\n",
      "        1159       0.00      0.00      0.00         0\n",
      "        1160       0.00      0.00      0.00         0\n",
      "        1161       0.00      0.00      0.00         0\n",
      "        1162       0.00      0.00      0.00         0\n",
      "        1163       0.00      0.00      0.00         0\n",
      "        1164       0.00      0.00      0.00         0\n",
      "        1165       0.00      0.00      0.00         0\n",
      "        1166       0.00      0.00      0.00         0\n",
      "        1167       0.00      0.00      0.00         0\n",
      "        1168       0.00      0.00      0.00         0\n",
      "        1169       0.00      0.00      0.00         0\n",
      "        1170       0.00      0.00      0.00         0\n",
      "        1171       0.00      0.00      0.00         0\n",
      "        1172       0.00      0.00      0.00         0\n",
      "        1173       0.00      0.00      0.00         0\n",
      "        1174       0.00      0.00      0.00         0\n",
      "        1175       0.00      0.00      0.00         0\n",
      "        1176       0.00      0.00      0.00         0\n",
      "        1177       0.00      0.00      0.00         0\n",
      "        1178       0.00      0.00      0.00         0\n",
      "        1179       0.00      0.00      0.00         0\n",
      "        1180       0.00      0.00      0.00         0\n",
      "        1181       0.00      0.00      0.00         0\n",
      "        1182       0.00      0.00      0.00         0\n",
      "        1183       0.00      0.00      0.00         0\n",
      "        1184       0.00      0.00      0.00         0\n",
      "        1185       0.00      0.00      0.00         0\n",
      "        1186       0.00      0.00      0.00         0\n",
      "        1187       0.00      0.00      0.00         0\n",
      "        1188       0.00      0.00      0.00         0\n",
      "        1189       0.00      0.00      0.00         0\n",
      "        1190       0.00      0.00      0.00         0\n",
      "        1191       0.00      0.00      0.00         0\n",
      "        1192       0.00      0.00      0.00         0\n",
      "        1193       0.00      0.00      0.00         0\n",
      "        1194       0.00      0.00      0.00         0\n",
      "        1195       0.00      0.00      0.00         0\n",
      "        1196       0.00      0.00      0.00         0\n",
      "        1197       0.00      0.00      0.00         0\n",
      "        1198       0.00      0.00      0.00         0\n",
      "        1199       0.00      0.00      0.00         0\n",
      "        1200       0.00      0.00      0.00         0\n",
      "        1201       0.00      0.00      0.00         0\n",
      "        1202       0.00      0.00      0.00         0\n",
      "        1203       0.00      0.00      0.00         0\n",
      "        1204       0.00      0.00      0.00         0\n",
      "        1205       0.00      0.00      0.00         0\n",
      "        1206       0.00      0.00      0.00         0\n",
      "        1207       0.00      0.00      0.00         0\n",
      "        1208       0.00      0.00      0.00         0\n",
      "        1209       0.00      0.00      0.00         0\n",
      "        1210       0.00      0.00      0.00         0\n",
      "        1211       0.00      0.00      0.00         0\n",
      "        1212       0.00      0.00      0.00         0\n",
      "        1213       0.00      0.00      0.00         0\n",
      "        1214       0.00      0.00      0.00         0\n",
      "        1215       0.00      0.00      0.00         0\n",
      "        1216       0.00      0.00      0.00         0\n",
      "        1217       0.00      0.00      0.00         0\n",
      "        1218       0.00      0.00      0.00         0\n",
      "        1219       0.00      0.00      0.00         0\n",
      "        1220       0.00      0.00      0.00         0\n",
      "        1221       0.00      0.00      0.00         0\n",
      "        1222       0.00      0.00      0.00         0\n",
      "        1223       0.00      0.00      0.00         0\n",
      "        1224       0.00      0.00      0.00         0\n",
      "        1225       0.00      0.00      0.00         0\n",
      "        1226       0.00      0.00      0.00         0\n",
      "        1227       0.00      0.00      0.00         0\n",
      "        1228       0.00      0.00      0.00         0\n",
      "        1229       0.00      0.00      0.00         0\n",
      "        1230       0.00      0.00      0.00         0\n",
      "        1231       0.00      0.00      0.00         0\n",
      "        1232       0.00      0.00      0.00         1\n",
      "        1233       0.00      0.00      0.00         0\n",
      "        1234       0.00      0.00      0.00         0\n",
      "        1235       0.00      0.00      0.00         0\n",
      "        1236       0.00      0.00      0.00         0\n",
      "        1237       0.00      0.00      0.00         0\n",
      "        1238       0.00      0.00      0.00         0\n",
      "        1239       0.00      0.00      0.00         1\n",
      "        1240       0.00      0.00      0.00         0\n",
      "        1241       0.00      0.00      0.00         0\n",
      "        1242       0.00      0.00      0.00         0\n",
      "        1243       0.00      0.00      0.00         0\n",
      "        1244       0.00      0.00      0.00         0\n",
      "        1245       0.00      0.00      0.00         0\n",
      "        1246       0.00      0.00      0.00         0\n",
      "        1247       0.00      0.00      0.00         0\n",
      "        1248       0.00      0.00      0.00         0\n",
      "        1249       0.00      0.00      0.00         0\n",
      "        1250       0.00      0.00      0.00         1\n",
      "        1251       0.00      0.00      0.00         0\n",
      "        1252       0.00      0.00      0.00         1\n",
      "        1253       0.00      0.00      0.00         0\n",
      "        1254       0.00      0.00      0.00         1\n",
      "        1255       0.00      0.00      0.00         0\n",
      "        1256       0.00      0.00      0.00         0\n",
      "        1257       0.00      0.00      0.00         0\n",
      "        1258       0.00      0.00      0.00         0\n",
      "        1259       0.00      0.00      0.00         0\n",
      "        1260       0.00      0.00      0.00         0\n",
      "        1261       0.00      0.00      0.00         0\n",
      "        1262       0.00      0.00      0.00         0\n",
      "        1263       0.00      0.00      0.00         0\n",
      "        1264       0.00      0.00      0.00         0\n",
      "        1265       0.00      0.00      0.00         0\n",
      "        1266       0.00      0.00      0.00         1\n",
      "        1267       0.00      0.00      0.00         1\n",
      "        1268       0.00      0.00      0.00         1\n",
      "        1269       0.00      0.00      0.00         0\n",
      "        1270       0.00      0.00      0.00         0\n",
      "        1271       0.00      0.00      0.00         0\n",
      "        1272       0.00      0.00      0.00         1\n",
      "        1273       0.00      0.00      0.00         0\n",
      "        1274       0.00      0.00      0.00         0\n",
      "        1275       0.00      0.00      0.00         1\n",
      "        1276       0.00      0.00      0.00         1\n",
      "        1277       0.00      0.00      0.00         0\n",
      "        1278       0.00      0.00      0.00         0\n",
      "        1279       0.00      0.00      0.00         0\n",
      "        1280       0.00      0.00      0.00         1\n",
      "        1281       0.00      0.00      0.00         0\n",
      "        1282       0.00      0.00      0.00         0\n",
      "        1283       0.00      0.00      0.00         0\n",
      "        1284       0.00      0.00      0.00         1\n",
      "        1285       0.00      0.00      0.00         0\n",
      "        1286       0.00      0.00      0.00         0\n",
      "        1287       0.00      0.00      0.00         0\n",
      "        1288       0.00      0.00      0.00         0\n",
      "        1289       0.00      0.00      0.00         0\n",
      "        1290       0.00      0.00      0.00         0\n",
      "        1291       0.00      0.00      0.00         0\n",
      "        1292       0.00      0.00      0.00         0\n",
      "        1293       0.00      0.00      0.00         0\n",
      "        1294       0.00      0.00      0.00         1\n",
      "        1295       0.00      0.00      0.00         0\n",
      "        1296       0.00      0.00      0.00         0\n",
      "        1297       0.00      0.00      0.00         0\n",
      "        1298       0.00      0.00      0.00         0\n",
      "        1299       0.00      0.00      0.00         0\n",
      "        1300       0.00      0.00      0.00         0\n",
      "        1301       0.00      0.00      0.00         0\n",
      "        1302       0.00      0.00      0.00         0\n",
      "        1303       0.00      0.00      0.00         0\n",
      "        1304       0.00      0.00      0.00         0\n",
      "        1305       0.00      0.00      0.00         0\n",
      "        1306       0.00      0.00      0.00         0\n",
      "        1307       0.00      0.00      0.00         0\n",
      "        1308       0.00      0.00      0.00         0\n",
      "        1309       0.00      0.00      0.00         0\n",
      "        1310       0.00      0.00      0.00         0\n",
      "        1311       0.00      0.00      0.00         0\n",
      "        1312       0.00      0.00      0.00         0\n",
      "        1313       0.00      0.00      0.00         0\n",
      "        1314       0.00      0.00      0.00         1\n",
      "        1315       0.00      0.00      0.00         1\n",
      "        1316       0.00      0.00      0.00         1\n",
      "        1317       0.00      0.00      0.00         1\n",
      "        1318       0.00      0.00      0.00         1\n",
      "        1319       0.00      0.00      0.00         0\n",
      "        1320       0.00      0.00      0.00         0\n",
      "        1321       0.00      0.00      0.00         0\n",
      "        1322       0.00      0.00      0.00         0\n",
      "        1323       0.00      0.00      0.00         0\n",
      "        1324       0.00      0.00      0.00         0\n",
      "        1325       0.00      0.00      0.00         0\n",
      "        1326       0.00      0.00      0.00         0\n",
      "        1327       0.00      0.00      0.00         0\n",
      "        1328       0.00      0.00      0.00         0\n",
      "        1329       0.00      0.00      0.00         0\n",
      "        1330       0.00      0.00      0.00         0\n",
      "        1331       0.00      0.00      0.00         0\n",
      "        1332       0.00      0.00      0.00         0\n",
      "        1333       0.00      0.00      0.00         0\n",
      "        1334       0.00      0.00      0.00         0\n",
      "        1335       0.00      0.00      0.00         0\n",
      "        1336       0.00      0.00      0.00         0\n",
      "        1337       0.00      0.00      0.00         1\n",
      "        1338       0.00      0.00      0.00         0\n",
      "        1339       0.00      0.00      0.00         0\n",
      "        1340       0.00      0.00      0.00         0\n",
      "        1341       0.00      0.00      0.00         0\n",
      "        1342       0.00      0.00      0.00         0\n",
      "        1343       0.00      0.00      0.00         0\n",
      "        1344       0.00      0.00      0.00         0\n",
      "        1345       0.00      0.00      0.00         0\n",
      "        1346       0.00      0.00      0.00         0\n",
      "        1347       0.00      0.00      0.00         0\n",
      "        1348       0.00      0.00      0.00         0\n",
      "        1349       0.00      0.00      0.00         0\n",
      "        1350       0.00      0.00      0.00         0\n",
      "        1351       0.00      0.00      0.00         0\n",
      "        1352       0.00      0.00      0.00         0\n",
      "        1353       0.00      0.00      0.00         0\n",
      "        1354       0.00      0.00      0.00         0\n",
      "        1355       0.00      0.00      0.00         0\n",
      "        1356       0.00      0.00      0.00         0\n",
      "        1357       0.00      0.00      0.00         0\n",
      "        1358       0.00      0.00      0.00         0\n",
      "        1359       0.00      0.00      0.00         0\n",
      "        1360       0.00      0.00      0.00         0\n",
      "        1361       0.00      0.00      0.00         0\n",
      "        1362       0.00      0.00      0.00         0\n",
      "        1363       0.00      0.00      0.00         0\n",
      "        1364       0.00      0.00      0.00         0\n",
      "        1365       0.00      0.00      0.00         0\n",
      "        1366       0.00      0.00      0.00         0\n",
      "        1367       0.00      0.00      0.00         0\n",
      "        1368       0.00      0.00      0.00         0\n",
      "        1369       0.00      0.00      0.00         0\n",
      "        1370       0.00      0.00      0.00         0\n",
      "        1371       0.00      0.00      0.00         0\n",
      "        1372       0.00      0.00      0.00         0\n",
      "        1373       0.00      0.00      0.00         0\n",
      "        1374       0.00      0.00      0.00         0\n",
      "        1375       0.00      0.00      0.00         0\n",
      "        1376       0.00      0.00      0.00         0\n",
      "        1377       0.00      0.00      0.00         0\n",
      "        1378       0.00      0.00      0.00         0\n",
      "        1379       0.00      0.00      0.00         0\n",
      "        1380       0.00      0.00      0.00         0\n",
      "        1381       0.00      0.00      0.00         0\n",
      "        1382       0.00      0.00      0.00         0\n",
      "        1383       0.00      0.00      0.00         0\n",
      "        1384       0.00      0.00      0.00         0\n",
      "        1385       0.00      0.00      0.00         0\n",
      "        1386       0.00      0.00      0.00         0\n",
      "        1387       0.00      0.00      0.00         0\n",
      "        1388       0.00      0.00      0.00         0\n",
      "        1389       0.00      0.00      0.00         0\n",
      "        1390       0.00      0.00      0.00         0\n",
      "        1391       0.00      0.00      0.00         0\n",
      "        1392       0.00      0.00      0.00         0\n",
      "        1393       0.00      0.00      0.00         0\n",
      "        1394       0.00      0.00      0.00         0\n",
      "        1395       0.00      0.00      0.00         0\n",
      "        1396       0.00      0.00      0.00         0\n",
      "        1397       0.00      0.00      0.00         0\n",
      "        1398       0.00      0.00      0.00         0\n",
      "        1399       0.00      0.00      0.00         0\n",
      "        1400       0.00      0.00      0.00         0\n",
      "        1401       0.00      0.00      0.00         0\n",
      "        1402       0.00      0.00      0.00         0\n",
      "        1403       0.00      0.00      0.00         0\n",
      "        1404       0.00      0.00      0.00         0\n",
      "        1405       0.00      0.00      0.00         0\n",
      "        1406       0.00      0.00      0.00         0\n",
      "        1407       0.00      0.00      0.00         0\n",
      "        1408       0.00      0.00      0.00         0\n",
      "        1409       0.00      0.00      0.00         0\n",
      "        1410       0.00      0.00      0.00         2\n",
      "        1411       0.00      0.00      0.00         0\n",
      "        1412       0.00      0.00      0.00         2\n",
      "        1413       0.00      0.00      0.00         0\n",
      "        1414       0.00      0.00      0.00         0\n",
      "        1415       0.00      0.00      0.00         0\n",
      "        1416       0.00      0.00      0.00         0\n",
      "        1417       0.00      0.00      0.00         0\n",
      "        1418       0.00      0.00      0.00         0\n",
      "        1419       0.00      0.00      0.00         0\n",
      "        1420       0.00      0.00      0.00         1\n",
      "        1421       0.00      0.00      0.00         0\n",
      "        1422       0.00      0.00      0.00         0\n",
      "        1423       0.00      0.00      0.00         1\n",
      "        1424       0.00      0.00      0.00         0\n",
      "        1425       0.00      0.00      0.00         0\n",
      "        1426       0.00      0.00      0.00         1\n",
      "        1427       0.00      0.00      0.00         0\n",
      "        1428       0.00      0.00      0.00         0\n",
      "        1429       0.00      0.00      0.00         0\n",
      "        1430       0.00      0.00      0.00         0\n",
      "        1431       0.00      0.00      0.00         1\n",
      "        1432       0.00      0.00      0.00         3\n",
      "        1433       0.00      0.00      0.00         2\n",
      "        1434       0.00      0.00      0.00         0\n",
      "        1435       0.00      0.00      0.00         0\n",
      "        1436       0.00      0.00      0.00         0\n",
      "        1437       0.00      0.00      0.00         0\n",
      "        1438       0.00      0.00      0.00         0\n",
      "        1439       0.00      0.00      0.00         0\n",
      "        1440       0.00      0.00      0.00         0\n",
      "        1441       0.00      0.00      0.00         1\n",
      "        1442       0.00      0.00      0.00         0\n",
      "        1443       0.00      0.00      0.00         0\n",
      "        1444       0.00      0.00      0.00         0\n",
      "        1445       0.00      0.00      0.00         0\n",
      "        1446       0.00      0.00      0.00         0\n",
      "        1447       0.00      0.00      0.00         0\n",
      "        1448       0.00      0.00      0.00         0\n",
      "        1449       0.00      0.00      0.00         0\n",
      "        1450       0.00      0.00      0.00         0\n",
      "        1451       0.00      0.00      0.00         0\n",
      "        1452       0.00      0.00      0.00         0\n",
      "        1453       0.00      0.00      0.00         0\n",
      "        1454       0.00      0.00      0.00         0\n",
      "        1455       0.00      0.00      0.00         0\n",
      "        1456       0.00      0.00      0.00         0\n",
      "        1457       0.00      0.00      0.00         0\n",
      "        1458       0.00      0.00      0.00         1\n",
      "        1459       0.00      0.00      0.00         1\n",
      "        1460       0.00      0.00      0.00         0\n",
      "        1461       0.00      0.00      0.00         1\n",
      "        1462       0.00      0.00      0.00         0\n",
      "        1463       0.00      0.00      0.00         1\n",
      "        1464       0.00      0.00      0.00         0\n",
      "        1465       0.00      0.00      0.00         0\n",
      "        1466       0.00      0.00      0.00         0\n",
      "        1467       0.00      0.00      0.00         0\n",
      "        1468       0.00      0.00      0.00         0\n",
      "        1469       0.00      0.00      0.00         0\n",
      "        1470       0.00      0.00      0.00         2\n",
      "        1471       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.05      0.01      0.01       141\n",
      "   macro avg       0.00      0.00      0.00       141\n",
      "weighted avg       0.01      0.01      0.01       141\n",
      " samples avg       0.03      0.01      0.01       141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "c1d42f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.008308946488294314\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c019a8",
   "metadata": {},
   "source": [
    "### procedures_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "64deabf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 355)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "4e64f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 240)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "9f983508",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"procedures_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedures_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "4ef34365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to integers\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "e733af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "c62d880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "12914dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "71da1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "5cca575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "ac42c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "9883ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "fb66fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "a521fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 355 to 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "8d516790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "[3.08921484e-01 4.71046748e-01 2.01995355e-01 6.70578329e-04\n",
      " 5.97555236e-04 4.47598195e-04 3.85753827e-04 2.94080361e-04\n",
      " 2.93762187e-04 2.93053791e-04 2.82650969e-04 2.61389982e-04\n",
      " 2.59750760e-04 2.48404704e-04 1.96052418e-04 1.96063673e-04\n",
      " 1.96051526e-04 1.92877046e-04 1.87573604e-04 1.67152925e-04\n",
      " 1.63386178e-04 1.63382172e-04 1.63385596e-04 1.62659035e-04\n",
      " 1.57535338e-04 1.50846914e-04 1.30709913e-04 1.30709021e-04\n",
      " 1.30709021e-04 1.29670173e-04 1.27668155e-04 1.23094801e-04\n",
      " 9.80306790e-05 9.80322453e-05 9.80298799e-05 9.80300821e-05\n",
      " 9.80297568e-05 9.80314221e-05 9.80265969e-05 9.80301643e-05\n",
      " 9.80304148e-05 9.80318414e-05 9.80303455e-05 9.80297629e-05\n",
      " 9.80294097e-05 9.68615570e-05 9.05856878e-05 8.41064144e-05\n",
      " 6.53509947e-05 6.53475964e-05 6.53495782e-05 6.53439287e-05\n",
      " 6.53481022e-05 6.53479094e-05 6.53468326e-05 6.53463851e-05\n",
      " 6.53459390e-05 6.53457045e-05 6.53446750e-05 6.53434222e-05\n",
      " 6.53424966e-05 6.53420766e-05 6.53405857e-05 6.53390422e-05\n",
      " 6.53384677e-05 6.53350034e-05 6.53340149e-05 6.53326554e-05\n",
      " 6.53310842e-05 6.53299323e-05 6.53252761e-05 6.53236966e-05\n",
      " 6.53201544e-05 6.53153758e-05 6.53143642e-05 6.53125510e-05\n",
      " 6.53051828e-05 6.53052644e-05 6.52955206e-05 6.52864940e-05\n",
      " 6.52731080e-05 6.52696426e-05 6.52591828e-05 6.52546556e-05\n",
      " 6.52287717e-05 6.52030609e-05 6.51349877e-05 6.24553542e-05\n",
      " 5.86674759e-05 5.29702721e-05 3.26765546e-05 3.26774569e-05\n",
      " 3.26774618e-05 3.26775070e-05 3.26774467e-05 3.26773169e-05\n",
      " 3.26770764e-05 3.26774216e-05 3.26772196e-05 3.26774155e-05\n",
      " 3.26764192e-05 3.26774732e-05 3.26774450e-05 3.26775065e-05\n",
      " 3.26772571e-05 3.26774984e-05 3.26775224e-05 3.26775213e-05\n",
      " 3.26773666e-05 3.26772473e-05 3.26773226e-05 3.26775226e-05\n",
      " 3.26774984e-05 3.26775225e-05 3.26773220e-05]\n",
      "\n",
      " Amount of original variance conserved: 0.993951919178135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 115\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "X_train = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "beb1213c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "[3.04270466e-01 4.81443421e-01 1.96010480e-01 9.20171180e-04\n",
      " 6.58187181e-04 5.40965866e-04 5.28767772e-04 4.13855721e-04\n",
      " 4.13860369e-04 4.13797776e-04 4.13856704e-04 4.04664219e-04\n",
      " 4.01329206e-04 3.65571274e-04 2.75893539e-04 2.75902385e-04\n",
      " 2.75878103e-04 2.75904762e-04 2.63580951e-04 2.45864272e-04\n",
      " 2.23776991e-04 1.37952664e-04 1.37950848e-04 1.37950779e-04\n",
      " 1.37954348e-04 1.37949150e-04 1.37949335e-04 1.37953645e-04\n",
      " 1.37941902e-04 1.37954000e-04 1.37954367e-04 1.37953813e-04\n",
      " 1.37949317e-04 1.37950997e-04 1.37952842e-04 1.37951813e-04\n",
      " 1.37952394e-04 1.37954312e-04 1.37953069e-04 1.37954365e-04\n",
      " 1.37953611e-04 1.37952069e-04 1.37951003e-04 1.37949557e-04\n",
      " 1.37952880e-04 1.37953435e-04 1.37954368e-04 1.37952196e-04\n",
      " 1.37954350e-04 1.37952010e-04 1.37950181e-04 1.37947873e-04\n",
      " 1.37952278e-04 1.37948086e-04 1.37954272e-04 1.37954101e-04\n",
      " 1.37954196e-04 1.37953724e-04 1.37951219e-04 1.37952263e-04\n",
      " 1.37945215e-04 1.37950783e-04 1.37953745e-04 1.37939509e-04\n",
      " 1.37954298e-04 1.37943610e-04 1.37954360e-04 1.37953869e-04\n",
      " 1.37954355e-04 1.37954358e-04 1.37952770e-04 1.37954334e-04\n",
      " 1.37953971e-04 1.37953479e-04 1.37954364e-04 1.37953763e-04\n",
      " 1.37954278e-04 1.37954166e-04 1.37947112e-04 1.37954221e-04\n",
      " 1.37947863e-04 1.37953764e-04 1.37951728e-04 1.37952434e-04\n",
      " 1.37953334e-04 1.37935326e-04 1.37949306e-04 1.37954011e-04\n",
      " 1.37954044e-04 1.37951604e-04 1.37953127e-04 1.37944670e-04\n",
      " 1.37953802e-04 1.37950048e-04 1.37950430e-04 1.37950789e-04\n",
      " 1.37953720e-04 1.37954364e-04 1.37946263e-04 1.37953829e-04\n",
      " 3.47814662e-05 3.08442177e-05 4.91448787e-35 1.45590252e-33\n",
      " 8.74844548e-33 1.35887180e-32 1.79069363e-35 3.41637433e-35\n",
      " 3.67507586e-35 2.88485405e-35 2.18781540e-35 3.53294117e-35\n",
      " 3.77662746e-35 1.79654500e-35 1.14688034e-35]\n",
      "\n",
      " Amount of original variance conserved: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 115\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_test)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a97f36",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "f428b3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [51:30<00:00, 30.90s/it]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "55e3a4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         7\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         4\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         9\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         3\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         5\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       1.00      0.15      0.27        13\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.00      0.00      0.00         2\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         2\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         5\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         4\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         6\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         5\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         1\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       0.00      0.00      0.00         2\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         2\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         7\n",
      "         186       0.00      0.00      0.00         1\n",
      "         187       0.00      0.00      0.00         7\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         1\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         4\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         2\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         7\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         2\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         3\n",
      "         216       0.00      0.00      0.00         4\n",
      "         217       0.00      0.00      0.00         0\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         3\n",
      "         226       0.00      0.00      0.00         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       0.00      0.00      0.00         8\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         5\n",
      "         235       0.00      0.00      0.00         0\n",
      "         236       0.00      0.00      0.00         2\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         4\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.17      0.01      0.01       265\n",
      "   macro avg       0.00      0.00      0.00       265\n",
      "weighted avg       0.05      0.01      0.01       265\n",
      " samples avg       0.01      0.01      0.01       265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "fd79bdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.008302919708029197\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132d96c",
   "metadata": {},
   "source": [
    "### services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "f354988c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 25)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "3c4bcadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 240)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "457a20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"services_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"services_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "cc7ee661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "5907e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "e1f50c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "2460fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "648d495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "f2e66d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "19462263",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "484b9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "0f43a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37ecdb",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "5b1baed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:51<00:00,  5.91s/it]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "55fbcff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         4\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         2\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         4\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         5\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         1\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         1\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         2\n",
      "         182       0.00      0.00      0.00         1\n",
      "         183       0.00      0.00      0.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         2\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       0.00      0.00      0.00         4\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         1\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         0\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         1\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         2\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       0.00      0.00      0.00         3\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         0\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         0\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       107\n",
      "   macro avg       0.00      0.00      0.00       107\n",
      "weighted avg       0.00      0.00      0.00       107\n",
      " samples avg       0.00      0.00      0.00       107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "dfe2d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.008705357142857143\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f0a25",
   "metadata": {},
   "source": [
    "### transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "d5cfb9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(815, 38)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "8b3b4bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(815, 240)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "67e33b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"transfers_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"transfers_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "97d479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "223dee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "e5359e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "7ec99773",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "3bfaa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "9b2dc273",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "80cec3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "85e6f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "131a27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "5ce039ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0190b",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "38b37c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "8e77279b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.005128205128205128\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         5\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.50      0.50      0.50         2\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.17      0.10      0.12        10\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         3\n",
      "          59       0.00      0.00      0.00         3\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         8\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00        10\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.75      0.38      0.50         8\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         4\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         3\n",
      "          96       0.00      0.00      0.00         4\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.50      0.50      0.50         2\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         6\n",
      "         107       0.00      0.00      0.00         4\n",
      "         108       0.00      0.00      0.00         4\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         2\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         5\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       0.00      0.00      0.00         2\n",
      "         118       0.00      0.00      0.00         2\n",
      "         119       0.00      0.00      0.00         4\n",
      "         120       0.00      0.00      0.00         3\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         2\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         3\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         3\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         2\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         2\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         1\n",
      "         159       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         2\n",
      "         165       0.00      0.00      0.00         4\n",
      "         166       0.00      0.00      0.00         2\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         1\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         2\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         2\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         2\n",
      "         186       0.00      0.00      0.00         3\n",
      "         187       0.00      0.00      0.00        10\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         3\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         2\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         2\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         2\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         2\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         3\n",
      "         212       0.00      0.00      0.00         4\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         7\n",
      "         217       0.00      0.00      0.00         2\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         3\n",
      "         224       0.00      0.00      0.00         4\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         2\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         3\n",
      "         231       0.00      0.00      0.00         3\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         3\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         3\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.02      0.03       381\n",
      "   macro avg       0.01      0.01      0.01       381\n",
      "weighted avg       0.03      0.02      0.02       381\n",
      " samples avg       0.02      0.02      0.02       381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "f7c88b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.00935897435897436\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34834d4c",
   "metadata": {},
   "source": [
    "### Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "6a334c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=50)\n",
    "\n",
    "# Initialize the multi-output classifier with the decision tree as the base estimator\n",
    "multi_output_tree = MultiOutputClassifier(decision_tree, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "18b6d7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=DecisionTreeClassifier(max_depth=50), n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=DecisionTreeClassifier(max_depth=50), n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=50)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=50)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=DecisionTreeClassifier(max_depth=50), n_jobs=-1)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the multi-output classifier\n",
    "multi_output_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "2b94d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the outputs for the test set\n",
    "y_pred = multi_output_tree.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a783c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example thresholding (adjust threshold as needed)\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Now, both y_test.values and y_pred_multilabel should be in the multilabel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "70ab7aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.015876068376068374\n"
     ]
    }
   ],
   "source": [
    "# Hamming loss measures the fraction of labels that are incorrectly predicted, averaged over all samples\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test.values, y_pred_multilabel)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "014a3009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.010256410256410256\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.40      0.33      0.36         6\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.50      0.50      0.50         2\n",
      "          28       0.00      0.00      0.00         5\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.36      0.50      0.42        10\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         3\n",
      "          59       0.00      0.00      0.00         3\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.11      0.12      0.12         8\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00        10\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.27      0.38      0.32         8\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         4\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         3\n",
      "          96       0.00      0.00      0.00         4\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         6\n",
      "         107       0.17      0.25      0.20         4\n",
      "         108       0.20      0.25      0.22         4\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         2\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         5\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       0.00      0.00      0.00         2\n",
      "         118       0.00      0.00      0.00         2\n",
      "         119       0.00      0.00      0.00         4\n",
      "         120       0.00      0.00      0.00         3\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         2\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         3\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         3\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         2\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         2\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         1\n",
      "         159       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         2\n",
      "         165       0.00      0.00      0.00         4\n",
      "         166       0.00      0.00      0.00         2\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       1.00      1.00      1.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         1\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         2\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         2\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         2\n",
      "         186       0.00      0.00      0.00         3\n",
      "         187       0.00      0.00      0.00        10\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         3\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         2\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         2\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         2\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         2\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         3\n",
      "         212       0.00      0.00      0.00         4\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         7\n",
      "         217       0.00      0.00      0.00         2\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         3\n",
      "         224       0.00      0.00      0.00         4\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.17      0.50      0.25         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         2\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         3\n",
      "         231       0.00      0.00      0.00         3\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.14      0.33      0.20         3\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         3\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.05      0.05      0.05       381\n",
      "   macro avg       0.02      0.02      0.02       381\n",
      "weighted avg       0.04      0.05      0.04       381\n",
      " samples avg       0.04      0.05      0.04       381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test.values, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test.values, y_pred_multilabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e2eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "ac137fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize a base classifier (Random Forest in this case)\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# Initialize the Classifier Chain classifier with the base classifier\n",
    "classifier = ClassifierChain(classifier=base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d5eaad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "0c9adeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.035897435897435895\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         5\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.45      0.50      0.48        10\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         3\n",
      "          59       0.00      0.00      0.00         3\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         8\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00        10\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.40      0.50      0.44         8\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         4\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         3\n",
      "          96       0.00      0.00      0.00         4\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         6\n",
      "         107       0.00      0.00      0.00         4\n",
      "         108       0.00      0.00      0.00         4\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         2\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         5\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       0.00      0.00      0.00         2\n",
      "         118       0.00      0.00      0.00         2\n",
      "         119       0.00      0.00      0.00         4\n",
      "         120       0.00      0.00      0.00         3\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         2\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         3\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         3\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         2\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         2\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         1\n",
      "         159       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         2\n",
      "         165       0.00      0.00      0.00         4\n",
      "         166       0.00      0.00      0.00         2\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         1\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         2\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         2\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         2\n",
      "         186       0.50      0.33      0.40         3\n",
      "         187       0.18      0.20      0.19        10\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         3\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         2\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         2\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         2\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         2\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.50      0.33      0.40         3\n",
      "         212       0.00      0.00      0.00         4\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.22      0.29      0.25         7\n",
      "         217       0.00      0.00      0.00         2\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         3\n",
      "         224       0.00      0.00      0.00         4\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         2\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         2\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         3\n",
      "         231       0.00      0.00      0.00         3\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         3\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         3\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.04      0.06       381\n",
      "   macro avg       0.01      0.01      0.01       381\n",
      "weighted avg       0.04      0.04      0.04       381\n",
      " samples avg       0.04      0.04      0.04       381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Example thresholding (adjust threshold as needed)\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_multilabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "8a475792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize a base classifier (Random Forest in this case)\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# Initialize the Classifier Chain classifier with the base classifier\n",
    "classifier = ClassifierChain(classifier=base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "77b86b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "648d1ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3549222797927461\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      0.15      0.24        13\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       1.00      0.22      0.36         9\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      0.56      0.71         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      0.56      0.71         9\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.65      0.33      0.44        33\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.33      0.43      0.38         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.25      0.14      0.18         7\n",
      "          46       0.60      0.75      0.67         4\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       1.00      0.86      0.92         7\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       1.00      0.50      0.67         2\n",
      "          59       1.00      1.00      1.00         6\n",
      "          60       0.00      0.00      0.00         5\n",
      "          61       1.00      0.71      0.83         7\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.65      0.31      0.42        35\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.50      0.20      0.29         5\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         5\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.67      0.17      0.27        12\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       1.00      0.14      0.25         7\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.71      0.41      0.52        41\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       1.00      0.86      0.92         7\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.67      0.29      0.40         7\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       1.00      0.33      0.50         3\n",
      "         106       1.00      0.88      0.93         8\n",
      "         107       1.00      0.71      0.83         7\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         3\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.83      0.38      0.53        13\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       1.00      0.50      0.67         2\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.67      0.17      0.27        12\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         4\n",
      "         147       1.00      0.33      0.50         3\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.80      0.52      0.63        31\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.83      0.33      0.48        15\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.25      0.17      0.20         6\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       1.00      0.33      0.50         3\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       1.00      1.00      1.00         2\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       1.00      0.20      0.33         5\n",
      "         172       1.00      0.62      0.77         8\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       1.00      0.50      0.67         4\n",
      "         183       0.67      0.25      0.36         8\n",
      "         184       1.00      0.50      0.67         2\n",
      "         185       1.00      0.33      0.50         9\n",
      "         186       0.95      0.86      0.90        21\n",
      "         187       0.36      0.40      0.38        48\n",
      "         188       0.82      0.75      0.78        12\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         4\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.67      0.29      0.40         7\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       1.00      0.50      0.67         2\n",
      "         208       1.00      0.50      0.67         6\n",
      "         209       1.00      0.33      0.50         9\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.95      0.86      0.90        21\n",
      "         212       1.00      1.00      1.00         6\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.67      0.31      0.42        13\n",
      "         216       0.15      0.21      0.17        29\n",
      "         217       0.50      0.25      0.33         4\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.32      0.43      0.36        14\n",
      "         226       0.00      0.00      0.00         3\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       1.00      0.50      0.67         6\n",
      "         230       0.80      0.62      0.70        13\n",
      "         231       1.00      0.14      0.25         7\n",
      "         232       0.50      0.14      0.22         7\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.30      0.40      0.34        15\n",
      "         235       0.80      0.62      0.70        13\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.22      0.29      0.25         7\n",
      "         239       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.62      0.37      0.46       763\n",
      "   macro avg       0.20      0.12      0.14       763\n",
      "weighted avg       0.58      0.37      0.43       763\n",
      " samples avg       0.37      0.37      0.37       763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Example thresholding (adjust threshold as needed)\n",
    "threshold = 0.5\n",
    "y_pred_multilabel = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred_multilabel)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_multilabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "eb60435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(815, 38)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "689a3fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(815, 240)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19587313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35367c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "329f4d06",
   "metadata": {},
   "source": [
    "### icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "8ce21673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 20)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "29bd4f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 240)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "30424c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"icustays_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"icustays_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "a25835e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "77b2b3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icu_los</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>...</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "      <th>last_careunit_Cardiac Vascular Intensive Care Unit (CVICU)</th>\n",
       "      <th>last_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>last_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>last_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>last_careunit_Neuro Intermediate</th>\n",
       "      <th>last_careunit_Neuro Stepdown</th>\n",
       "      <th>last_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>last_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>last_careunit_Trauma SICU (TSICU)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20291550</td>\n",
       "      <td>4.983889</td>\n",
       "      <td>0.444861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22205327</td>\n",
       "      <td>6.327037</td>\n",
       "      <td>0.093056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22429197</td>\n",
       "      <td>9.362049</td>\n",
       "      <td>0.036806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25926192</td>\n",
       "      <td>2.280752</td>\n",
       "      <td>1.699178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20199380</td>\n",
       "      <td>3.677384</td>\n",
       "      <td>0.992396</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>25809882</td>\n",
       "      <td>2.525509</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>29642388</td>\n",
       "      <td>1.446539</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>27417763</td>\n",
       "      <td>0.798125</td>\n",
       "      <td>0.090382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>22580999</td>\n",
       "      <td>1.083877</td>\n",
       "      <td>1.065671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>27505812</td>\n",
       "      <td>1.040370</td>\n",
       "      <td>0.111088</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id   icu_los  days_since_admission  \\\n",
       "0    20291550  4.983889              0.444861   \n",
       "1    22205327  6.327037              0.093056   \n",
       "2    22429197  9.362049              0.036806   \n",
       "3    25926192  2.280752              1.699178   \n",
       "4    20199380  3.677384              0.992396   \n",
       "..        ...       ...                   ...   \n",
       "107  25809882  2.525509              0.060417   \n",
       "108  29642388  1.446539              0.001319   \n",
       "109  27417763  0.798125              0.090382   \n",
       "110  22580999  1.083877              1.065671   \n",
       "111  27505812  1.040370              0.111088   \n",
       "\n",
       "     first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)  \\\n",
       "0                                                    0             \n",
       "1                                                    0             \n",
       "2                                                    0             \n",
       "3                                                    1             \n",
       "4                                                    1             \n",
       "..                                                 ...             \n",
       "107                                                  0             \n",
       "108                                                  1             \n",
       "109                                                  0             \n",
       "110                                                  1             \n",
       "111                                                  1             \n",
       "\n",
       "     first_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                          0   \n",
       "1                                          1   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "..                                       ...   \n",
       "107                                        0   \n",
       "108                                        0   \n",
       "109                                        0   \n",
       "110                                        0   \n",
       "111                                        0   \n",
       "\n",
       "     first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                    0   \n",
       "1                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "4                                                    0   \n",
       "..                                                 ...   \n",
       "107                                                  0   \n",
       "108                                                  0   \n",
       "109                                                  0   \n",
       "110                                                  0   \n",
       "111                                                  0   \n",
       "\n",
       "     first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                    0                 \n",
       "1                                                    0                 \n",
       "2                                                    0                 \n",
       "3                                                    0                 \n",
       "4                                                    0                 \n",
       "..                                                 ...                 \n",
       "107                                                  0                 \n",
       "108                                                  0                 \n",
       "109                                                  0                 \n",
       "110                                                  0                 \n",
       "111                                                  0                 \n",
       "\n",
       "     first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "..                                 ...                            ...   \n",
       "107                                  0                              0   \n",
       "108                                  0                              0   \n",
       "109                                  0                              0   \n",
       "110                                  0                              0   \n",
       "111                                  0                              0   \n",
       "\n",
       "     first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  ...  \\\n",
       "0                                                    0               ...   \n",
       "1                                                    0               ...   \n",
       "2                                                    0               ...   \n",
       "3                                                    0               ...   \n",
       "4                                                    0               ...   \n",
       "..                                                 ...               ...   \n",
       "107                                                  0               ...   \n",
       "108                                                  0               ...   \n",
       "109                                                  0               ...   \n",
       "110                                                  0               ...   \n",
       "111                                                  0               ...   \n",
       "\n",
       "     first_careunit_Trauma SICU (TSICU)  \\\n",
       "0                                     1   \n",
       "1                                     0   \n",
       "2                                     1   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "..                                  ...   \n",
       "107                                   0   \n",
       "108                                   0   \n",
       "109                                   1   \n",
       "110                                   0   \n",
       "111                                   0   \n",
       "\n",
       "     last_careunit_Cardiac Vascular Intensive Care Unit (CVICU)  \\\n",
       "0                                                    0            \n",
       "1                                                    0            \n",
       "2                                                    0            \n",
       "3                                                    1            \n",
       "4                                                    1            \n",
       "..                                                 ...            \n",
       "107                                                  0            \n",
       "108                                                  1            \n",
       "109                                                  0            \n",
       "110                                                  1            \n",
       "111                                                  1            \n",
       "\n",
       "     last_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                         0   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "..                                      ...   \n",
       "107                                       0   \n",
       "108                                       0   \n",
       "109                                       0   \n",
       "110                                       0   \n",
       "111                                       0   \n",
       "\n",
       "     last_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "..                                                ...   \n",
       "107                                                 0   \n",
       "108                                                 0   \n",
       "109                                                 0   \n",
       "110                                                 0   \n",
       "111                                                 0   \n",
       "\n",
       "     last_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                    0                \n",
       "1                                                    0                \n",
       "2                                                    0                \n",
       "3                                                    0                \n",
       "4                                                    0                \n",
       "..                                                 ...                \n",
       "107                                                  0                \n",
       "108                                                  0                \n",
       "109                                                  0                \n",
       "110                                                  0                \n",
       "111                                                  0                \n",
       "\n",
       "     last_careunit_Neuro Intermediate  last_careunit_Neuro Stepdown  \\\n",
       "0                                   0                             0   \n",
       "1                                   0                             0   \n",
       "2                                   0                             0   \n",
       "3                                   0                             0   \n",
       "4                                   0                             0   \n",
       "..                                ...                           ...   \n",
       "107                                 0                             0   \n",
       "108                                 0                             0   \n",
       "109                                 0                             0   \n",
       "110                                 0                             0   \n",
       "111                                 0                             0   \n",
       "\n",
       "     last_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "0                                                    0               \n",
       "1                                                    0               \n",
       "2                                                    0               \n",
       "3                                                    0               \n",
       "4                                                    0               \n",
       "..                                                 ...               \n",
       "107                                                  0               \n",
       "108                                                  0               \n",
       "109                                                  0               \n",
       "110                                                  0               \n",
       "111                                                  0               \n",
       "\n",
       "     last_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "0                                                    0   \n",
       "1                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "4                                                    0   \n",
       "..                                                 ...   \n",
       "107                                                  1   \n",
       "108                                                  0   \n",
       "109                                                  0   \n",
       "110                                                  0   \n",
       "111                                                  0   \n",
       "\n",
       "     last_careunit_Trauma SICU (TSICU)  \n",
       "0                                    1  \n",
       "1                                    0  \n",
       "2                                    1  \n",
       "3                                    0  \n",
       "4                                    0  \n",
       "..                                 ...  \n",
       "107                                  0  \n",
       "108                                  0  \n",
       "109                                  1  \n",
       "110                                  0  \n",
       "111                                  0  \n",
       "\n",
       "[112 rows x 21 columns]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "a1d160df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "114372e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "bf091126",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "3aed420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "a4c5c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "70846f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "e493e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "abd251db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d38cda",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "641ea469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:03<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "e38130d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.50      0.50      0.50         2\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         2\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         0\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       0.50      1.00      0.67         1\n",
      "         217       0.00      0.00      0.00         0\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       0.00      0.00      0.00         2\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.25      0.04      0.06        55\n",
      "   macro avg       0.00      0.01      0.00        55\n",
      "weighted avg       0.03      0.04      0.03        55\n",
      " samples avg       0.07      0.04      0.05        55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "04dc3e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.008779761904761905\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1667ca",
   "metadata": {},
   "source": [
    "### RAKEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "71684b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [16:12<00:00,  9.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03571428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.50      0.33      0.40         3\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.50      1.00      0.67         2\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         2\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         0\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.00      0.00      0.00         0\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       0.00      0.00      0.00         2\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.42      0.09      0.15        55\n",
      "   macro avg       0.01      0.01      0.01        55\n",
      "weighted avg       0.08      0.09      0.08        55\n",
      " samples avg       0.14      0.09      0.11        55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the base classifier (Random Forest)\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# Initialize the RAkEL classifier with the base classifier\n",
    "classifier = RakelD(base_classifier, labelset_size=3)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47468784",
   "metadata": {},
   "source": [
    "### outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "f95aef4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7489, 42)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "92fe6a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7489, 240)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "e54d1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"output_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"output_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "a70e781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "ffa567d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "f32b2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "108d3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "5b06fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "7d759b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "b76e9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "3f6accb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "10cd670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "eabfcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17fee79",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "80529c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [49:00<00:00, 29.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "1860488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17458622530699414\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.96      0.48      0.64       112\n",
      "           2       0.87      0.42      0.57        97\n",
      "           3       0.00      0.00      0.00        15\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.52      0.30      0.38        37\n",
      "           6       0.74      0.35      0.47        49\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.33      0.20      0.25         5\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      0.18      0.31        11\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.50      0.04      0.08        23\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       1.00      0.18      0.31        11\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.50      0.04      0.08        23\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         5\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00        22\n",
      "          27       0.50      0.20      0.29         5\n",
      "          28       0.33      0.08      0.12       168\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.33      0.05      0.08        21\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         4\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.17      0.05      0.07        21\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.25      0.05      0.09        19\n",
      "          42       0.47      0.13      0.21        53\n",
      "          43       0.00      0.00      0.00        22\n",
      "          44       0.57      0.35      0.43        46\n",
      "          45       0.65      0.37      0.47       144\n",
      "          46       0.80      0.40      0.53        10\n",
      "          47       0.00      0.00      0.00        22\n",
      "          48       0.33      0.10      0.15        20\n",
      "          49       0.00      0.00      0.00        10\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.36      0.13      0.20        30\n",
      "          52       0.00      0.00      0.00         4\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         9\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.17      0.05      0.07        21\n",
      "          61       0.67      0.43      0.53        23\n",
      "          62       0.50      0.07      0.12        14\n",
      "          63       0.00      0.00      0.00        18\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         4\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.32      0.08      0.13       190\n",
      "          71       0.33      0.08      0.13        12\n",
      "          72       0.25      0.05      0.09        19\n",
      "          73       0.53      0.13      0.21        63\n",
      "          74       0.50      0.30      0.37        10\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.33      0.14      0.20         7\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.80      0.40      0.53        10\n",
      "          82       0.57      0.35      0.43        46\n",
      "          83       0.60      0.08      0.14        37\n",
      "          84       0.69      0.37      0.48       107\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00        16\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         9\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00        11\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00        13\n",
      "          96       0.00      0.00      0.00         4\n",
      "          97       0.36      0.13      0.20        30\n",
      "          98       0.00      0.00      0.00         5\n",
      "          99       0.82      0.50      0.62        56\n",
      "         100       0.50      0.33      0.40         3\n",
      "         101       0.50      0.12      0.20        16\n",
      "         102       0.50      0.09      0.15        11\n",
      "         103       0.00      0.00      0.00        11\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.33      0.06      0.11        16\n",
      "         108       0.67      0.48      0.56        21\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00        10\n",
      "         111       0.00      0.00      0.00         8\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         2\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         3\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         4\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         7\n",
      "         123       0.50      0.11      0.18        18\n",
      "         124       0.77      0.52      0.62        69\n",
      "         125       0.00      0.00      0.00        10\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.33      0.14      0.20         7\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00        11\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         9\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00        21\n",
      "         136       0.00      0.00      0.00         8\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         4\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         5\n",
      "         149       0.84      0.73      0.78        37\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.50      0.13      0.21        23\n",
      "         153       0.50      0.20      0.29         5\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00        11\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         2\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         3\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       1.00      0.25      0.40         4\n",
      "         173       0.78      0.47      0.58        15\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.50      0.20      0.29         5\n",
      "         176       0.40      0.36      0.38        11\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.25      0.14      0.18         7\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.58      0.24      0.34        87\n",
      "         186       0.00      0.00      0.00        27\n",
      "         187       0.45      0.11      0.18       247\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.17      0.02      0.04        43\n",
      "         199       0.40      0.36      0.38        11\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       1.00      0.67      0.80         3\n",
      "         202       0.25      0.14      0.18         7\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       1.00      0.07      0.12        15\n",
      "         209       0.58      0.24      0.34        87\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00        27\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.12      0.02      0.03       101\n",
      "         216       0.55      0.19      0.28       146\n",
      "         217       0.00      0.00      0.00         0\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00        22\n",
      "         225       0.76      0.29      0.42        77\n",
      "         226       0.00      0.00      0.00        64\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       1.00      0.67      0.80         3\n",
      "         229       1.00      0.07      0.12        15\n",
      "         230       0.11      0.03      0.04        39\n",
      "         231       0.60      0.12      0.21        97\n",
      "         232       0.50      0.50      0.50         2\n",
      "         233       0.00      0.00      0.00        12\n",
      "         234       0.62      0.17      0.27       124\n",
      "         235       0.14      0.02      0.03        54\n",
      "         236       0.00      0.00      0.00         3\n",
      "         237       0.00      0.00      0.00         3\n",
      "         238       0.79      0.61      0.69        67\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.56      0.19      0.28      3591\n",
      "   macro avg       0.16      0.07      0.09      3591\n",
      "weighted avg       0.46      0.19      0.26      3591\n",
      " samples avg       0.21      0.20      0.20      3591\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "b32d7208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.007677077771845524\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ff1cb",
   "metadata": {},
   "source": [
    "### procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "e4224289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 162)"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "69ef67f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 240)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbf1edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"procedure_events_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedure_events_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74c6db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2755652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51ca95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd5cb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59a181c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "248c9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1db632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a890be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc82fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f230bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b92b49e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     14   20   21   22   23   24   25   26   27   39   ...  950  951  952  \\\n",
       "0      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "289    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "290    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "291    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "292    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "293    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "     956  957  981  982  983  987  988  \n",
       "0      0    0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "289    0    0    0    0    0    0    0  \n",
       "290    0    0    0    0    0    0    0  \n",
       "291    0    0    0    0    0    0    0  \n",
       "292    0    0    0    0    0    0    0  \n",
       "293    0    0    0    0    0    0    0  \n",
       "\n",
       "[294 rows x 240 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f88d5",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3128471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a90504a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eb0bc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     14   20   21   22   23   24   25   26   27   39   ...  950  951  952  \\\n",
       "0      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "289    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "290    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "291    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "292    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "293    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "     956  957  981  982  983  987  988  \n",
       "0      0    0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "289    0    0    0    0    0    0    0  \n",
       "290    0    0    0    0    0    0    0  \n",
       "291    0    0    0    0    0    0    0  \n",
       "292    0    0    0    0    0    0    0  \n",
       "293    0    0    0    0    0    0    0  \n",
       "\n",
       "[294 rows x 240 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "25ba56c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:28<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7244897959183674\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.90      0.93        21\n",
      "           2       0.80      0.80      0.80        10\n",
      "           3       1.00      0.25      0.40         4\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      0.75      0.86         8\n",
      "           6       1.00      1.00      1.00        13\n",
      "           7       1.00      0.75      0.86         4\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       1.00      1.00      1.00         1\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.96      1.00      0.98        26\n",
      "          29       1.00      0.50      0.67         2\n",
      "          30       0.67      1.00      0.80         2\n",
      "          31       1.00      1.00      1.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       1.00      0.20      0.33         5\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       1.00      0.67      0.80         3\n",
      "          42       0.88      0.64      0.74        11\n",
      "          43       1.00      1.00      1.00         6\n",
      "          44       1.00      0.86      0.92         7\n",
      "          45       0.81      0.74      0.77        23\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       0.00      0.00      0.00         5\n",
      "          48       1.00      1.00      1.00         9\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       1.00      1.00      1.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       1.00      0.20      0.33         5\n",
      "          61       1.00      1.00      1.00         4\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.96      0.93      0.95        29\n",
      "          71       0.50      1.00      0.67         1\n",
      "          72       1.00      0.67      0.80         3\n",
      "          73       0.86      0.55      0.67        11\n",
      "          74       1.00      0.50      0.67         2\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      0.86      0.92         7\n",
      "          83       0.62      1.00      0.77         5\n",
      "          84       0.92      0.67      0.77        18\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.67      0.29      0.40         7\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       1.00      1.00      1.00         1\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       1.00      0.33      0.50         6\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       1.00      1.00      1.00         3\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.94      0.94      0.94        18\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       1.00      1.00      1.00         7\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         1\n",
      "         104       1.00      0.50      0.67         2\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       1.00      1.00      1.00         3\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         2\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       1.00      1.00      1.00         1\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       1.00      0.50      0.67         2\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       1.00      1.00      1.00         2\n",
      "         125       0.00      0.00      0.00         3\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       1.00      1.00      1.00         1\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       1.00      1.00      1.00         1\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.80      0.57      0.67         7\n",
      "         136       1.00      0.33      0.50         3\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.92      0.92      0.92        13\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       1.00      1.00      1.00         5\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         2\n",
      "         155       1.00      0.50      0.67         2\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       1.00      1.00      1.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       1.00      0.33      0.50         3\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.83      1.00      0.91         5\n",
      "         186       1.00      1.00      1.00         5\n",
      "         187       0.84      0.87      0.85        30\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       1.00      1.00      1.00         6\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.83      1.00      0.91         5\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       1.00      1.00      1.00         5\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       1.00      1.00      1.00        12\n",
      "         216       0.75      0.83      0.79        18\n",
      "         217       0.00      0.00      0.00         0\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         5\n",
      "         225       0.94      1.00      0.97        16\n",
      "         226       1.00      1.00      1.00        10\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       1.00      0.75      0.86         4\n",
      "         231       1.00      1.00      1.00        14\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       1.00      1.00      1.00         1\n",
      "         234       0.96      1.00      0.98        23\n",
      "         235       1.00      1.00      1.00         9\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       1.00      1.00      1.00         3\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.76      0.83       579\n",
      "   macro avg       0.29      0.26      0.27       579\n",
      "weighted avg       0.83      0.76      0.78       579\n",
      " samples avg       0.79      0.76      0.77       579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "45230025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7244897959183674\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.90      0.93        21\n",
      "           2       0.80      0.80      0.80        10\n",
      "           3       1.00      0.25      0.40         4\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      0.75      0.86         8\n",
      "           6       1.00      1.00      1.00        13\n",
      "           7       1.00      0.75      0.86         4\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       1.00      1.00      1.00         1\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.96      1.00      0.98        26\n",
      "          29       1.00      0.50      0.67         2\n",
      "          30       0.67      1.00      0.80         2\n",
      "          31       1.00      1.00      1.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       1.00      0.20      0.33         5\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       1.00      0.67      0.80         3\n",
      "          42       0.88      0.64      0.74        11\n",
      "          43       1.00      1.00      1.00         6\n",
      "          44       1.00      0.86      0.92         7\n",
      "          45       0.81      0.74      0.77        23\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       0.00      0.00      0.00         5\n",
      "          48       1.00      1.00      1.00         9\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       1.00      1.00      1.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       1.00      0.20      0.33         5\n",
      "          61       1.00      1.00      1.00         4\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.96      0.93      0.95        29\n",
      "          71       0.50      1.00      0.67         1\n",
      "          72       1.00      0.67      0.80         3\n",
      "          73       0.86      0.55      0.67        11\n",
      "          74       1.00      0.50      0.67         2\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      0.86      0.92         7\n",
      "          83       0.62      1.00      0.77         5\n",
      "          84       0.92      0.67      0.77        18\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.67      0.29      0.40         7\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       1.00      1.00      1.00         1\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       1.00      0.33      0.50         6\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       1.00      1.00      1.00         3\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.94      0.94      0.94        18\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       1.00      1.00      1.00         7\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         1\n",
      "         104       1.00      0.50      0.67         2\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       1.00      1.00      1.00         3\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         2\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       1.00      1.00      1.00         1\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       1.00      0.50      0.67         2\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       1.00      1.00      1.00         2\n",
      "         125       0.00      0.00      0.00         3\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       1.00      1.00      1.00         1\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       1.00      1.00      1.00         1\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.80      0.57      0.67         7\n",
      "         136       1.00      0.33      0.50         3\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.92      0.92      0.92        13\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       1.00      1.00      1.00         5\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         2\n",
      "         155       1.00      0.50      0.67         2\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       1.00      1.00      1.00         1\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       1.00      0.33      0.50         3\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.83      1.00      0.91         5\n",
      "         186       1.00      1.00      1.00         5\n",
      "         187       0.84      0.87      0.85        30\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       1.00      1.00      1.00         6\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.83      1.00      0.91         5\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       1.00      1.00      1.00         5\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       1.00      1.00      1.00        12\n",
      "         216       0.75      0.83      0.79        18\n",
      "         217       0.00      0.00      0.00         0\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         5\n",
      "         225       0.94      1.00      0.97        16\n",
      "         226       1.00      1.00      1.00        10\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       1.00      0.75      0.86         4\n",
      "         231       1.00      1.00      1.00        14\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       1.00      1.00      1.00         1\n",
      "         234       0.96      1.00      0.98        23\n",
      "         235       1.00      1.00      1.00         9\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       1.00      1.00      1.00         3\n",
      "         239       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.76      0.83       579\n",
      "   macro avg       0.29      0.26      0.27       579\n",
      "weighted avg       0.83      0.76      0.78       579\n",
      " samples avg       0.79      0.76      0.77       579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "ecf152ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.0025085034013605442\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7509133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19407f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ff80bf",
   "metadata": {},
   "source": [
    "## Took too long to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67682005",
   "metadata": {},
   "source": [
    "### poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "5735370a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35022, 1458)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "70c415dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35022, 240)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "ff5ce3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"poe_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"poe_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "ab5aebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "17f73102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "cadb4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "ed316151",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "0e3a3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "b808096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "5ec1ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "90ae2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "999f9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9284180",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "5b353b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x000001DADD82D150>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 589, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n",
      "  0%|          | 0/100 [02:53<?, ?it/s]\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[10:58:32] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.cc:231: Check failed: accumulated_rows == Info().num_row_ (70044 vs. 35022) : ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[566], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the classifier with both input features (X_train) and target labels (y_train)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[1;32m---> 11\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mvalues, y_train\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:538\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    513\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:273\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    274\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y[:, i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    278\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:60\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     58\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1500\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[1;32m-> 1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1503\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   1504\u001b[0m     group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1505\u001b[0m     qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1506\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1507\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1508\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m   1509\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[0;32m   1510\u001b[0m     sample_weight_eval_set\u001b[38;5;241m=\u001b[39msample_weight_eval_set,\n\u001b[0;32m   1511\u001b[0m     base_margin_eval_set\u001b[38;5;241m=\u001b[39mbase_margin_eval_set,\n\u001b[0;32m   1512\u001b[0m     eval_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1513\u001b[0m     eval_qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1514\u001b[0m     create_dmatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dmatrix,\n\u001b[0;32m   1515\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1520\u001b[0m     params,\n\u001b[0;32m   1521\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1531\u001b[0m )\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:521\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    502\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    503\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    518\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m create_dmatrix(\n\u001b[0;32m    522\u001b[0m         data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    523\u001b[0m         label\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    524\u001b[0m         group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m    525\u001b[0m         qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[0;32m    526\u001b[0m         weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    527\u001b[0m         base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m    528\u001b[0m         feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m    529\u001b[0m         missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    530\u001b[0m         enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[0;32m    531\u001b[0m         feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m    532\u001b[0m         ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    535\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:958\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[0;32m    959\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, ref\u001b[38;5;241m=\u001b[39mref, nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m    960\u001b[0m         )\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:1529\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1510\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         )\n\u001b[0;32m   1523\u001b[0m     ):\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1525\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1526\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1527\u001b[0m         )\n\u001b[1;32m-> 1529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(\n\u001b[0;32m   1530\u001b[0m     data,\n\u001b[0;32m   1531\u001b[0m     ref\u001b[38;5;241m=\u001b[39mref,\n\u001b[0;32m   1532\u001b[0m     label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[0;32m   1533\u001b[0m     weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m   1534\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1535\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m   1536\u001b[0m     qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[0;32m   1537\u001b[0m     label_lower_bound\u001b[38;5;241m=\u001b[39mlabel_lower_bound,\n\u001b[0;32m   1538\u001b[0m     label_upper_bound\u001b[38;5;241m=\u001b[39mlabel_upper_bound,\n\u001b[0;32m   1539\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m   1540\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m   1541\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m   1542\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[0;32m   1543\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:1590\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1588\u001b[0m it\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m-> 1590\u001b[0m _check_call(ret)\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:282\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [10:58:32] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.cc:231: Check failed: accumulated_rows == Info().num_row_ (70044 vs. 35022) : "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7bc2d",
   "metadata": {},
   "source": [
    "###  prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "e041979f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14097, 4890)"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "c722fbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14097, 240)"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "a3b9e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"prescriptions_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"prescriptions_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "e2b261c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "9d5db6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "be0566e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "e18c6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "43f730a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "87337626",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "922a540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "88bcb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "0c6d708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "1330258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 4890 to 2874 or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "d433079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "[9.99925217e-01 4.51264065e-05 4.18328590e-06 ... 2.25190037e-36\n",
      " 5.20660165e-36 2.40845222e-36]\n",
      "\n",
      " Amount of original variance conserved: 0.9999999999999991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 2874\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "X_train = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "bfc0d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "[9.99927933e-01 4.23148006e-05 4.19434751e-06 ... 7.03449370e-38\n",
      " 1.14052715e-35 7.76366226e-38]\n",
      "\n",
      " Amount of original variance conserved: 0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "# Number of desired features (components)\n",
    "n_components = 2874\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_test)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd069ffb",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "3ffafcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [02:45<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[581], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the classifier with both input features (X_train) and target labels (y_train)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[1;32m---> 11\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:538\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    513\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:273\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    274\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y[:, i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    278\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:60\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     58\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1520\u001b[0m     params,\n\u001b[0;32m   1521\u001b[0m     train_dmatrix,\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1523\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1524\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1525\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1526\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1527\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1528\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1529\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1531\u001b[0m )\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2052\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2053\u001b[0m         )\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b12342",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7fa3d",
   "metadata": {},
   "source": [
    "### pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "0ccc29f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11983, 766)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "53fd9111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11983, 240)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "409213f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"pharmacy_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"pharmacy_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "b5e72f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['medication_duration']= X_train['medication_duration'].apply(convert_to_days)\n",
    "X_test['medication_duration']= X_test['medication_duration'].apply(convert_to_days)\n",
    "# Convert strings to integers\n",
    "X_train['verification_delay'] = X_train['verification_delay'].str.split().str[0].astype(int)\n",
    "X_test['verification_delay'] = X_test['verification_delay'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "dd1ead1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "bca6ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "21087575",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "fec05e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "f41b16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "dfec2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "171d2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "2e5c194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd07c1",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "6fd296d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [05:53<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[483], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the classifier with both input features (X_train) and target labels (y_train)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[1;32m---> 11\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mvalues, y_train\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:538\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    513\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:273\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    274\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y[:, i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    278\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:60\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     58\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1520\u001b[0m     params,\n\u001b[0;32m   1521\u001b[0m     train_dmatrix,\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1523\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1524\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1525\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1526\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1527\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1528\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1529\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1531\u001b[0m )\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2052\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2053\u001b[0m         )\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69170690",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e50caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99811ea",
   "metadata": {},
   "source": [
    "### inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "c9c2f333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16323, 221)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "0c3ddb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16323, 240)"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "e0a629b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"input_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"input_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "3e4bd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "ad2bcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "ea529ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "55ecc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "d60b3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "6a109978",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "21c5e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "67412db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "32cb575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "15879621",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64209275",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "3a7b1ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [2:32:20<1:50:19, 157.60s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[652], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the classifier with both input features (X_train) and target labels (y_train)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[1;32m---> 11\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mvalues, y_train\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:538\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    513\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:273\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    274\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y[:, i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    278\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:60\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     58\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1520\u001b[0m     params,\n\u001b[0;32m   1521\u001b[0m     train_dmatrix,\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1523\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1524\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1525\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1526\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1527\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1528\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1529\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1531\u001b[0m )\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2052\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2053\u001b[0m         )\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd445a",
   "metadata": {},
   "source": [
    "## Not enough memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a2e4c",
   "metadata": {},
   "source": [
    "### ingredientevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ead0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "7c20d4ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.18 GiB for an array with shape (7723, 20582) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[637], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mingredient_data_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m full_path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m file\n\u001b[1;32m----> 5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(full_path)\n\u001b[0;32m      7\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mingredient_data_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m full_path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m file\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1795\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1795\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(col_dict, columns\u001b[38;5;241m=\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:154\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    151\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    155\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2204\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate)\u001b[0m\n\u001b[0;32m   2202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2204\u001b[0m     mgr\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1871\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1873\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m _consolidate_with_refs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2329\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2327\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2329\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2330\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2388\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2385\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2387\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2388\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2389\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2391\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.18 GiB for an array with shape (7723, 20582) and data type int64"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"ingredient_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"ingredient_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f26273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed56fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b309e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194dd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd926774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 7727 to 4116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47885c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 4116\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "X_train = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c64999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 4116\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_test)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65576e",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc310ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1ec15",
   "metadata": {},
   "source": [
    "### chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "c9ba081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "# file = \"chart_data_train.csv\"\n",
    "# full_path = path + file\n",
    "# X_train = pd.read_csv(full_path)\n",
    "\n",
    "# file = \"chart_data_test.csv\"\n",
    "# full_path = path + file\n",
    "# X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58874fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "099cf17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2f4b4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fbdc5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "23c98e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "69145679",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "42e3c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a24c4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "96dbe6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad533f1",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a8bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd964a",
   "metadata": {},
   "source": [
    "### emar_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "1639c9fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 701. MiB for an array with shape (1594, 57614) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[500], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memar_detail_data_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m full_path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m file\n\u001b[1;32m----> 5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(full_path)\n\u001b[0;32m      7\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memar_detail_data_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m full_path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m file\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1795\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1795\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(col_dict, columns\u001b[38;5;241m=\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:154\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    151\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    155\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2204\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate)\u001b[0m\n\u001b[0;32m   2202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2204\u001b[0m     mgr\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1871\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1873\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m _consolidate_with_refs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2329\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2327\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2329\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2330\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2388\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2385\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2387\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2388\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2389\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2391\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 701. MiB for an array with shape (1594, 57614) and data type int64"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"emar_detail_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_detail_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "cd44452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize an empty list to store the chunks\n",
    "# chunks = []\n",
    "\n",
    "# # Define the chunk size (number of rows to read at a time)\n",
    "# chunksize = 1000  # Adjust as needed based on your system's memory\n",
    "\n",
    "# file = \"emar_detail_data_train.csv\"\n",
    "# full_path = path + file\n",
    "\n",
    "# for chunk in pd.read_csv(full_path, chunksize=chunksize):\n",
    "#     chunks.append(chunk)\n",
    "\n",
    "# # Concatenate the chunks into a single DataFrame\n",
    "# X_train = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# file = \"emar_detail_data_test.csv\"\n",
    "# full_path = path + file\n",
    "\n",
    "# for chunk in pd.read_csv(full_path, chunksize=chunksize):\n",
    "#     chunks.append(chunk)\n",
    "\n",
    "# # Concatenate the chunks into a single DataFrame\n",
    "# X_test = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "31f6e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "460539d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "a2b943d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "27822018",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "196a07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "fa0b9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "372a3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b50fce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88287ae8",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530602db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4908d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba350201",
   "metadata": {},
   "source": [
    "### labevents - can't allocate memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5204f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't allocate memory this way \n",
    "\n",
    "# path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "# file = \"labevents_data_train.csv\"\n",
    "# full_path = path + file\n",
    "# X_train = pd.read_csv(full_path)\n",
    "\n",
    "# file = \"labevents_data_test.csv\"\n",
    "# full_path = path + file\n",
    "# X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "96998c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "52969a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/labevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_labevents = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e52fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents['value'] = pd.to_numeric(df_labevents['value'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7e605ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature for days_since_admission using charttime - admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['charttime'] = pd.to_datetime(df_labevents['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_labevents = df_labevents.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_labevents['days_since_admission'] = df_labevents['charttime'] - df_labevents['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['days_since_admission'] = df_labevents['days_since_admission'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dcab22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add storetime - charttime feature called delay\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['storetime'] = pd.to_datetime(df_labevents['storetime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_labevents['delay'] = df_labevents['storetime'] - df_labevents['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['delay'] = df_labevents['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3609d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = df_labevents.drop(columns=['labevent_id','subject_id','order_provider_id','charttime','storetime','comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6c87830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For flag make abnormal = 1 and fill Null with 0\n",
    "df_labevents['flag'] = df_labevents['flag'].fillna(0)\n",
    "df_labevents['flag'] = df_labevents['flag'].replace('abnormal', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9aba6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For priority fill Null with N/A and then one hot encode\n",
    "df_labevents['priority'] = df_labevents['priority'].fillna('N/A')\n",
    "df_labevents = pd.get_dummies(df_labevents, columns=['priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "36f4bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = pd.get_dummies(df_labevents, columns=['valueuom','specimen_id','itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7966b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null values \n",
    "df_labevents = df_labevents.dropna()\n",
    "# Reduced from 107727 rows to 66660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1506ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = df_labevents.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a05baab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_52286</th>\n",
       "      <th>itemid_52312</th>\n",
       "      <th>itemid_52369</th>\n",
       "      <th>itemid_52391</th>\n",
       "      <th>itemid_52419</th>\n",
       "      <th>itemid_52425</th>\n",
       "      <th>itemid_52427</th>\n",
       "      <th>itemid_52769</th>\n",
       "      <th>itemid_52955</th>\n",
       "      <th>itemid_53153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>15.40</td>\n",
       "      <td>15.40</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>49.70</td>\n",
       "      <td>49.70</td>\n",
       "      <td>35.1</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "0  29600294.0  15.40     15.40             10.5             15.5     0   \n",
       "1  29600294.0   3.35      3.35              4.6              6.1     1   \n",
       "2  29600294.0  49.70     49.70             35.1             46.3     1   \n",
       "3  29600294.0  20.30     20.30              4.0             10.0     1   \n",
       "4  29600294.0  31.10     31.10             32.0             37.0     1   \n",
       "\n",
       "  days_since_admission           delay  priority_N/A  priority_ROUTINE  ...  \\\n",
       "0      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "1      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "2      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "3      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "4      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "\n",
       "   itemid_52286  itemid_52312  itemid_52369  itemid_52391  itemid_52419  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   itemid_52425  itemid_52427  itemid_52769  itemid_52955  itemid_53153  \n",
       "0             0             0             0             0             0  \n",
       "1             0             0             0             0             0  \n",
       "2             0             0             0             0             0  \n",
       "3             0             0             0             0             0  \n",
       "4             0             0             0             0             0  \n",
       "\n",
       "[5 rows x 11680 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labevents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f5639",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a2654c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (53328, 11680)\n",
      "Testing set shape: (13332, 11680)\n"
     ]
    }
   ],
   "source": [
    "data = df_labevents\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "labevents_data_train, labevents_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", labevents_data_train.shape)\n",
    "print(\"Testing set shape:\", labevents_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6de2978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labevents_data_train.drop(columns=['hadm_id'])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1bf78e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_52286</th>\n",
       "      <th>itemid_52312</th>\n",
       "      <th>itemid_52369</th>\n",
       "      <th>itemid_52391</th>\n",
       "      <th>itemid_52419</th>\n",
       "      <th>itemid_52425</th>\n",
       "      <th>itemid_52427</th>\n",
       "      <th>itemid_52769</th>\n",
       "      <th>itemid_52955</th>\n",
       "      <th>itemid_53153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99267</th>\n",
       "      <td>26793610.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 04:36:00</td>\n",
       "      <td>0 days 02:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106026</th>\n",
       "      <td>28998349.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7 days 03:35:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44791</th>\n",
       "      <td>22490490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5 days 15:25:00</td>\n",
       "      <td>0 days 02:06:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83275</th>\n",
       "      <td>28258130.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10 days 23:24:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100330</th>\n",
       "      <td>22205327.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>9 days 09:55:00</td>\n",
       "      <td>0 days 01:58:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hadm_id  value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "99267   26793610.0   19.0      19.0             22.0             32.0     1   \n",
       "106026  28998349.0   17.7      17.7             10.5             15.5     1   \n",
       "44791   22490490.0    0.0     134.0             70.0            100.0     1   \n",
       "83275   28258130.0   34.0      34.0             35.0             45.0     1   \n",
       "100330  22205327.0    2.4       2.4              1.6              2.6     0   \n",
       "\n",
       "       days_since_admission           delay  priority_N/A  priority_ROUTINE  \\\n",
       "99267       0 days 04:36:00 0 days 02:53:00             0                 1   \n",
       "106026      7 days 03:35:00 0 days 00:10:00             0                 1   \n",
       "44791       5 days 15:25:00 0 days 02:06:00             0                 1   \n",
       "83275      10 days 23:24:00 0 days 00:10:00             1                 0   \n",
       "100330      9 days 09:55:00 0 days 01:58:00             0                 0   \n",
       "\n",
       "        ...  itemid_52286  itemid_52312  itemid_52369  itemid_52391  \\\n",
       "99267   ...             0             0             0             0   \n",
       "106026  ...             0             0             0             0   \n",
       "44791   ...             0             0             0             0   \n",
       "83275   ...             0             0             0             0   \n",
       "100330  ...             0             0             0             0   \n",
       "\n",
       "        itemid_52419  itemid_52425  itemid_52427  itemid_52769  itemid_52955  \\\n",
       "99267              0             0             0             0             0   \n",
       "106026             0             0             0             0             0   \n",
       "44791              0             0             0             0             0   \n",
       "83275              0             0             0             0             0   \n",
       "100330             0             0             0             0             0   \n",
       "\n",
       "        itemid_53153  \n",
       "99267              0  \n",
       "106026             0  \n",
       "44791              0  \n",
       "83275              0  \n",
       "100330             0  \n",
       "\n",
       "[5 rows x 11680 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labevents_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2fc853f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# # Make sure the order is the same\n",
    "\n",
    "# # Extract the unique IDs from the column \n",
    "# train_ids = labevents_data_train['hadm_id'].unique()\n",
    "\n",
    "# # Filter to keep only rows where the id column is in train_ids\n",
    "# y_train = df_diagnoses[df_diagnoses['hadm_id'].isin(train_ids)]\n",
    "\n",
    "# test_ids = labevents_data_test['hadm_id'].unique()\n",
    "\n",
    "# # Filter to keep only rows where the id column is in train_ids\n",
    "# y_test = df_diagnoses[df_diagnoses['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f3348a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = labevents_data_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = labevents_data_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "094fe67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, labevents_data_train['hadm_id'], on='hadm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0f8bf947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52756</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52757</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52758</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52759</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52760</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52761 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "...         ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "52756  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52757  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52758  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52759  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52760  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "       957  981  982  983  987  988  \n",
       "0        0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  \n",
       "52756    0    0    0    0    0    0  \n",
       "52757    0    0    0    0    0    0  \n",
       "52758    0    0    0    0    0    0  \n",
       "52759    0    0    0    0    0    0  \n",
       "52760    0    0    0    0    0    0  \n",
       "\n",
       "[52761 rows x 241 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = merged_df\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "324a1efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13194</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13195</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13196</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13197</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13198</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13199 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "...         ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "13194  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13195  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13196  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13197  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13198  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "       957  981  982  983  987  988  \n",
       "0        0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  \n",
       "13194    0    0    0    0    0    0  \n",
       "13195    0    0    0    0    0    0  \n",
       "13196    0    0    0    0    0    0  \n",
       "13197    0    0    0    0    0    0  \n",
       "13198    0    0    0    0    0    0  \n",
       "\n",
       "[13199 rows x 241 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(y_test, labevents_data_test['hadm_id'], on='hadm_id')\n",
    "\n",
    "y_test = merged_df\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "57ed8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = labevents_data_train\n",
    "X_test = labevents_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f7007f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['delay']= X_train['delay'].astype(str)\n",
    "# X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "# X_train['days_since_admission'] = X_train['days_since_admission'].astype(str)\n",
    "# X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "\n",
    "# X_train = X_train.drop(columns=['hadm_id'])\n",
    "# X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "# y_train = y_train.drop(columns=['hadm_id'])\n",
    "# y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aa2eb130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_52286</th>\n",
       "      <th>itemid_52312</th>\n",
       "      <th>itemid_52369</th>\n",
       "      <th>itemid_52391</th>\n",
       "      <th>itemid_52419</th>\n",
       "      <th>itemid_52425</th>\n",
       "      <th>itemid_52427</th>\n",
       "      <th>itemid_52769</th>\n",
       "      <th>itemid_52955</th>\n",
       "      <th>itemid_53153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99267</th>\n",
       "      <td>26793610.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 04:36:00</td>\n",
       "      <td>0 days 02:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106026</th>\n",
       "      <td>28998349.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7 days 03:35:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44791</th>\n",
       "      <td>22490490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5 days 15:25:00</td>\n",
       "      <td>0 days 02:06:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83275</th>\n",
       "      <td>28258130.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10 days 23:24:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100330</th>\n",
       "      <td>22205327.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>9 days 09:55:00</td>\n",
       "      <td>0 days 01:58:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58478</th>\n",
       "      <td>28872262.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8 days 18:53:00</td>\n",
       "      <td>0 days 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>21476294.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21 days 10:06:00</td>\n",
       "      <td>0 days 01:08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89565</th>\n",
       "      <td>26467376.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 14:02:00</td>\n",
       "      <td>0 days 01:28:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>21476294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 12:06:00</td>\n",
       "      <td>0 days 02:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>29276678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6 days 05:14:00</td>\n",
       "      <td>0 days 10:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53328 rows × 11680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hadm_id  value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "99267   26793610.0   19.0      19.0             22.0             32.0     1   \n",
       "106026  28998349.0   17.7      17.7             10.5             15.5     1   \n",
       "44791   22490490.0    0.0     134.0             70.0            100.0     1   \n",
       "83275   28258130.0   34.0      34.0             35.0             45.0     1   \n",
       "100330  22205327.0    2.4       2.4              1.6              2.6     0   \n",
       "...            ...    ...       ...              ...              ...   ...   \n",
       "58478   28872262.0    3.9       3.9              3.3              5.1     0   \n",
       "9921    21476294.0  100.0     100.0             96.0            108.0     0   \n",
       "89565   26467376.0   68.5      68.5              9.4             12.5     1   \n",
       "1419    21476294.0    0.0       0.0              0.0              0.0     0   \n",
       "25176   29276678.0    0.0       0.0              0.0              0.0     0   \n",
       "\n",
       "       days_since_admission           delay  priority_N/A  priority_ROUTINE  \\\n",
       "99267       0 days 04:36:00 0 days 02:53:00             0                 1   \n",
       "106026      7 days 03:35:00 0 days 00:10:00             0                 1   \n",
       "44791       5 days 15:25:00 0 days 02:06:00             0                 1   \n",
       "83275      10 days 23:24:00 0 days 00:10:00             1                 0   \n",
       "100330      9 days 09:55:00 0 days 01:58:00             0                 0   \n",
       "...                     ...             ...           ...               ...   \n",
       "58478       8 days 18:53:00 0 days 01:00:00             0                 1   \n",
       "9921       21 days 10:06:00 0 days 01:08:00             0                 0   \n",
       "89565       0 days 14:02:00 0 days 01:28:00             0                 1   \n",
       "1419        0 days 12:06:00 0 days 02:15:00             0                 0   \n",
       "25176       6 days 05:14:00 0 days 10:15:00             0                 1   \n",
       "\n",
       "        ...  itemid_52286  itemid_52312  itemid_52369  itemid_52391  \\\n",
       "99267   ...             0             0             0             0   \n",
       "106026  ...             0             0             0             0   \n",
       "44791   ...             0             0             0             0   \n",
       "83275   ...             0             0             0             0   \n",
       "100330  ...             0             0             0             0   \n",
       "...     ...           ...           ...           ...           ...   \n",
       "58478   ...             0             0             0             0   \n",
       "9921    ...             0             0             0             0   \n",
       "89565   ...             0             0             0             0   \n",
       "1419    ...             0             0             0             0   \n",
       "25176   ...             0             0             0             0   \n",
       "\n",
       "        itemid_52419  itemid_52425  itemid_52427  itemid_52769  itemid_52955  \\\n",
       "99267              0             0             0             0             0   \n",
       "106026             0             0             0             0             0   \n",
       "44791              0             0             0             0             0   \n",
       "83275              0             0             0             0             0   \n",
       "100330             0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "58478              0             0             0             0             0   \n",
       "9921               0             0             0             0             0   \n",
       "89565              0             0             0             0             0   \n",
       "1419               0             0             0             0             0   \n",
       "25176              0             0             0             0             0   \n",
       "\n",
       "        itemid_53153  \n",
       "99267              0  \n",
       "106026             0  \n",
       "44791              0  \n",
       "83275              0  \n",
       "100330             0  \n",
       "...              ...  \n",
       "58478              0  \n",
       "9921               0  \n",
       "89565              0  \n",
       "1419               0  \n",
       "25176              0  \n",
       "\n",
       "[53328 rows x 11680 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d1b3e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].astype(str)\n",
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].astype(str)\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f8b9f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrices to address memory issue\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X_train_sparse = csr_matrix(X_train)\n",
    "X_test_sparse = csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc44518",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction - not enough memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d405c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 11681 to 10665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "393bd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['delay']= data['delay'].astype(str)\n",
    "# data['delay']= data['delay'].apply(convert_to_days)\n",
    "# data['days_since_admission'] = data['days_since_admission'].astype(str)\n",
    "# data['days_since_admission'] = data['days_since_admission'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "703c8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# # Number of desired features (components)\n",
    "# n_components = 10665\n",
    "\n",
    "# # Initialize Truncated SVD with the desired number of components\n",
    "# svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# # Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "# svd.fit(data)\n",
    "# data = svd.transform(data)\n",
    "\n",
    "# # Get the explained variance ratio (how much variance is explained by each component)\n",
    "# explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# # Print the transformed matrix and explained variance ratio\n",
    "# # print(\"Transformed Matrix:\")\n",
    "# # print(transformed_matrix)\n",
    "# print(\"\\nExplained Variance Ratio:\")\n",
    "# print(explained_variance_ratio)\n",
    "\n",
    "# print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "cee8b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4761923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "11000dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5f2b5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "995f01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a8e0437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "8a968612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6d6a05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324a74c",
   "metadata": {},
   "source": [
    "#### Multi-output decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8b2dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42, max_depth=50)\n",
    "\n",
    "# Initialize the multi-output classifier with the decision tree as the base estimator\n",
    "multi_output_tree = MultiOutputClassifier(decision_tree, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e3efb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the multi-output classifier\n",
    "multi_output_tree.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Predict the outputs for the test set\n",
    "y_pred = multi_output_tree.predict(X_test_sparse)\n",
    "\n",
    "# # Evaluate the accuracy of the multi-output classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5f883b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.00      0.01       370\n",
      "           1       0.00      0.00      0.00       112\n",
      "           2       0.00      0.00      0.00       101\n",
      "           3       0.00      0.00      0.00       137\n",
      "           4       0.08      0.00      0.01       504\n",
      "           5       0.00      0.00      0.00        85\n",
      "           6       0.00      0.00      0.00       184\n",
      "           7       0.00      0.00      0.00        36\n",
      "           8       0.00      0.00      0.00       322\n",
      "           9       0.00      0.00      0.00        27\n",
      "          10       0.00      0.00      0.00       123\n",
      "          11       0.00      0.00      0.00       352\n",
      "          12       0.00      0.00      0.00        72\n",
      "          13       0.00      0.00      0.00        30\n",
      "          14       0.00      0.00      0.00        46\n",
      "          15       0.00      0.00      0.00        11\n",
      "          16       0.00      0.00      0.00        32\n",
      "          17       0.03      0.00      0.01       311\n",
      "          18       0.00      0.00      0.00       117\n",
      "          19       0.00      0.00      0.00       257\n",
      "          20       0.00      0.00      0.00        27\n",
      "          21       0.00      0.00      0.00        19\n",
      "          22       0.00      0.00      0.00        31\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        49\n",
      "          25       0.00      0.00      0.00        38\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.03      0.00      0.00       404\n",
      "          28       0.00      0.00      0.00        32\n",
      "          29       0.00      0.00      0.00        55\n",
      "          30       0.00      0.00      0.00       156\n",
      "          31       0.00      0.00      0.00       150\n",
      "          32       0.03      0.00      0.01       271\n",
      "          33       0.00      0.00      0.00        34\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        64\n",
      "          36       0.00      0.00      0.00        46\n",
      "          37       0.00      0.00      0.00        93\n",
      "          38       0.00      0.00      0.00        38\n",
      "          39       0.00      0.00      0.00       232\n",
      "          40       0.06      0.02      0.03        43\n",
      "          41       0.00      0.00      0.00       118\n",
      "          42       0.00      0.00      0.00        36\n",
      "          43       0.00      0.00      0.00       151\n",
      "          44       0.00      0.00      0.00        77\n",
      "          45       0.00      0.00      0.00        24\n",
      "          46       0.00      0.00      0.00        57\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00        63\n",
      "          50       0.00      0.00      0.00         9\n",
      "          51       0.05      0.01      0.01       129\n",
      "          52       0.00      0.00      0.00        31\n",
      "          53       0.00      0.00      0.00       151\n",
      "          54       0.00      0.00      0.00        36\n",
      "          55       0.00      0.00      0.00       120\n",
      "          56       0.00      0.00      0.00         9\n",
      "          57       0.05      0.00      0.01       238\n",
      "          58       0.05      0.01      0.01       129\n",
      "          59       0.00      0.00      0.00       120\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00        93\n",
      "          62       0.03      0.00      0.00       383\n",
      "          63       0.11      0.01      0.01       529\n",
      "          64       0.00      0.00      0.00        46\n",
      "          65       0.00      0.00      0.00        32\n",
      "          66       0.00      0.00      0.00        77\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00        22\n",
      "          69       0.00      0.00      0.00        17\n",
      "          70       0.00      0.00      0.00       118\n",
      "          71       0.00      0.00      0.00        42\n",
      "          72       0.05      0.00      0.00       634\n",
      "          73       0.00      0.00      0.00        11\n",
      "          74       0.00      0.00      0.00       106\n",
      "          75       0.05      0.00      0.00      1071\n",
      "          76       0.06      0.00      0.01       322\n",
      "          77       0.00      0.00      0.00       118\n",
      "          78       0.10      0.02      0.03        53\n",
      "          79       0.00      0.00      0.00        59\n",
      "          80       0.00      0.00      0.00        71\n",
      "          81       0.00      0.00      0.00        11\n",
      "          82       0.00      0.00      0.00       133\n",
      "          83       0.00      0.00      0.00        24\n",
      "          84       0.00      0.00      0.00        58\n",
      "          85       0.00      0.00      0.00        12\n",
      "          86       0.00      0.00      0.00        25\n",
      "          87       0.00      0.00      0.00       155\n",
      "          88       0.00      0.00      0.00        27\n",
      "          89       0.00      0.00      0.00       846\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.00      0.00      0.00        78\n",
      "          92       0.08      0.00      0.01       814\n",
      "          93       0.21      0.01      0.02      2290\n",
      "          94       0.03      0.00      0.01       340\n",
      "          95       0.09      0.01      0.01       318\n",
      "          96       0.00      0.00      0.00       180\n",
      "          97       0.00      0.00      0.00       120\n",
      "          98       0.03      0.00      0.00       938\n",
      "          99       0.10      0.00      0.01       982\n",
      "         100       0.07      0.00      0.00      1203\n",
      "         101       0.07      0.01      0.02       218\n",
      "         102       0.00      0.00      0.00        98\n",
      "         103       0.00      0.00      0.00        55\n",
      "         104       0.00      0.00      0.00        99\n",
      "         105       0.00      0.00      0.00       499\n",
      "         106       0.00      0.00      0.00       643\n",
      "         107       0.07      0.00      0.01       619\n",
      "         108       0.00      0.00      0.00        70\n",
      "         109       0.13      0.00      0.01       932\n",
      "         110       0.00      0.00      0.00       139\n",
      "         111       0.00      0.00      0.00       244\n",
      "         112       0.00      0.00      0.00        66\n",
      "         113       0.00      0.00      0.00        44\n",
      "         114       0.08      0.01      0.01       176\n",
      "         115       0.00      0.00      0.00        70\n",
      "         116       0.00      0.00      0.00       327\n",
      "         117       0.06      0.00      0.00       475\n",
      "         118       0.00      0.00      0.00       128\n",
      "         119       0.00      0.00      0.00       321\n",
      "         120       0.00      0.00      0.00       120\n",
      "         121       0.10      0.01      0.01      1479\n",
      "         122       0.00      0.00      0.00       237\n",
      "         123       0.00      0.00      0.00       239\n",
      "         124       0.04      0.00      0.01       230\n",
      "         125       0.03      0.00      0.00       939\n",
      "         126       0.00      0.00      0.00       258\n",
      "         127       0.00      0.00      0.00       368\n",
      "         128       0.00      0.00      0.00       128\n",
      "         129       0.00      0.00      0.00        58\n",
      "         130       0.00      0.00      0.00        28\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00       397\n",
      "         133       0.00      0.00      0.00        66\n",
      "         134       0.00      0.00      0.00       139\n",
      "         135       0.04      0.00      0.01       247\n",
      "         136       0.00      0.00      0.00        56\n",
      "         137       0.00      0.00      0.00        92\n",
      "         138       0.00      0.00      0.00        22\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00        18\n",
      "         143       0.00      0.00      0.00        41\n",
      "         144       0.10      0.01      0.02       161\n",
      "         145       0.00      0.00      0.00       439\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00        72\n",
      "         148       0.00      0.00      0.00        23\n",
      "         149       0.00      0.00      0.00        60\n",
      "         150       0.14      0.01      0.01       277\n",
      "         151       0.00      0.00      0.00        36\n",
      "         152       0.00      0.00      0.00       119\n",
      "         153       0.03      0.00      0.00       425\n",
      "         154       0.00      0.00      0.00        44\n",
      "         155       0.00      0.00      0.00       181\n",
      "         156       0.00      0.00      0.00       744\n",
      "         157       0.00      0.00      0.00         7\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         4\n",
      "         160       0.00      0.00      0.00       130\n",
      "         161       0.00      0.00      0.00       109\n",
      "         162       0.06      0.00      0.01      1055\n",
      "         163       0.00      0.00      0.00       117\n",
      "         164       0.00      0.00      0.00       110\n",
      "         165       0.00      0.00      0.00        51\n",
      "         166       0.03      0.00      0.01       297\n",
      "         167       0.00      0.00      0.00        66\n",
      "         168       0.00      0.00      0.00         8\n",
      "         169       0.00      0.00      0.00        12\n",
      "         170       0.00      0.00      0.00        25\n",
      "         171       0.00      0.00      0.00        46\n",
      "         172       0.00      0.00      0.00       195\n",
      "         173       0.00      0.00      0.00         5\n",
      "         174       0.05      0.01      0.01       180\n",
      "         175       0.07      0.00      0.01       427\n",
      "         176       0.00      0.00      0.00       258\n",
      "         177       0.00      0.00      0.00        51\n",
      "         178       0.00      0.00      0.00       117\n",
      "         179       0.00      0.00      0.00        65\n",
      "         180       0.00      0.00      0.00        31\n",
      "         181       0.00      0.00      0.00        44\n",
      "         182       0.00      0.00      0.00        46\n",
      "         183       0.00      0.00      0.00        98\n",
      "         184       0.10      0.00      0.01       603\n",
      "         185       0.06      0.00      0.01       247\n",
      "         186       0.00      0.00      0.00       154\n",
      "         187       0.00      0.00      0.00        24\n",
      "         188       0.00      0.00      0.00       137\n",
      "         189       0.00      0.00      0.00        93\n",
      "         190       0.00      0.00      0.00       233\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00       136\n",
      "         193       0.00      0.00      0.00       103\n",
      "         194       0.00      0.00      0.00       118\n",
      "         195       0.00      0.00      0.00        71\n",
      "         196       0.00      0.00      0.00        36\n",
      "         197       0.00      0.00      0.00        77\n",
      "         198       0.00      0.00      0.00        77\n",
      "         199       0.00      0.00      0.00        44\n",
      "         200       0.00      0.00      0.00        12\n",
      "         201       0.00      0.00      0.00        14\n",
      "         202       0.00      0.00      0.00        14\n",
      "         203       0.00      0.00      0.00        44\n",
      "         204       0.00      0.00      0.00        47\n",
      "         205       0.00      0.00      0.00        66\n",
      "         206       0.00      0.00      0.00        36\n",
      "         207       0.00      0.00      0.00        39\n",
      "         208       0.15      0.01      0.01      2699\n",
      "         209       0.00      0.00      0.00       117\n",
      "         210       0.03      0.00      0.00      1266\n",
      "         211       0.00      0.00      0.00        45\n",
      "         212       0.00      0.00      0.00        39\n",
      "         213       0.00      0.00      0.00       150\n",
      "         214       0.00      0.00      0.00       103\n",
      "         215       0.00      0.00      0.00        33\n",
      "         216       0.00      0.00      0.00       241\n",
      "         217       0.00      0.00      0.00        50\n",
      "         218       0.00      0.00      0.00        88\n",
      "         219       0.21      0.01      0.01      1375\n",
      "         220       0.00      0.00      0.00        21\n",
      "         221       0.00      0.00      0.00       107\n",
      "         222       0.00      0.00      0.00        82\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00        32\n",
      "         225       0.00      0.00      0.00        31\n",
      "         226       0.08      0.01      0.01       312\n",
      "         227       0.00      0.00      0.00        31\n",
      "         228       0.00      0.00      0.00        79\n",
      "         229       0.10      0.00      0.01       626\n",
      "         230       0.00      0.00      0.00       157\n",
      "         231       0.04      0.00      0.01       247\n",
      "         232       0.00      0.00      0.00        92\n",
      "         233       0.00      0.00      0.00        14\n",
      "         234       0.00      0.00      0.00        77\n",
      "         235       0.00      0.00      0.00        92\n",
      "         236       0.04      0.00      0.01       284\n",
      "         237       0.03      0.00      0.00       521\n",
      "         238       0.09      0.00      0.00      1696\n",
      "         239       0.00      0.00      0.00        72\n",
      "         240       0.00      0.00      0.00        51\n",
      "         241       0.00      0.00      0.00       130\n",
      "         242       0.05      0.00      0.00      1500\n",
      "         243       0.05      0.01      0.01       139\n",
      "         244       0.00      0.00      0.00        59\n",
      "         245       0.00      0.00      0.00       213\n",
      "         246       0.00      0.00      0.00         0\n",
      "         247       0.00      0.00      0.00        34\n",
      "         248       0.06      0.01      0.01       257\n",
      "         249       0.00      0.00      0.00        51\n",
      "         250       0.00      0.00      0.00        85\n",
      "         251       0.00      0.00      0.00        21\n",
      "         252       0.00      0.00      0.00        77\n",
      "         253       0.00      0.00      0.00        54\n",
      "         254       0.00      0.00      0.00        17\n",
      "         255       0.00      0.00      0.00       134\n",
      "         256       0.00      0.00      0.00        24\n",
      "         257       0.00      0.00      0.00        26\n",
      "         258       0.00      0.00      0.00        84\n",
      "         259       0.00      0.00      0.00        37\n",
      "         260       0.00      0.00      0.00       112\n",
      "         261       0.00      0.00      0.00        42\n",
      "         262       0.00      0.00      0.00       125\n",
      "         263       0.00      0.00      0.00         7\n",
      "         264       0.00      0.00      0.00         6\n",
      "         265       0.00      0.00      0.00        10\n",
      "         266       0.00      0.00      0.00       118\n",
      "         267       0.05      0.01      0.01       181\n",
      "         268       0.00      0.00      0.00       214\n",
      "         269       0.00      0.00      0.00       151\n",
      "         270       0.00      0.00      0.00         0\n",
      "         271       0.06      0.00      0.01       244\n",
      "         272       0.07      0.01      0.01       192\n",
      "         273       0.00      0.00      0.00        17\n",
      "         274       0.00      0.00      0.00        32\n",
      "         275       0.00      0.00      0.00         8\n",
      "         276       0.00      0.00      0.00       155\n",
      "         277       0.00      0.00      0.00        45\n",
      "         278       0.00      0.00      0.00       151\n",
      "         279       0.00      0.00      0.00        12\n",
      "         280       0.00      0.00      0.00        77\n",
      "         281       0.04      0.00      0.00       423\n",
      "         282       0.00      0.00      0.00        14\n",
      "         283       0.00      0.00      0.00       597\n",
      "         284       0.04      0.00      0.01       247\n",
      "         285       0.00      0.00      0.00        89\n",
      "         286       0.00      0.00      0.00        45\n",
      "         287       0.00      0.00      0.00       120\n",
      "         288       0.00      0.00      0.00        11\n",
      "         289       0.00      0.00      0.00       254\n",
      "         290       0.00      0.00      0.00        35\n",
      "         291       0.00      0.00      0.00       258\n",
      "         292       0.00      0.00      0.00       184\n",
      "         293       0.04      0.00      0.01       284\n",
      "         294       0.00      0.00      0.00        77\n",
      "         295       0.00      0.00      0.00       117\n",
      "         296       0.00      0.00      0.00        36\n",
      "         297       0.04      0.00      0.01       245\n",
      "         298       0.10      0.00      0.01       507\n",
      "         299       0.00      0.00      0.00        32\n",
      "         300       0.00      0.00      0.00        25\n",
      "         301       0.00      0.00      0.00         5\n",
      "         302       0.06      0.00      0.00       788\n",
      "         303       0.00      0.00      0.00       148\n",
      "         304       0.00      0.00      0.00       365\n",
      "         305       0.00      0.00      0.00       538\n",
      "         306       0.00      0.00      0.00        46\n",
      "         307       0.00      0.00      0.00        36\n",
      "         308       0.00      0.00      0.00       123\n",
      "         309       0.00      0.00      0.00       411\n",
      "         310       0.00      0.00      0.00        35\n",
      "         311       0.00      0.00      0.00       379\n",
      "         312       0.05      0.01      0.01       121\n",
      "         313       0.00      0.00      0.00        66\n",
      "         314       0.00      0.00      0.00       433\n",
      "         315       0.06      0.00      0.01       267\n",
      "         316       0.04      0.00      0.01       284\n",
      "         317       0.00      0.00      0.00       155\n",
      "         318       0.05      0.00      0.00      1568\n",
      "         319       0.00      0.00      0.00       114\n",
      "         320       0.00      0.00      0.00        21\n",
      "         321       0.00      0.00      0.00        70\n",
      "         322       0.00      0.00      0.00        62\n",
      "         323       0.00      0.00      0.00        44\n",
      "         324       0.05      0.00      0.00      1034\n",
      "         325       0.00      0.00      0.00       177\n",
      "         326       0.00      0.00      0.00        84\n",
      "         327       0.00      0.00      0.00        62\n",
      "         328       0.00      0.00      0.00        82\n",
      "         329       0.00      0.00      0.00        62\n",
      "         330       0.00      0.00      0.00       262\n",
      "         331       0.00      0.00      0.00        12\n",
      "         332       0.00      0.00      0.00       155\n",
      "         333       0.00      0.00      0.00       155\n",
      "         334       0.00      0.00      0.00        20\n",
      "         335       0.00      0.00      0.00        36\n",
      "         336       0.07      0.01      0.01       192\n",
      "         337       0.00      0.00      0.00       224\n",
      "         338       0.00      0.00      0.00       136\n",
      "         339       0.00      0.00      0.00        91\n",
      "         340       0.00      0.00      0.00       508\n",
      "         341       0.08      0.01      0.01       357\n",
      "         342       0.00      0.00      0.00        10\n",
      "         343       0.00      0.00      0.00       595\n",
      "         344       0.07      0.01      0.01       192\n",
      "         345       0.00      0.00      0.00       384\n",
      "         346       0.00      0.00      0.00       224\n",
      "         347       0.00      0.00      0.00       302\n",
      "         348       0.00      0.00      0.00       184\n",
      "         349       0.00      0.00      0.00       187\n",
      "         350       0.00      0.00      0.00       155\n",
      "         351       0.00      0.00      0.00        26\n",
      "         352       0.00      0.00      0.00       234\n",
      "         353       0.00      0.00      0.00       151\n",
      "         354       0.00      0.00      0.00       103\n",
      "         355       0.00      0.00      0.00        38\n",
      "         356       0.00      0.00      0.00        62\n",
      "         357       0.10      0.03      0.05        32\n",
      "         358       0.04      0.00      0.00       455\n",
      "         359       0.00      0.00      0.00       129\n",
      "         360       0.00      0.00      0.00       164\n",
      "         361       0.00      0.00      0.00       189\n",
      "         362       0.04      0.00      0.01       284\n",
      "         363       0.03      0.01      0.01       191\n",
      "         364       0.00      0.00      0.00        45\n",
      "         365       0.04      0.00      0.00       444\n",
      "         366       0.03      0.00      0.01       242\n",
      "         367       0.00      0.00      0.00       258\n",
      "         368       0.00      0.00      0.00        22\n",
      "         369       0.00      0.00      0.00        36\n",
      "         370       0.05      0.01      0.01       139\n",
      "         371       0.00      0.00      0.00       117\n",
      "         372       0.00      0.00      0.00       137\n",
      "         373       0.00      0.00      0.00       487\n",
      "         374       0.00      0.00      0.00        84\n",
      "         375       0.03      0.00      0.00       370\n",
      "         376       0.00      0.00      0.00        17\n",
      "         377       0.00      0.00      0.00       156\n",
      "         378       0.00      0.00      0.00       297\n",
      "         379       0.00      0.00      0.00       137\n",
      "         380       0.00      0.00      0.00       117\n",
      "         381       0.05      0.01      0.01       183\n",
      "         382       0.08      0.00      0.01      1156\n",
      "         383       0.11      0.00      0.01      1272\n",
      "         384       0.04      0.00      0.00       685\n",
      "         385       0.00      0.00      0.00        10\n",
      "         386       0.00      0.00      0.00        35\n",
      "         387       0.04      0.00      0.00       828\n",
      "         388       0.00      0.00      0.00        11\n",
      "         389       0.00      0.00      0.00        65\n",
      "         390       0.00      0.00      0.00        38\n",
      "         391       0.00      0.00      0.00        27\n",
      "         392       0.06      0.01      0.01       151\n",
      "         393       0.00      0.00      0.00        10\n",
      "         394       0.00      0.00      0.00       106\n",
      "         395       0.15      0.00      0.01      1304\n",
      "         396       0.00      0.00      0.00        44\n",
      "         397       0.00      0.00      0.00        22\n",
      "         398       0.00      0.00      0.00        65\n",
      "         399       0.00      0.00      0.00        22\n",
      "         400       0.08      0.01      0.02        79\n",
      "         401       0.00      0.00      0.00        80\n",
      "         402       0.04      0.00      0.01       284\n",
      "         403       0.00      0.00      0.00       258\n",
      "         404       0.10      0.02      0.03        53\n",
      "         405       0.00      0.00      0.00        12\n",
      "         406       0.00      0.00      0.00        12\n",
      "         407       0.00      0.00      0.00         5\n",
      "         408       0.00      0.00      0.00         0\n",
      "         409       0.10      0.02      0.03        53\n",
      "         410       0.00      0.00      0.00         7\n",
      "         411       0.00      0.00      0.00       192\n",
      "         412       0.00      0.00      0.00        32\n",
      "         413       0.00      0.00      0.00        71\n",
      "         414       0.00      0.00      0.00        77\n",
      "         415       0.04      0.00      0.01       284\n",
      "         416       0.00      0.00      0.00        83\n",
      "         417       0.00      0.00      0.00       169\n",
      "         418       0.00      0.00      0.00        32\n",
      "         419       0.00      0.00      0.00       118\n",
      "         420       0.05      0.01      0.01       129\n",
      "         421       0.00      0.00      0.00       146\n",
      "         422       0.00      0.00      0.00         9\n",
      "         423       0.00      0.00      0.00       120\n",
      "         424       0.06      0.00      0.01       262\n",
      "         425       0.00      0.00      0.00         6\n",
      "         426       0.00      0.00      0.00        13\n",
      "         427       0.00      0.00      0.00       122\n",
      "         428       0.00      0.00      0.00        77\n",
      "         429       0.00      0.00      0.00       262\n",
      "         430       0.00      0.00      0.00        44\n",
      "         431       0.00      0.00      0.00        96\n",
      "         432       0.00      0.00      0.00        47\n",
      "         433       0.00      0.00      0.00        36\n",
      "         434       0.00      0.00      0.00        68\n",
      "         435       0.00      0.00      0.00        44\n",
      "         436       0.00      0.00      0.00        12\n",
      "         437       0.00      0.00      0.00        24\n",
      "         438       0.00      0.00      0.00        24\n",
      "         439       0.00      0.00      0.00        53\n",
      "         440       0.00      0.00      0.00        53\n",
      "         441       0.00      0.00      0.00        25\n",
      "         442       0.00      0.00      0.00        33\n",
      "         443       0.05      0.01      0.01       181\n",
      "         444       0.00      0.00      0.00        24\n",
      "         445       0.04      0.00      0.01       284\n",
      "         446       0.00      0.00      0.00       155\n",
      "         447       0.00      0.00      0.00        12\n",
      "         448       0.00      0.00      0.00        31\n",
      "         449       0.00      0.00      0.00         5\n",
      "         450       0.00      0.00      0.00        93\n",
      "         451       0.00      0.00      0.00        41\n",
      "         452       0.00      0.00      0.00        41\n",
      "         453       0.05      0.00      0.01       260\n",
      "         454       0.00      0.00      0.00        33\n",
      "         455       0.05      0.01      0.01       139\n",
      "         456       0.00      0.00      0.00        13\n",
      "         457       0.00      0.00      0.00        93\n",
      "         458       0.00      0.00      0.00        39\n",
      "         459       0.00      0.00      0.00        10\n",
      "         460       0.00      0.00      0.00        33\n",
      "         461       0.04      0.00      0.01       247\n",
      "         462       0.00      0.00      0.00         1\n",
      "         463       0.00      0.00      0.00        24\n",
      "         464       0.00      0.00      0.00       185\n",
      "         465       0.00      0.00      0.00        32\n",
      "         466       0.00      0.00      0.00       185\n",
      "         467       0.00      0.00      0.00        44\n",
      "         468       0.00      0.00      0.00       258\n",
      "         469       0.00      0.00      0.00        43\n",
      "         470       0.00      0.00      0.00        13\n",
      "         471       0.00      0.00      0.00        27\n",
      "         472       0.00      0.00      0.00       151\n",
      "         473       0.00      0.00      0.00       306\n",
      "         474       0.00      0.00      0.00        93\n",
      "         475       0.00      0.00      0.00        24\n",
      "         476       0.00      0.00      0.00        31\n",
      "         477       0.00      0.00      0.00       135\n",
      "         478       0.03      0.00      0.01       306\n",
      "         479       0.08      0.01      0.01       176\n",
      "         480       0.00      0.00      0.00       215\n",
      "         481       0.00      0.00      0.00       117\n",
      "         482       0.00      0.00      0.00         0\n",
      "         483       0.00      0.00      0.00        32\n",
      "         484       0.00      0.00      0.00        48\n",
      "         485       0.00      0.00      0.00        24\n",
      "         486       0.00      0.00      0.00        57\n",
      "         487       0.00      0.00      0.00        17\n",
      "         488       0.00      0.00      0.00       227\n",
      "         489       0.00      0.00      0.00       463\n",
      "         490       0.00      0.00      0.00         0\n",
      "         491       0.00      0.00      0.00        17\n",
      "         492       0.05      0.01      0.01       139\n",
      "         493       0.00      0.00      0.00       663\n",
      "         494       0.00      0.00      0.00        26\n",
      "         495       0.00      0.00      0.00       155\n",
      "         496       0.00      0.00      0.00        26\n",
      "         497       0.00      0.00      0.00       120\n",
      "         498       0.00      0.00      0.00        89\n",
      "         499       0.08      0.01      0.01       176\n",
      "         500       0.00      0.00      0.00       449\n",
      "         501       0.05      0.01      0.01       194\n",
      "         502       0.00      0.00      0.00        44\n",
      "         503       0.00      0.00      0.00        35\n",
      "         504       0.09      0.00      0.01       596\n",
      "         505       0.00      0.00      0.00       718\n",
      "         506       0.00      0.00      0.00        12\n",
      "         507       0.00      0.00      0.00       100\n",
      "         508       0.00      0.00      0.00       224\n",
      "         509       0.00      0.00      0.00       155\n",
      "         510       0.00      0.00      0.00        11\n",
      "         511       0.00      0.00      0.00         5\n",
      "         512       0.00      0.00      0.00        12\n",
      "         513       0.07      0.00      0.01       660\n",
      "         514       0.00      0.00      0.00       118\n",
      "         515       0.00      0.00      0.00        24\n",
      "         516       0.05      0.01      0.01       139\n",
      "         517       0.12      0.00      0.01       545\n",
      "         518       0.00      0.00      0.00        73\n",
      "         519       0.05      0.01      0.01       139\n",
      "         520       0.05      0.00      0.00       392\n",
      "         521       0.00      0.00      0.00       367\n",
      "         522       0.00      0.00      0.00        19\n",
      "         523       0.00      0.00      0.00        88\n",
      "         524       0.00      0.00      0.00       161\n",
      "         525       0.00      0.00      0.00        24\n",
      "         526       0.00      0.00      0.00       412\n",
      "         527       0.00      0.00      0.00       167\n",
      "         528       0.00      0.00      0.00        15\n",
      "         529       0.04      0.00      0.01       284\n",
      "         530       0.04      0.00      0.01       290\n",
      "         531       0.09      0.01      0.01       295\n",
      "         532       0.00      0.00      0.00        25\n",
      "         533       0.05      0.00      0.01       330\n",
      "         534       0.00      0.00      0.00         8\n",
      "         535       0.00      0.00      0.00        32\n",
      "         536       0.00      0.00      0.00        44\n",
      "         537       0.07      0.01      0.01       192\n",
      "         538       0.00      0.00      0.00        11\n",
      "         539       0.00      0.00      0.00        37\n",
      "         540       0.00      0.00      0.00        46\n",
      "         541       0.04      0.00      0.01       284\n",
      "         542       0.00      0.00      0.00        66\n",
      "         543       0.00      0.00      0.00        60\n",
      "         544       0.00      0.00      0.00        44\n",
      "         545       0.00      0.00      0.00        10\n",
      "         546       0.00      0.00      0.00        55\n",
      "         547       0.00      0.00      0.00        33\n",
      "         548       0.04      0.00      0.01       284\n",
      "         549       0.04      0.00      0.01       284\n",
      "         550       0.04      0.00      0.01       284\n",
      "         551       0.04      0.00      0.01       284\n",
      "         552       0.04      0.00      0.01       284\n",
      "         553       0.04      0.00      0.01       284\n",
      "         554       0.04      0.00      0.01       284\n",
      "         555       0.04      0.00      0.01       284\n",
      "         556       0.11      0.01      0.02        95\n",
      "         557       0.00      0.00      0.00        31\n",
      "         558       0.00      0.00      0.00        66\n",
      "         559       0.00      0.00      0.00        44\n",
      "         560       0.00      0.00      0.00         6\n",
      "         561       0.04      0.00      0.01       247\n",
      "         562       0.04      0.00      0.01       284\n",
      "         563       0.04      0.00      0.01       284\n",
      "         564       0.00      0.00      0.00        13\n",
      "         565       0.00      0.00      0.00        12\n",
      "         566       0.04      0.00      0.00       461\n",
      "         567       0.05      0.00      0.00       908\n",
      "         568       0.07      0.01      0.01       192\n",
      "         569       0.00      0.00      0.00         4\n",
      "         570       0.00      0.00      0.00        92\n",
      "         571       0.00      0.00      0.00        49\n",
      "         572       0.00      0.00      0.00        19\n",
      "         573       0.09      0.01      0.01       343\n",
      "         574       0.00      0.00      0.00        21\n",
      "         575       0.03      0.00      0.00       405\n",
      "         576       0.03      0.00      0.01       268\n",
      "         577       0.05      0.01      0.01       150\n",
      "         578       0.07      0.01      0.01       192\n",
      "         579       0.00      0.00      0.00       193\n",
      "         580       0.00      0.00      0.00       230\n",
      "         581       0.00      0.00      0.00        62\n",
      "         582       0.00      0.00      0.00       238\n",
      "         583       0.00      0.00      0.00       308\n",
      "         584       0.00      0.00      0.00        51\n",
      "         585       0.13      0.01      0.02       208\n",
      "         586       0.00      0.00      0.00       258\n",
      "         587       0.07      0.01      0.02        69\n",
      "         588       0.04      0.00      0.01       256\n",
      "         589       0.05      0.01      0.01       176\n",
      "         590       0.00      0.00      0.00        16\n",
      "         591       0.00      0.00      0.00        76\n",
      "         592       0.00      0.00      0.00        34\n",
      "         593       0.00      0.00      0.00       373\n",
      "         594       0.00      0.00      0.00        39\n",
      "         595       0.10      0.00      0.01       908\n",
      "         596       0.00      0.00      0.00       174\n",
      "         597       0.00      0.00      0.00        77\n",
      "         598       0.00      0.00      0.00       172\n",
      "         599       0.00      0.00      0.00        37\n",
      "         600       0.00      0.00      0.00         0\n",
      "         601       0.00      0.00      0.00        41\n",
      "         602       0.00      0.00      0.00        76\n",
      "         603       0.00      0.00      0.00        48\n",
      "         604       0.03      0.00      0.01       313\n",
      "         605       0.00      0.00      0.00        14\n",
      "         606       0.07      0.01      0.01       272\n",
      "         607       0.07      0.01      0.01       272\n",
      "         608       0.00      0.00      0.00       116\n",
      "         609       0.00      0.00      0.00       372\n",
      "         610       0.03      0.00      0.00       450\n",
      "         611       0.03      0.00      0.01       310\n",
      "         612       0.00      0.00      0.00       174\n",
      "         613       0.00      0.00      0.00        47\n",
      "         614       0.00      0.00      0.00        74\n",
      "         615       0.04      0.00      0.00       530\n",
      "         616       0.00      0.00      0.00        77\n",
      "         617       0.00      0.00      0.00        77\n",
      "         618       0.03      0.00      0.00       796\n",
      "         619       0.00      0.00      0.00        30\n",
      "         620       0.04      0.00      0.01       262\n",
      "         621       0.00      0.00      0.00        14\n",
      "         622       0.00      0.00      0.00        14\n",
      "         623       0.00      0.00      0.00        48\n",
      "         624       0.00      0.00      0.00        12\n",
      "         625       0.04      0.00      0.00       378\n",
      "         626       0.00      0.00      0.00        46\n",
      "         627       0.00      0.00      0.00         2\n",
      "         628       0.04      0.00      0.01       262\n",
      "         629       0.04      0.00      0.01       262\n",
      "         630       0.00      0.00      0.00       164\n",
      "         631       0.00      0.00      0.00       164\n",
      "         632       0.03      0.00      0.01       298\n",
      "         633       0.14      0.00      0.01       930\n",
      "         634       0.00      0.00      0.00         0\n",
      "         635       0.00      0.00      0.00        29\n",
      "         636       0.07      0.01      0.01       272\n",
      "         637       0.04      0.00      0.01       320\n",
      "         638       0.00      0.00      0.00        77\n",
      "         639       0.00      0.00      0.00        77\n",
      "         640       0.03      0.00      0.00       399\n",
      "         641       0.00      0.00      0.00        14\n",
      "         642       0.00      0.00      0.00        77\n",
      "         643       0.00      0.00      0.00       341\n",
      "         644       0.00      0.00      0.00       112\n",
      "         645       0.00      0.00      0.00        76\n",
      "         646       0.00      0.00      0.00        84\n",
      "         647       0.00      0.00      0.00       254\n",
      "         648       0.00      0.00      0.00       174\n",
      "         649       0.00      0.00      0.00       112\n",
      "         650       0.00      0.00      0.00       511\n",
      "         651       0.16      0.00      0.01      1940\n",
      "         652       0.03      0.00      0.00       772\n",
      "         653       0.00      0.00      0.00       222\n",
      "         654       0.00      0.00      0.00       650\n",
      "         655       0.00      0.00      0.00        41\n",
      "         656       0.17      0.01      0.01      1400\n",
      "         657       0.00      0.00      0.00       373\n",
      "         658       0.04      0.00      0.01       290\n",
      "         659       0.06      0.00      0.00       894\n",
      "         660       0.10      0.00      0.01       669\n",
      "         661       0.16      0.00      0.01      1718\n",
      "         662       0.00      0.00      0.00        74\n",
      "         663       0.12      0.01      0.01       592\n",
      "         664       0.00      0.00      0.00        47\n",
      "         665       0.00      0.00      0.00        17\n",
      "         666       0.00      0.00      0.00       167\n",
      "         667       0.00      0.00      0.00        53\n",
      "         668       0.07      0.01      0.01       272\n",
      "         669       0.00      0.00      0.00       179\n",
      "         670       0.35      0.01      0.02      2839\n",
      "         671       0.00      0.00      0.00        11\n",
      "         672       0.00      0.00      0.00        48\n",
      "         673       0.00      0.00      0.00         0\n",
      "         674       0.00      0.00      0.00         0\n",
      "         675       0.00      0.00      0.00        21\n",
      "         676       0.00      0.00      0.00        53\n",
      "         677       0.00      0.00      0.00        61\n",
      "         678       0.06      0.00      0.00       991\n",
      "         679       0.00      0.00      0.00       102\n",
      "         680       0.00      0.00      0.00       168\n",
      "         681       0.07      0.00      0.01       878\n",
      "         682       0.00      0.00      0.00        17\n",
      "         683       0.00      0.00      0.00       225\n",
      "         684       0.00      0.00      0.00       563\n",
      "         685       0.00      0.00      0.00        32\n",
      "         686       0.00      0.00      0.00        32\n",
      "         687       0.04      0.00      0.00       583\n",
      "         688       0.00      0.00      0.00       297\n",
      "         689       0.00      0.00      0.00        77\n",
      "         690       0.00      0.00      0.00        77\n",
      "         691       0.13      0.01      0.01      1528\n",
      "         692       0.00      0.00      0.00         4\n",
      "         693       0.04      0.00      0.00       429\n",
      "         694       0.00      0.00      0.00        28\n",
      "         695       0.09      0.00      0.01      1386\n",
      "         696       0.06      0.00      0.01       419\n",
      "         697       0.00      0.00      0.00       438\n",
      "         698       0.03      0.00      0.00       399\n",
      "         699       0.03      0.00      0.00       399\n",
      "         700       0.00      0.00      0.00       228\n",
      "         701       0.08      0.00      0.01      1128\n",
      "         702       0.05      0.01      0.01       277\n",
      "         703       0.00      0.00      0.00       363\n",
      "         704       0.00      0.00      0.00        53\n",
      "         705       0.19      0.01      0.01      2697\n",
      "         706       0.00      0.00      0.00       399\n",
      "         707       0.00      0.00      0.00        91\n",
      "         708       0.11      0.01      0.02        95\n",
      "         709       0.09      0.01      0.01       295\n",
      "         710       0.00      0.00      0.00       455\n",
      "         711       0.00      0.00      0.00       250\n",
      "         712       0.08      0.01      0.02       106\n",
      "         713       0.09      0.00      0.01      1442\n",
      "         714       0.00      0.00      0.00         4\n",
      "         715       0.06      0.00      0.01       207\n",
      "         716       0.00      0.00      0.00        13\n",
      "         717       0.03      0.00      0.00       400\n",
      "         718       0.00      0.00      0.00       117\n",
      "         719       0.04      0.00      0.01       284\n",
      "         720       0.07      0.00      0.01       687\n",
      "         721       0.00      0.00      0.00        63\n",
      "         722       0.00      0.00      0.00        49\n",
      "         723       0.00      0.00      0.00       118\n",
      "         724       0.02      0.00      0.00      1509\n",
      "         725       0.16      0.01      0.02      1648\n",
      "         726       0.03      0.00      0.00       446\n",
      "         727       0.00      0.00      0.00       292\n",
      "         728       0.09      0.01      0.01      1261\n",
      "         729       0.14      0.00      0.01       784\n",
      "         730       0.00      0.00      0.00        92\n",
      "         731       0.00      0.00      0.00        34\n",
      "         732       0.00      0.00      0.00       145\n",
      "         733       0.05      0.00      0.01       243\n",
      "         734       0.08      0.00      0.01       269\n",
      "         735       0.10      0.03      0.05        32\n",
      "         736       0.00      0.00      0.00        21\n",
      "         737       0.04      0.00      0.00      1118\n",
      "         738       0.00      0.00      0.00       330\n",
      "         739       0.04      0.00      0.00       507\n",
      "         740       0.00      0.00      0.00        68\n",
      "         741       0.00      0.00      0.00        11\n",
      "         742       0.07      0.01      0.01       192\n",
      "         743       0.00      0.00      0.00       102\n",
      "         744       0.00      0.00      0.00       280\n",
      "         745       0.00      0.00      0.00        44\n",
      "         746       0.04      0.00      0.01       247\n",
      "         747       0.00      0.00      0.00        66\n",
      "         748       0.00      0.00      0.00        31\n",
      "         749       0.00      0.00      0.00       342\n",
      "         750       0.00      0.00      0.00        63\n",
      "         751       0.12      0.01      0.02       296\n",
      "         752       0.00      0.00      0.00        87\n",
      "         753       0.00      0.00      0.00       155\n",
      "         754       0.00      0.00      0.00       258\n",
      "         755       0.00      0.00      0.00        49\n",
      "         756       0.00      0.00      0.00        70\n",
      "         757       0.00      0.00      0.00       151\n",
      "         758       0.00      0.00      0.00       117\n",
      "         759       0.00      0.00      0.00        28\n",
      "         760       0.00      0.00      0.00       101\n",
      "         761       0.00      0.00      0.00       207\n",
      "         762       0.00      0.00      0.00        15\n",
      "         763       0.00      0.00      0.00        32\n",
      "         764       0.00      0.00      0.00       628\n",
      "         765       0.00      0.00      0.00        33\n",
      "         766       0.00      0.00      0.00        50\n",
      "         767       0.00      0.00      0.00       172\n",
      "         768       0.00      0.00      0.00        85\n",
      "         769       0.00      0.00      0.00        24\n",
      "         770       0.00      0.00      0.00       585\n",
      "         771       0.05      0.01      0.01       199\n",
      "         772       0.00      0.00      0.00         0\n",
      "         773       0.00      0.00      0.00        41\n",
      "         774       0.00      0.00      0.00        31\n",
      "         775       0.00      0.00      0.00         0\n",
      "         776       0.00      0.00      0.00        10\n",
      "         777       0.00      0.00      0.00        11\n",
      "         778       0.00      0.00      0.00       179\n",
      "         779       0.00      0.00      0.00        81\n",
      "         780       0.00      0.00      0.00        10\n",
      "         781       0.00      0.00      0.00         0\n",
      "         782       0.00      0.00      0.00        70\n",
      "         783       0.03      0.00      0.00      1039\n",
      "         784       0.00      0.00      0.00        14\n",
      "         785       0.00      0.00      0.00         0\n",
      "         786       0.00      0.00      0.00       229\n",
      "         787       0.00      0.00      0.00        68\n",
      "         788       0.04      0.00      0.00       663\n",
      "         789       0.00      0.00      0.00       179\n",
      "         790       0.00      0.00      0.00        10\n",
      "         791       0.00      0.00      0.00         6\n",
      "         792       0.00      0.00      0.00       179\n",
      "         793       0.00      0.00      0.00        18\n",
      "         794       0.00      0.00      0.00        28\n",
      "         795       0.13      0.00      0.01      1565\n",
      "         796       0.00      0.00      0.00        53\n",
      "         797       0.00      0.00      0.00       232\n",
      "         798       0.03      0.00      0.00       969\n",
      "         799       0.03      0.00      0.01       349\n",
      "         800       0.00      0.00      0.00       118\n",
      "         801       0.00      0.00      0.00        28\n",
      "         802       0.00      0.00      0.00        12\n",
      "         803       0.00      0.00      0.00       179\n",
      "         804       0.00      0.00      0.00       179\n",
      "         805       0.00      0.00      0.00       179\n",
      "         806       0.18      0.02      0.04        94\n",
      "         807       0.17      0.04      0.06        28\n",
      "         808       0.00      0.00      0.00         7\n",
      "         809       0.00      0.00      0.00       112\n",
      "         810       0.08      0.01      0.01       256\n",
      "         811       0.00      0.00      0.00        28\n",
      "         812       0.00      0.00      0.00        25\n",
      "         813       0.04      0.00      0.01       320\n",
      "         814       0.04      0.00      0.01       339\n",
      "         815       0.15      0.00      0.01      1191\n",
      "         816       0.00      0.00      0.00        60\n",
      "         817       0.00      0.00      0.00         7\n",
      "         818       0.00      0.00      0.00        21\n",
      "         819       0.00      0.00      0.00       925\n",
      "         820       0.20      0.01      0.01       775\n",
      "         821       0.11      0.01      0.01       355\n",
      "         822       0.00      0.00      0.00        68\n",
      "         823       0.14      0.01      0.01       840\n",
      "         824       0.00      0.00      0.00       112\n",
      "         825       0.00      0.00      0.00        60\n",
      "         826       0.00      0.00      0.00         0\n",
      "         827       0.07      0.01      0.01       272\n",
      "         828       0.00      0.00      0.00        68\n",
      "         829       0.00      0.00      0.00        28\n",
      "         830       0.00      0.00      0.00       118\n",
      "         831       0.00      0.00      0.00       144\n",
      "         832       0.00      0.00      0.00         0\n",
      "         833       0.00      0.00      0.00        28\n",
      "         834       0.08      0.01      0.02       118\n",
      "         835       0.00      0.00      0.00         5\n",
      "         836       0.00      0.00      0.00        68\n",
      "         837       0.00      0.00      0.00        28\n",
      "         838       0.00      0.00      0.00       116\n",
      "         839       0.00      0.00      0.00        33\n",
      "         840       0.00      0.00      0.00        26\n",
      "         841       0.00      0.00      0.00        48\n",
      "         842       0.19      0.00      0.01      1339\n",
      "         843       0.11      0.00      0.01      1016\n",
      "         844       0.00      0.00      0.00       172\n",
      "         845       0.10      0.00      0.00      1833\n",
      "         846       0.00      0.00      0.00       577\n",
      "         847       0.00      0.00      0.00        33\n",
      "         848       0.19      0.01      0.01       826\n",
      "         849       0.12      0.01      0.01       375\n",
      "         850       0.12      0.00      0.01      1947\n",
      "         851       0.00      0.00      0.00       128\n",
      "         852       0.00      0.00      0.00       373\n",
      "         853       0.00      0.00      0.00        15\n",
      "         854       0.00      0.00      0.00       416\n",
      "         855       0.00      0.00      0.00       180\n",
      "         856       0.00      0.00      0.00        57\n",
      "         857       0.00      0.00      0.00       179\n",
      "         858       0.00      0.00      0.00        36\n",
      "         859       0.08      0.00      0.01       475\n",
      "         860       0.00      0.00      0.00       112\n",
      "         861       0.00      0.00      0.00         8\n",
      "         862       0.00      0.00      0.00        26\n",
      "         863       0.04      0.00      0.01       243\n",
      "         864       0.04      0.00      0.01       243\n",
      "         865       0.10      0.01      0.02       199\n",
      "         866       0.00      0.00      0.00        34\n",
      "         867       0.00      0.00      0.00       672\n",
      "         868       0.00      0.00      0.00        86\n",
      "         869       0.00      0.00      0.00        91\n",
      "         870       0.00      0.00      0.00       116\n",
      "         871       0.00      0.00      0.00        22\n",
      "         872       0.00      0.00      0.00       139\n",
      "         873       0.00      0.00      0.00        33\n",
      "         874       0.00      0.00      0.00       179\n",
      "         875       0.00      0.00      0.00        33\n",
      "         876       0.00      0.00      0.00       220\n",
      "         877       0.00      0.00      0.00        36\n",
      "         878       0.09      0.01      0.01       528\n",
      "         879       0.00      0.00      0.00       225\n",
      "         880       0.03      0.00      0.01       336\n",
      "         881       0.17      0.00      0.01      2226\n",
      "         882       0.04      0.00      0.00       550\n",
      "         883       0.04      0.00      0.00       378\n",
      "         884       0.00      0.00      0.00        88\n",
      "         885       0.03      0.00      0.00       399\n",
      "         886       0.00      0.00      0.00       281\n",
      "         887       0.09      0.00      0.01       831\n",
      "         888       0.00      0.00      0.00        60\n",
      "         889       0.04      0.00      0.00       619\n",
      "         890       0.04      0.00      0.00       519\n",
      "         891       0.00      0.00      0.00       132\n",
      "         892       0.05      0.01      0.01       176\n",
      "         893       0.03      0.00      0.01       257\n",
      "         894       0.03      0.00      0.00       399\n",
      "         895       0.00      0.00      0.00        37\n",
      "         896       0.00      0.00      0.00         7\n",
      "         897       0.00      0.00      0.00         4\n",
      "         898       0.00      0.00      0.00         1\n",
      "         899       0.00      0.00      0.00        95\n",
      "         900       0.05      0.01      0.01       176\n",
      "         901       0.08      0.01      0.02        81\n",
      "         902       0.05      0.01      0.01       176\n",
      "         903       0.00      0.00      0.00        94\n",
      "         904       0.05      0.01      0.01       176\n",
      "         905       0.00      0.00      0.00         7\n",
      "         906       0.00      0.00      0.00        51\n",
      "         907       0.00      0.00      0.00         7\n",
      "         908       0.00      0.00      0.00       101\n",
      "         909       0.00      0.00      0.00        32\n",
      "         910       0.00      0.00      0.00        39\n",
      "         911       0.00      0.00      0.00       160\n",
      "         912       0.00      0.00      0.00        74\n",
      "         913       0.00      0.00      0.00        50\n",
      "         914       0.00      0.00      0.00        55\n",
      "         915       0.00      0.00      0.00        39\n",
      "         916       0.03      0.00      0.00       399\n",
      "         917       0.00      0.00      0.00       200\n",
      "         918       0.00      0.00      0.00        30\n",
      "         919       0.00      0.00      0.00        36\n",
      "         920       0.00      0.00      0.00       112\n",
      "         921       0.00      0.00      0.00        68\n",
      "         922       0.00      0.00      0.00       164\n",
      "         923       0.04      0.00      0.00       442\n",
      "         924       0.00      0.00      0.00        27\n",
      "         925       0.00      0.00      0.00       194\n",
      "         926       0.11      0.01      0.01       496\n",
      "         927       0.00      0.00      0.00       172\n",
      "         928       0.00      0.00      0.00         8\n",
      "         929       0.05      0.00      0.00       534\n",
      "         930       0.00      0.00      0.00        60\n",
      "         931       0.00      0.00      0.00        30\n",
      "         932       0.00      0.00      0.00        60\n",
      "         933       0.00      0.00      0.00       373\n",
      "         934       0.00      0.00      0.00        60\n",
      "         935       0.00      0.00      0.00        68\n",
      "         936       0.00      0.00      0.00        53\n",
      "         937       0.07      0.01      0.01       272\n",
      "         938       0.05      0.00      0.00       645\n",
      "         939       0.00      0.00      0.00        51\n",
      "         940       0.00      0.00      0.00        68\n",
      "         941       0.00      0.00      0.00        48\n",
      "         942       0.00      0.00      0.00        28\n",
      "         943       0.12      0.01      0.01      1585\n",
      "         944       0.03      0.00      0.00       668\n",
      "         945       0.00      0.00      0.00        17\n",
      "         946       0.00      0.00      0.00       620\n",
      "         947       0.05      0.00      0.00       388\n",
      "         948       0.04      0.00      0.01       292\n",
      "         949       0.03      0.00      0.00       505\n",
      "         950       0.00      0.00      0.00       426\n",
      "         951       0.08      0.01      0.02       118\n",
      "         952       0.00      0.00      0.00        60\n",
      "         953       0.00      0.00      0.00        67\n",
      "         954       0.00      0.00      0.00        68\n",
      "         955       0.02      0.00      0.00      1040\n",
      "         956       0.00      0.00      0.00       634\n",
      "         957       0.12      0.00      0.01      1384\n",
      "         958       0.00      0.00      0.00        47\n",
      "         959       0.00      0.00      0.00       231\n",
      "         960       0.00      0.00      0.00        48\n",
      "         961       0.00      0.00      0.00        33\n",
      "         962       0.07      0.01      0.01       545\n",
      "         963       0.00      0.00      0.00        67\n",
      "         964       0.07      0.00      0.01       884\n",
      "         965       0.00      0.00      0.00       179\n",
      "         966       0.00      0.00      0.00       172\n",
      "         967       0.05      0.00      0.00      1205\n",
      "         968       0.00      0.00      0.00        48\n",
      "         969       0.00      0.00      0.00       232\n",
      "         970       0.00      0.00      0.00       172\n",
      "         971       0.00      0.00      0.00        76\n",
      "         972       0.00      0.00      0.00       153\n",
      "         973       0.00      0.00      0.00       172\n",
      "         974       0.00      0.00      0.00        27\n",
      "         975       0.00      0.00      0.00       107\n",
      "         976       0.00      0.00      0.00        77\n",
      "         977       0.04      0.00      0.01       262\n",
      "         978       0.00      0.00      0.00        53\n",
      "         979       0.00      0.00      0.00       172\n",
      "         980       0.00      0.00      0.00        30\n",
      "         981       0.00      0.00      0.00       225\n",
      "         982       0.00      0.00      0.00        68\n",
      "         983       0.04      0.00      0.01       320\n",
      "         984       0.00      0.00      0.00        90\n",
      "         985       0.04      0.00      0.01       262\n",
      "         986       0.00      0.00      0.00        65\n",
      "         987       0.00      0.00      0.00       373\n",
      "         988       0.03      0.00      0.00       399\n",
      "         989       0.00      0.00      0.00        48\n",
      "         990       0.00      0.00      0.00        36\n",
      "         991       0.00      0.00      0.00        88\n",
      "         992       0.00      0.00      0.00       116\n",
      "         993       0.00      0.00      0.00        49\n",
      "         994       0.00      0.00      0.00        49\n",
      "         995       0.00      0.00      0.00        49\n",
      "         996       0.00      0.00      0.00        49\n",
      "         997       0.00      0.00      0.00        32\n",
      "         998       0.00      0.00      0.00       373\n",
      "         999       0.00      0.00      0.00       205\n",
      "        1000       0.00      0.00      0.00       373\n",
      "        1001       0.00      0.00      0.00       438\n",
      "        1002       0.00      0.00      0.00       127\n",
      "        1003       0.06      0.00      0.01       454\n",
      "        1004       0.06      0.00      0.00       514\n",
      "        1005       0.00      0.00      0.00        58\n",
      "        1006       0.00      0.00      0.00       489\n",
      "        1007       0.00      0.00      0.00       552\n",
      "        1008       0.00      0.00      0.00       167\n",
      "        1009       0.00      0.00      0.00         0\n",
      "        1010       0.00      0.00      0.00       389\n",
      "        1011       0.03      0.00      0.00       806\n",
      "        1012       0.07      0.00      0.01       749\n",
      "        1013       0.08      0.00      0.01       527\n",
      "        1014       0.00      0.00      0.00       127\n",
      "        1015       0.00      0.00      0.00        48\n",
      "        1016       0.00      0.00      0.00       127\n",
      "        1017       0.00      0.00      0.00        39\n",
      "        1018       0.00      0.00      0.00       127\n",
      "        1019       0.00      0.00      0.00        27\n",
      "        1020       0.00      0.00      0.00       163\n",
      "        1021       0.00      0.00      0.00        16\n",
      "        1022       0.00      0.00      0.00        53\n",
      "        1023       0.00      0.00      0.00        13\n",
      "        1024       0.00      0.00      0.00       205\n",
      "        1025       0.00      0.00      0.00        67\n",
      "        1026       0.05      0.01      0.01       176\n",
      "        1027       0.00      0.00      0.00        76\n",
      "        1028       0.00      0.00      0.00        13\n",
      "        1029       0.00      0.00      0.00        28\n",
      "        1030       0.00      0.00      0.00        68\n",
      "        1031       0.00      0.00      0.00        68\n",
      "        1032       0.00      0.00      0.00        74\n",
      "        1033       0.00      0.00      0.00        34\n",
      "        1034       0.00      0.00      0.00        53\n",
      "        1035       0.00      0.00      0.00       116\n",
      "        1036       0.00      0.00      0.00         8\n",
      "        1037       0.00      0.00      0.00        32\n",
      "        1038       0.00      0.00      0.00        32\n",
      "        1039       0.00      0.00      0.00        32\n",
      "        1040       0.00      0.00      0.00        13\n",
      "        1041       0.00      0.00      0.00        77\n",
      "        1042       0.00      0.00      0.00        91\n",
      "        1043       0.00      0.00      0.00        32\n",
      "        1044       0.00      0.00      0.00       171\n",
      "        1045       0.00      0.00      0.00        48\n",
      "        1046       0.00      0.00      0.00       908\n",
      "        1047       0.00      0.00      0.00        53\n",
      "        1048       0.00      0.00      0.00         3\n",
      "        1049       0.04      0.00      0.01       262\n",
      "        1050       0.00      0.00      0.00        53\n",
      "        1051       0.00      0.00      0.00        53\n",
      "        1052       0.00      0.00      0.00         0\n",
      "        1053       0.00      0.00      0.00        48\n",
      "        1054       0.00      0.00      0.00         6\n",
      "        1055       0.00      0.00      0.00        11\n",
      "        1056       0.00      0.00      0.00        33\n",
      "        1057       0.00      0.00      0.00        49\n",
      "        1058       0.00      0.00      0.00        16\n",
      "        1059       0.00      0.00      0.00        71\n",
      "        1060       0.00      0.00      0.00        14\n",
      "        1061       0.00      0.00      0.00        67\n",
      "        1062       0.00      0.00      0.00        65\n",
      "        1063       0.00      0.00      0.00        32\n",
      "        1064       0.00      0.00      0.00         0\n",
      "        1065       0.00      0.00      0.00         0\n",
      "        1066       0.00      0.00      0.00         0\n",
      "        1067       0.00      0.00      0.00         0\n",
      "        1068       0.00      0.00      0.00        14\n",
      "        1069       0.04      0.00      0.01       350\n",
      "        1070       0.00      0.00      0.00        45\n",
      "        1071       0.00      0.00      0.00        55\n",
      "        1072       0.00      0.00      0.00        16\n",
      "        1073       0.00      0.00      0.00         7\n",
      "        1074       0.00      0.00      0.00        68\n",
      "        1075       0.00      0.00      0.00        77\n",
      "        1076       0.00      0.00      0.00        62\n",
      "        1077       0.00      0.00      0.00       151\n",
      "        1078       0.04      0.00      0.00       419\n",
      "        1079       0.00      0.00      0.00        16\n",
      "        1080       0.00      0.00      0.00        68\n",
      "        1081       0.00      0.00      0.00        77\n",
      "        1082       0.00      0.00      0.00       125\n",
      "        1083       0.00      0.00      0.00        67\n",
      "        1084       0.00      0.00      0.00        47\n",
      "        1085       0.04      0.00      0.01       262\n",
      "        1086       0.06      0.00      0.01       279\n",
      "        1087       0.17      0.01      0.01      1068\n",
      "        1088       0.12      0.00      0.00      2962\n",
      "        1089       0.11      0.00      0.01      1204\n",
      "        1090       0.04      0.00      0.00       539\n",
      "        1091       0.04      0.00      0.01       268\n",
      "        1092       0.04      0.00      0.00       618\n",
      "        1093       0.00      0.00      0.00       112\n",
      "        1094       0.00      0.00      0.00        27\n",
      "        1095       0.00      0.00      0.00        50\n",
      "        1096       0.10      0.00      0.01      1168\n",
      "        1097       0.03      0.00      0.01       250\n",
      "        1098       0.00      0.00      0.00        74\n",
      "        1099       0.04      0.00      0.01       262\n",
      "        1100       0.03      0.00      0.01       250\n",
      "        1101       0.00      0.00      0.00       125\n",
      "        1102       0.07      0.01      0.01       130\n",
      "        1103       0.00      0.00      0.00       165\n",
      "        1104       0.07      0.01      0.01       272\n",
      "        1105       0.05      0.00      0.01       341\n",
      "        1106       0.00      0.00      0.00       120\n",
      "        1107       0.07      0.00      0.01       657\n",
      "        1108       0.00      0.00      0.00         9\n",
      "        1109       0.00      0.00      0.00        12\n",
      "        1110       0.00      0.00      0.00         6\n",
      "        1111       0.00      0.00      0.00        33\n",
      "        1112       0.00      0.00      0.00       191\n",
      "        1113       0.00      0.00      0.00       116\n",
      "        1114       0.00      0.00      0.00        48\n",
      "        1115       0.05      0.01      0.01       190\n",
      "        1116       0.00      0.00      0.00       179\n",
      "        1117       0.00      0.00      0.00        48\n",
      "        1118       0.00      0.00      0.00        36\n",
      "        1119       0.00      0.00      0.00       116\n",
      "        1120       0.00      0.00      0.00       245\n",
      "        1121       0.00      0.00      0.00       389\n",
      "        1122       0.00      0.00      0.00       591\n",
      "        1123       0.00      0.00      0.00         0\n",
      "        1124       0.08      0.01      0.02       119\n",
      "        1125       0.00      0.00      0.00        27\n",
      "        1126       0.00      0.00      0.00        28\n",
      "        1127       0.00      0.00      0.00         7\n",
      "        1128       0.00      0.00      0.00       118\n",
      "        1129       0.03      0.00      0.01       339\n",
      "        1130       0.00      0.00      0.00       282\n",
      "        1131       0.10      0.01      0.02       333\n",
      "        1132       0.00      0.00      0.00       589\n",
      "        1133       0.00      0.00      0.00        74\n",
      "        1134       0.00      0.00      0.00       112\n",
      "        1135       0.00      0.00      0.00       280\n",
      "        1136       0.20      0.03      0.05        32\n",
      "        1137       0.00      0.00      0.00        10\n",
      "        1138       0.00      0.00      0.00        60\n",
      "        1139       0.00      0.00      0.00        77\n",
      "        1140       0.00      0.00      0.00       179\n",
      "        1141       0.12      0.01      0.01       592\n",
      "        1142       0.00      0.00      0.00        76\n",
      "        1143       0.04      0.00      0.00       394\n",
      "        1144       0.00      0.00      0.00         0\n",
      "        1145       0.00      0.00      0.00       118\n",
      "        1146       0.00      0.00      0.00       107\n",
      "        1147       0.00      0.00      0.00        32\n",
      "        1148       0.00      0.00      0.00        33\n",
      "        1149       0.06      0.00      0.01       703\n",
      "        1150       0.03      0.00      0.00       623\n",
      "        1151       0.04      0.00      0.01       256\n",
      "        1152       0.00      0.00      0.00        64\n",
      "        1153       0.00      0.00      0.00        12\n",
      "        1154       0.00      0.00      0.00       373\n",
      "        1155       0.04      0.00      0.01       320\n",
      "        1156       0.00      0.00      0.00        12\n",
      "        1157       0.00      0.00      0.00       614\n",
      "        1158       0.03      0.00      0.00       425\n",
      "        1159       0.03      0.00      0.00       971\n",
      "        1160       0.03      0.00      0.00       399\n",
      "        1161       0.09      0.00      0.01       611\n",
      "        1162       0.00      0.00      0.00       159\n",
      "        1163       0.00      0.00      0.00        33\n",
      "        1164       0.04      0.00      0.01       219\n",
      "        1165       0.00      0.00      0.00        80\n",
      "        1166       0.00      0.00      0.00       112\n",
      "        1167       0.00      0.00      0.00        28\n",
      "        1168       0.00      0.00      0.00        31\n",
      "        1169       0.00      0.00      0.00        23\n",
      "        1170       0.00      0.00      0.00        23\n",
      "        1171       0.00      0.00      0.00       112\n",
      "        1172       0.00      0.00      0.00       112\n",
      "        1173       0.00      0.00      0.00        81\n",
      "        1174       0.00      0.00      0.00         0\n",
      "        1175       0.00      0.00      0.00        81\n",
      "        1176       0.00      0.00      0.00        31\n",
      "        1177       0.00      0.00      0.00        31\n",
      "        1178       0.00      0.00      0.00        81\n",
      "        1179       0.00      0.00      0.00        95\n",
      "        1180       0.00      0.00      0.00         9\n",
      "        1181       0.00      0.00      0.00        95\n",
      "        1182       0.00      0.00      0.00         9\n",
      "        1183       0.00      0.00      0.00        32\n",
      "        1184       0.00      0.00      0.00        33\n",
      "        1185       0.00      0.00      0.00        81\n",
      "        1186       0.00      0.00      0.00        23\n",
      "        1187       0.00      0.00      0.00        81\n",
      "        1188       0.00      0.00      0.00        81\n",
      "        1189       0.00      0.00      0.00        23\n",
      "        1190       0.00      0.00      0.00        77\n",
      "        1191       0.00      0.00      0.00        31\n",
      "        1192       0.00      0.00      0.00        31\n",
      "        1193       0.00      0.00      0.00        68\n",
      "        1194       0.00      0.00      0.00         0\n",
      "        1195       0.00      0.00      0.00        17\n",
      "        1196       0.00      0.00      0.00         0\n",
      "        1197       0.00      0.00      0.00        31\n",
      "        1198       0.00      0.00      0.00       112\n",
      "        1199       0.00      0.00      0.00         5\n",
      "        1200       0.00      0.00      0.00        36\n",
      "        1201       0.00      0.00      0.00       179\n",
      "        1202       0.11      0.01      0.02        95\n",
      "        1203       0.00      0.00      0.00        47\n",
      "        1204       0.04      0.00      0.01       320\n",
      "        1205       0.00      0.00      0.00        74\n",
      "        1206       0.00      0.00      0.00         0\n",
      "        1207       0.00      0.00      0.00        53\n",
      "        1208       0.00      0.00      0.00       170\n",
      "        1209       0.00      0.00      0.00       179\n",
      "        1210       0.00      0.00      0.00        22\n",
      "        1211       0.06      0.01      0.01       360\n",
      "        1212       0.00      0.00      0.00       246\n",
      "        1213       0.00      0.00      0.00        18\n",
      "        1214       0.00      0.00      0.00        24\n",
      "        1215       0.00      0.00      0.00        30\n",
      "        1216       0.00      0.00      0.00        76\n",
      "        1217       0.06      0.00      0.01       232\n",
      "        1218       0.00      0.00      0.00       373\n",
      "        1219       0.00      0.00      0.00       116\n",
      "        1220       0.10      0.01      0.01       489\n",
      "        1221       0.00      0.00      0.00       378\n",
      "        1222       0.00      0.00      0.00       445\n",
      "        1223       0.00      0.00      0.00        74\n",
      "        1224       0.00      0.00      0.00         0\n",
      "        1225       0.00      0.00      0.00        77\n",
      "        1226       0.00      0.00      0.00        34\n",
      "        1227       0.00      0.00      0.00        13\n",
      "        1228       0.04      0.00      0.01       262\n",
      "        1229       0.00      0.00      0.00        53\n",
      "        1230       0.00      0.00      0.00        36\n",
      "        1231       0.06      0.01      0.01       135\n",
      "        1232       0.00      0.00      0.00        45\n",
      "        1233       0.00      0.00      0.00        91\n",
      "        1234       0.00      0.00      0.00       260\n",
      "        1235       0.00      0.00      0.00        33\n",
      "        1236       0.00      0.00      0.00        72\n",
      "        1237       0.00      0.00      0.00        63\n",
      "        1238       0.00      0.00      0.00        53\n",
      "        1239       0.04      0.00      0.01       210\n",
      "        1240       0.00      0.00      0.00        12\n",
      "        1241       0.04      0.01      0.01       192\n",
      "        1242       0.00      0.00      0.00       153\n",
      "        1243       0.00      0.00      0.00       131\n",
      "        1244       0.00      0.00      0.00         1\n",
      "        1245       0.00      0.00      0.00        38\n",
      "        1246       0.00      0.00      0.00        20\n",
      "        1247       0.00      0.00      0.00       136\n",
      "        1248       0.00      0.00      0.00        78\n",
      "        1249       0.00      0.00      0.00        25\n",
      "        1250       0.00      0.00      0.00       117\n",
      "        1251       0.10      0.01      0.02       161\n",
      "        1252       0.00      0.00      0.00       134\n",
      "        1253       0.00      0.00      0.00       103\n",
      "        1254       0.00      0.00      0.00        11\n",
      "        1255       0.00      0.00      0.00       175\n",
      "        1256       0.00      0.00      0.00        92\n",
      "        1257       0.00      0.00      0.00         5\n",
      "        1258       0.00      0.00      0.00        35\n",
      "        1259       0.00      0.00      0.00        54\n",
      "        1260       0.00      0.00      0.00        38\n",
      "        1261       0.04      0.00      0.01       284\n",
      "        1262       0.08      0.01      0.01       176\n",
      "        1263       0.00      0.00      0.00        46\n",
      "        1264       0.00      0.00      0.00       303\n",
      "        1265       0.00      0.00      0.00        19\n",
      "        1266       0.00      0.00      0.00        13\n",
      "        1267       0.00      0.00      0.00       307\n",
      "        1268       0.14      0.00      0.01      1662\n",
      "        1269       0.00      0.00      0.00        24\n",
      "        1270       0.00      0.00      0.00        26\n",
      "        1271       0.00      0.00      0.00        50\n",
      "        1272       0.00      0.00      0.00        77\n",
      "        1273       0.00      0.00      0.00        77\n",
      "        1274       0.00      0.00      0.00        24\n",
      "        1275       0.00      0.00      0.00         0\n",
      "        1276       0.00      0.00      0.00        97\n",
      "        1277       0.00      0.00      0.00        30\n",
      "        1278       0.00      0.00      0.00        81\n",
      "        1279       0.00      0.00      0.00         0\n",
      "        1280       0.00      0.00      0.00        26\n",
      "        1281       0.00      0.00      0.00        77\n",
      "        1282       0.00      0.00      0.00        77\n",
      "        1283       0.00      0.00      0.00       179\n",
      "        1284       0.00      0.00      0.00        32\n",
      "        1285       0.00      0.00      0.00       111\n",
      "        1286       0.00      0.00      0.00        38\n",
      "        1287       0.00      0.00      0.00        52\n",
      "        1288       0.00      0.00      0.00       136\n",
      "        1289       0.00      0.00      0.00        11\n",
      "        1290       0.00      0.00      0.00        11\n",
      "        1291       0.00      0.00      0.00        19\n",
      "        1292       0.00      0.00      0.00        25\n",
      "        1293       0.00      0.00      0.00        77\n",
      "        1294       0.00      0.00      0.00        43\n",
      "        1295       0.00      0.00      0.00       344\n",
      "        1296       0.00      0.00      0.00        22\n",
      "        1297       0.00      0.00      0.00         2\n",
      "        1298       0.00      0.00      0.00         0\n",
      "        1299       0.12      0.00      0.01       527\n",
      "        1300       0.00      0.00      0.00        42\n",
      "        1301       0.00      0.00      0.00        59\n",
      "        1302       0.00      0.00      0.00       151\n",
      "        1303       0.00      0.00      0.00        89\n",
      "        1304       0.00      0.00      0.00        28\n",
      "        1305       0.00      0.00      0.00       553\n",
      "        1306       0.07      0.00      0.01       425\n",
      "        1307       0.00      0.00      0.00        14\n",
      "        1308       0.00      0.00      0.00        39\n",
      "        1309       0.00      0.00      0.00        62\n",
      "        1310       0.00      0.00      0.00        46\n",
      "        1311       0.00      0.00      0.00        62\n",
      "        1312       0.10      0.00      0.01      1155\n",
      "        1313       0.00      0.00      0.00        72\n",
      "        1314       0.00      0.00      0.00       471\n",
      "        1315       0.10      0.00      0.01       669\n",
      "        1316       0.00      0.00      0.00        13\n",
      "        1317       0.00      0.00      0.00         1\n",
      "        1318       0.00      0.00      0.00        17\n",
      "        1319       0.00      0.00      0.00       258\n",
      "        1320       0.00      0.00      0.00        21\n",
      "        1321       0.00      0.00      0.00        66\n",
      "        1322       0.07      0.01      0.01       192\n",
      "        1323       0.00      0.00      0.00       373\n",
      "        1324       0.08      0.00      0.00       940\n",
      "        1325       0.00      0.00      0.00       155\n",
      "        1326       0.00      0.00      0.00        29\n",
      "        1327       0.00      0.00      0.00        10\n",
      "        1328       0.00      0.00      0.00        39\n",
      "        1329       0.00      0.00      0.00        85\n",
      "        1330       0.00      0.00      0.00       214\n",
      "        1331       0.07      0.01      0.01       192\n",
      "        1332       0.00      0.00      0.00        36\n",
      "        1333       0.00      0.00      0.00         7\n",
      "        1334       0.00      0.00      0.00        36\n",
      "        1335       0.00      0.00      0.00       118\n",
      "        1336       0.00      0.00      0.00        66\n",
      "        1337       0.00      0.00      0.00         0\n",
      "        1338       0.00      0.00      0.00        11\n",
      "        1339       0.00      0.00      0.00        26\n",
      "        1340       0.00      0.00      0.00       329\n",
      "        1341       0.00      0.00      0.00        66\n",
      "        1342       0.00      0.00      0.00        17\n",
      "        1343       0.00      0.00      0.00        31\n",
      "        1344       0.00      0.00      0.00        37\n",
      "        1345       0.00      0.00      0.00        68\n",
      "        1346       0.00      0.00      0.00         0\n",
      "        1347       0.00      0.00      0.00       121\n",
      "        1348       0.00      0.00      0.00        36\n",
      "        1349       0.00      0.00      0.00        77\n",
      "        1350       0.00      0.00      0.00        23\n",
      "        1351       0.00      0.00      0.00        13\n",
      "        1352       0.00      0.00      0.00         0\n",
      "        1353       0.00      0.00      0.00       151\n",
      "        1354       0.00      0.00      0.00       184\n",
      "        1355       0.00      0.00      0.00        60\n",
      "        1356       0.00      0.00      0.00        97\n",
      "        1357       0.00      0.00      0.00       174\n",
      "        1358       0.03      0.00      0.00      1328\n",
      "        1359       0.00      0.00      0.00       124\n",
      "        1360       0.00      0.00      0.00        31\n",
      "        1361       0.00      0.00      0.00        17\n",
      "        1362       0.00      0.00      0.00         0\n",
      "        1363       0.00      0.00      0.00         5\n",
      "        1364       0.16      0.01      0.02      1796\n",
      "        1365       0.00      0.00      0.00        30\n",
      "        1366       0.04      0.00      0.01       300\n",
      "        1367       0.05      0.00      0.01       630\n",
      "        1368       0.00      0.00      0.00        11\n",
      "        1369       0.00      0.00      0.00        32\n",
      "        1370       0.00      0.00      0.00        33\n",
      "        1371       0.07      0.01      0.01       238\n",
      "        1372       0.10      0.01      0.01       399\n",
      "        1373       0.00      0.00      0.00       174\n",
      "        1374       0.00      0.00      0.00       116\n",
      "        1375       0.00      0.00      0.00       116\n",
      "        1376       0.00      0.00      0.00       179\n",
      "        1377       0.04      0.00      0.01       320\n",
      "        1378       0.00      0.00      0.00        14\n",
      "        1379       0.04      0.00      0.01       221\n",
      "        1380       0.00      0.00      0.00        47\n",
      "        1381       0.04      0.00      0.01       262\n",
      "        1382       0.14      0.05      0.08        19\n",
      "        1383       0.03      0.00      0.00       439\n",
      "        1384       0.00      0.00      0.00       116\n",
      "        1385       0.00      0.00      0.00        47\n",
      "        1386       0.04      0.00      0.00       407\n",
      "        1387       0.10      0.00      0.01      1290\n",
      "        1388       0.00      0.00      0.00       188\n",
      "        1389       0.00      0.00      0.00       182\n",
      "        1390       0.16      0.00      0.01      1720\n",
      "        1391       0.03      0.00      0.00       415\n",
      "        1392       0.00      0.00      0.00        33\n",
      "        1393       0.00      0.00      0.00        90\n",
      "        1394       0.05      0.00      0.01       348\n",
      "        1395       0.04      0.00      0.01       320\n",
      "        1396       0.00      0.00      0.00       143\n",
      "        1397       0.00      0.00      0.00       218\n",
      "        1398       0.00      0.00      0.00       130\n",
      "        1399       0.00      0.00      0.00       109\n",
      "        1400       0.00      0.00      0.00        53\n",
      "        1401       0.00      0.00      0.00       125\n",
      "        1402       0.00      0.00      0.00        77\n",
      "        1403       0.00      0.00      0.00        68\n",
      "        1404       0.06      0.01      0.01       319\n",
      "        1405       0.00      0.00      0.00       213\n",
      "        1406       0.00      0.00      0.00       507\n",
      "        1407       0.00      0.00      0.00        12\n",
      "        1408       0.03      0.00      0.00       837\n",
      "        1409       0.11      0.00      0.01      1506\n",
      "        1410       0.02      0.00      0.00       717\n",
      "        1411       0.04      0.00      0.01       320\n",
      "        1412       0.11      0.00      0.01      2049\n",
      "        1413       0.04      0.00      0.01       320\n",
      "        1414       0.00      0.00      0.00       234\n",
      "        1415       0.00      0.00      0.00        26\n",
      "        1416       0.00      0.00      0.00        12\n",
      "        1417       0.00      0.00      0.00        36\n",
      "        1418       0.00      0.00      0.00        30\n",
      "        1419       0.00      0.00      0.00        30\n",
      "        1420       0.04      0.00      0.01       320\n",
      "        1421       0.00      0.00      0.00       164\n",
      "        1422       0.12      0.00      0.01      1419\n",
      "        1423       0.00      0.00      0.00         5\n",
      "        1424       0.00      0.00      0.00       327\n",
      "        1425       0.00      0.00      0.00       229\n",
      "        1426       0.00      0.00      0.00         5\n",
      "        1427       0.00      0.00      0.00         9\n",
      "        1428       0.00      0.00      0.00        81\n",
      "        1429       0.00      0.00      0.00        14\n",
      "        1430       0.00      0.00      0.00         8\n",
      "        1431       0.00      0.00      0.00        50\n",
      "        1432       0.03      0.00      0.00       530\n",
      "        1433       0.08      0.01      0.01       274\n",
      "        1434       0.00      0.00      0.00        68\n",
      "        1435       0.00      0.00      0.00        14\n",
      "        1436       0.00      0.00      0.00        61\n",
      "        1437       0.00      0.00      0.00        12\n",
      "        1438       0.00      0.00      0.00       132\n",
      "        1439       0.00      0.00      0.00         8\n",
      "        1440       0.00      0.00      0.00        21\n",
      "        1441       0.28      0.01      0.01      2280\n",
      "        1442       0.00      0.00      0.00       128\n",
      "        1443       0.00      0.00      0.00        13\n",
      "        1444       0.12      0.01      0.01       592\n",
      "        1445       0.00      0.00      0.00        12\n",
      "        1446       0.00      0.00      0.00       116\n",
      "        1447       0.00      0.00      0.00        24\n",
      "        1448       0.00      0.00      0.00        10\n",
      "        1449       0.00      0.00      0.00       179\n",
      "        1450       0.00      0.00      0.00       111\n",
      "        1451       0.00      0.00      0.00        77\n",
      "        1452       0.00      0.00      0.00       133\n",
      "        1453       0.10      0.02      0.04        47\n",
      "        1454       0.00      0.00      0.00        63\n",
      "        1455       0.00      0.00      0.00        68\n",
      "        1456       0.11      0.00      0.01       621\n",
      "        1457       0.03      0.00      0.00       394\n",
      "        1458       0.00      0.00      0.00       220\n",
      "        1459       0.00      0.00      0.00         5\n",
      "        1460       0.00      0.00      0.00       132\n",
      "        1461       0.11      0.00      0.01      1684\n",
      "        1462       0.00      0.00      0.00       225\n",
      "        1463       0.00      0.00      0.00        15\n",
      "        1464       0.00      0.00      0.00         0\n",
      "        1465       0.00      0.00      0.00         3\n",
      "        1466       0.00      0.00      0.00        27\n",
      "        1467       0.00      0.00      0.00        25\n",
      "        1468       0.06      0.00      0.00       985\n",
      "        1469       0.08      0.01      0.02       206\n",
      "        1470       0.00      0.00      0.00       191\n",
      "        1471       0.00      0.00      0.00       197\n",
      "\n",
      "   micro avg       0.03      0.00      0.00    309858\n",
      "   macro avg       0.02      0.00      0.00    309858\n",
      "weighted avg       0.06      0.00      0.00    309858\n",
      " samples avg       0.02      0.00      0.00    309858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9feb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e1fec",
   "metadata": {},
   "source": [
    "Training time is fine but testing would take like 16 hours to predict 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbf0755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Create a MultiOutputClassifier to handle multi-output classification\n",
    "multi_output_knn = MultiOutputClassifier(knn_classifier)\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    multi_output_knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "a32ed536",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    y_pred = multi_output_knn.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
