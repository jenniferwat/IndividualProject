{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397b0aa8",
   "metadata": {},
   "source": [
    "#### Notes from phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48bf5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for each table was split into train and test\n",
    "# To get the target labels, search and filter the diagnoses dataframes (saved) for the hadm_ids present in the train / test\n",
    "# set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae76a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b8750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed8636aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.24.3\n",
      "Pandas version: 1.5.3\n",
      "Scikit version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# External libraries for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "#To render graphs within notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Versions of libraries\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Scikit version: {}\".format(sk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e93008b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4fbb6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df208946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_days(duration_str):\n",
    "    parts = duration_str.split(' days ')  # Split string into form ['22', '20:55:00']\n",
    "    days = float(parts[0])  # Extract number of days and convert to float\n",
    "    time_parts = parts[1].split(':')  # Split time part (hh:mm:ss) ['20', '55', '00']\n",
    "    hours = float(time_parts[0])  # Extract hours and convert to float\n",
    "    minutes = float(time_parts[1])  # Extract minutes and convert to float\n",
    "    seconds = float(time_parts[2])  # Extract seconds and convert to float\n",
    "    total_days = days + (hours / 24) + (minutes / (24 * 60)) + (seconds / (24 * 3600))  # Calculate total days\n",
    "    return total_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f2d22e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "66a6b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)\n",
    "\n",
    "df_admissions['dischtime'] = pd.to_datetime(df_admissions['dischtime'], format='%d/%m/%Y %H:%M')\n",
    "df_admissions['admittime'] = pd.to_datetime(df_admissions['admittime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_admittime= pd.DataFrame()\n",
    "df_admittime['hadm_id'] = df_admissions['hadm_id']\n",
    "df_admittime['admittime'] = df_admissions['admittime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03dcef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/diagnoses_icd.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_diagnoses = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c3e9311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses = df_diagnoses.drop(columns=['subject_id','seq_num','icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d9952635",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_diagnoses['icd_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_diagnoses[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "56b134c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>00845</th>\n",
       "      <th>0088</th>\n",
       "      <th>0380</th>\n",
       "      <th>0383</th>\n",
       "      <th>03842</th>\n",
       "      <th>03843</th>\n",
       "      <th>03849</th>\n",
       "      <th>0388</th>\n",
       "      <th>0389</th>\n",
       "      <th>...</th>\n",
       "      <th>Z95810</th>\n",
       "      <th>Z95820</th>\n",
       "      <th>Z961</th>\n",
       "      <th>Z96651</th>\n",
       "      <th>Z980</th>\n",
       "      <th>Z981</th>\n",
       "      <th>Z9884</th>\n",
       "      <th>Z9911</th>\n",
       "      <th>Z992</th>\n",
       "      <th>Z9981</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>29820177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  00845  0088  0380  0383  03842  03843  03849  0388  0389  ...  \\\n",
       "0    20044587      0     0     0     0      0      0      0     0     0  ...   \n",
       "1    20093566      0     0     0     0      0      0      0     0     0  ...   \n",
       "2    20192635      0     0     0     0      0      0      0     0     0  ...   \n",
       "3    20199380      0     0     0     0      0      0      0     0     0  ...   \n",
       "4    20214994      0     0     0     0      0      0      0     0     0  ...   \n",
       "..        ...    ...   ...   ...   ...    ...    ...    ...   ...   ...  ...   \n",
       "270  29820177      0     0     0     0      0      0      0     0     0  ...   \n",
       "271  29839885      0     0     0     0      0      0      0     0     0  ...   \n",
       "272  29842315      0     0     0     0      0      0      0     0     0  ...   \n",
       "273  29858644      0     0     0     0      0      0      0     0     0  ...   \n",
       "274  29974575      0     0     0     0      0      0      1     0     0  ...   \n",
       "\n",
       "     Z95810  Z95820  Z961  Z96651  Z980  Z981  Z9884  Z9911  Z992  Z9981  \n",
       "0         0       0     0       0     0     0      0      0     0      0  \n",
       "1         0       0     0       0     0     0      1      0     1      0  \n",
       "2         0       0     0       0     0     0      0      0     0      0  \n",
       "3         0       0     0       0     0     0      0      0     0      0  \n",
       "4         0       0     0       0     0     0      0      0     0      0  \n",
       "..      ...     ...   ...     ...   ...   ...    ...    ...   ...    ...  \n",
       "270       0       0     0       0     0     0      0      0     0      0  \n",
       "271       0       0     0       0     0     0      0      0     0      0  \n",
       "272       0       0     0       0     0     0      0      0     1      1  \n",
       "273       0       0     0       0     0     0      0      0     0      0  \n",
       "274       0       0     0       0     0     0      0      0     0      0  \n",
       "\n",
       "[275 rows x 1473 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diagnoses = df_aggregated\n",
    "df_diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5b17e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/drgcodes.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_drgcodes = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "329d7c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22187210    2\n",
       "27505812    2\n",
       "25926192    2\n",
       "27089790    2\n",
       "24490144    2\n",
       "           ..\n",
       "22539296    1\n",
       "20385771    1\n",
       "20199380    1\n",
       "20973395    1\n",
       "23559586    1\n",
       "Name: hadm_id, Length: 233, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes['hadm_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15d4236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drgcodes = df_drgcodes.drop(columns=['subject_id','drg_type','description','drg_severity','drg_mortality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0836367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_drgcodes['drg_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_drgcodes[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3e6caaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>29802992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0    20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1    20093566   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2    20192635   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3    20199380   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4    20214994   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "..        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "228  29802992   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "229  29839885   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "230  29842315   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "231  29858644   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "232  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "     957  981  982  983  987  988  \n",
       "0      0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  \n",
       "228    0    0    0    0    0    0  \n",
       "229    0    0    0    0    0    0  \n",
       "230    0    0    0    0    0    0  \n",
       "231    0    0    0    0    0    0  \n",
       "232    0    0    0    0    0    0  \n",
       "\n",
       "[233 rows x 241 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes = df_aggregated\n",
    "df_drgcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693a672",
   "metadata": {},
   "source": [
    "### labevents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "454a85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't allocate memory this way \n",
    "\n",
    "# path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "# file = \"labevents_data_train.csv\"\n",
    "# full_path = path + file\n",
    "# X_train = pd.read_csv(full_path)\n",
    "\n",
    "# file = \"labevents_data_test.csv\"\n",
    "# full_path = path + file\n",
    "# X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b8016e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c9a2be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/labevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_labevents = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f4539060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents['value'] = pd.to_numeric(df_labevents['value'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98fd7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature for days_since_admission using charttime - admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['charttime'] = pd.to_datetime(df_labevents['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_labevents = df_labevents.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_labevents['days_since_admission'] = df_labevents['charttime'] - df_labevents['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['days_since_admission'] = df_labevents['days_since_admission'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "37ebb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add storetime - charttime feature called delay\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['storetime'] = pd.to_datetime(df_labevents['storetime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_labevents['delay'] = df_labevents['storetime'] - df_labevents['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['delay'] = df_labevents['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8a8831b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = df_labevents.drop(columns=['labevent_id','subject_id','order_provider_id','charttime','storetime','comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cbb4a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For flag make abnormal = 1 and fill Null with 0\n",
    "df_labevents['flag'] = df_labevents['flag'].fillna(0)\n",
    "df_labevents['flag'] = df_labevents['flag'].replace('abnormal', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d6407113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For priority fill Null with N/A and then one hot encode\n",
    "df_labevents['priority'] = df_labevents['priority'].fillna('N/A')\n",
    "df_labevents = pd.get_dummies(df_labevents, columns=['priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d8a050f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = pd.get_dummies(df_labevents, columns=['valueuom','specimen_id','itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d86fcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null values \n",
    "df_labevents = df_labevents.dropna()\n",
    "# Reduced from 107727 rows to 66660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b011ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = df_labevents.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "17c5d53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_52286</th>\n",
       "      <th>itemid_52312</th>\n",
       "      <th>itemid_52369</th>\n",
       "      <th>itemid_52391</th>\n",
       "      <th>itemid_52419</th>\n",
       "      <th>itemid_52425</th>\n",
       "      <th>itemid_52427</th>\n",
       "      <th>itemid_52769</th>\n",
       "      <th>itemid_52955</th>\n",
       "      <th>itemid_53153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>15.40</td>\n",
       "      <td>15.40</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>49.70</td>\n",
       "      <td>49.70</td>\n",
       "      <td>35.1</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29600294.0</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 01:03:00</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "0  29600294.0  15.40     15.40             10.5             15.5     0   \n",
       "1  29600294.0   3.35      3.35              4.6              6.1     1   \n",
       "2  29600294.0  49.70     49.70             35.1             46.3     1   \n",
       "3  29600294.0  20.30     20.30              4.0             10.0     1   \n",
       "4  29600294.0  31.10     31.10             32.0             37.0     1   \n",
       "\n",
       "  days_since_admission           delay  priority_N/A  priority_ROUTINE  ...  \\\n",
       "0      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "1      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "2      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "3      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "4      1 days 01:03:00 0 days 01:30:00             0                 1  ...   \n",
       "\n",
       "   itemid_52286  itemid_52312  itemid_52369  itemid_52391  itemid_52419  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   itemid_52425  itemid_52427  itemid_52769  itemid_52955  itemid_53153  \n",
       "0             0             0             0             0             0  \n",
       "1             0             0             0             0             0  \n",
       "2             0             0             0             0             0  \n",
       "3             0             0             0             0             0  \n",
       "4             0             0             0             0             0  \n",
       "\n",
       "[5 rows x 11680 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labevents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8c356",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "577d46e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (53328, 11680)\n",
      "Testing set shape: (13332, 11680)\n"
     ]
    }
   ],
   "source": [
    "data = df_labevents\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "labevents_data_train, labevents_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", labevents_data_train.shape)\n",
    "print(\"Testing set shape:\", labevents_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "95342afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labevents_data_train.drop(columns=['hadm_id'])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9baa6822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_52286</th>\n",
       "      <th>itemid_52312</th>\n",
       "      <th>itemid_52369</th>\n",
       "      <th>itemid_52391</th>\n",
       "      <th>itemid_52419</th>\n",
       "      <th>itemid_52425</th>\n",
       "      <th>itemid_52427</th>\n",
       "      <th>itemid_52769</th>\n",
       "      <th>itemid_52955</th>\n",
       "      <th>itemid_53153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99267</th>\n",
       "      <td>26793610.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 04:36:00</td>\n",
       "      <td>0 days 02:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106026</th>\n",
       "      <td>28998349.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7 days 03:35:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44791</th>\n",
       "      <td>22490490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5 days 15:25:00</td>\n",
       "      <td>0 days 02:06:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83275</th>\n",
       "      <td>28258130.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10 days 23:24:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100330</th>\n",
       "      <td>22205327.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>9 days 09:55:00</td>\n",
       "      <td>0 days 01:58:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hadm_id  value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "99267   26793610.0   19.0      19.0             22.0             32.0     1   \n",
       "106026  28998349.0   17.7      17.7             10.5             15.5     1   \n",
       "44791   22490490.0    0.0     134.0             70.0            100.0     1   \n",
       "83275   28258130.0   34.0      34.0             35.0             45.0     1   \n",
       "100330  22205327.0    2.4       2.4              1.6              2.6     0   \n",
       "\n",
       "       days_since_admission           delay  priority_N/A  priority_ROUTINE  \\\n",
       "99267       0 days 04:36:00 0 days 02:53:00             0                 1   \n",
       "106026      7 days 03:35:00 0 days 00:10:00             0                 1   \n",
       "44791       5 days 15:25:00 0 days 02:06:00             0                 1   \n",
       "83275      10 days 23:24:00 0 days 00:10:00             1                 0   \n",
       "100330      9 days 09:55:00 0 days 01:58:00             0                 0   \n",
       "\n",
       "        ...  itemid_52286  itemid_52312  itemid_52369  itemid_52391  \\\n",
       "99267   ...             0             0             0             0   \n",
       "106026  ...             0             0             0             0   \n",
       "44791   ...             0             0             0             0   \n",
       "83275   ...             0             0             0             0   \n",
       "100330  ...             0             0             0             0   \n",
       "\n",
       "        itemid_52419  itemid_52425  itemid_52427  itemid_52769  itemid_52955  \\\n",
       "99267              0             0             0             0             0   \n",
       "106026             0             0             0             0             0   \n",
       "44791              0             0             0             0             0   \n",
       "83275              0             0             0             0             0   \n",
       "100330             0             0             0             0             0   \n",
       "\n",
       "        itemid_53153  \n",
       "99267              0  \n",
       "106026             0  \n",
       "44791              0  \n",
       "83275              0  \n",
       "100330             0  \n",
       "\n",
       "[5 rows x 11680 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labevents_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4ea65e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# # Make sure the order is the same\n",
    "\n",
    "# # Extract the unique IDs from the column \n",
    "# train_ids = labevents_data_train['hadm_id'].unique()\n",
    "\n",
    "# # Filter to keep only rows where the id column is in train_ids\n",
    "# y_train = df_diagnoses[df_diagnoses['hadm_id'].isin(train_ids)]\n",
    "\n",
    "# test_ids = labevents_data_test['hadm_id'].unique()\n",
    "\n",
    "# # Filter to keep only rows where the id column is in train_ids\n",
    "# y_test = df_diagnoses[df_diagnoses['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c3280fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = labevents_data_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = labevents_data_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "44990abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, labevents_data_train['hadm_id'], on='hadm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c5159bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52756</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52757</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52758</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52759</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52760</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52761 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "...         ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "52756  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52757  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52758  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52759  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "52760  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "       957  981  982  983  987  988  \n",
       "0        0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  \n",
       "52756    0    0    0    0    0    0  \n",
       "52757    0    0    0    0    0    0  \n",
       "52758    0    0    0    0    0    0  \n",
       "52759    0    0    0    0    0    0  \n",
       "52760    0    0    0    0    0    0  \n",
       "\n",
       "[52761 rows x 241 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = merged_df\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "51ed26ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13194</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13195</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13196</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13197</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13198</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13199 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4      20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "...         ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "13194  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13195  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13196  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13197  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "13198  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "       957  981  982  983  987  988  \n",
       "0        0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  \n",
       "13194    0    0    0    0    0    0  \n",
       "13195    0    0    0    0    0    0  \n",
       "13196    0    0    0    0    0    0  \n",
       "13197    0    0    0    0    0    0  \n",
       "13198    0    0    0    0    0    0  \n",
       "\n",
       "[13199 rows x 241 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(y_test, labevents_data_test['hadm_id'], on='hadm_id')\n",
    "\n",
    "y_test = merged_df\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6c24e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = labevents_data_train\n",
    "X_test = labevents_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f5df4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['delay']= X_train['delay'].astype(str)\n",
    "# X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "# X_train['days_since_admission'] = X_train['days_since_admission'].astype(str)\n",
    "# X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "\n",
    "# X_train = X_train.drop(columns=['hadm_id'])\n",
    "# X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "# y_train = y_train.drop(columns=['hadm_id'])\n",
    "# y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "43a5b5c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_52286</th>\n",
       "      <th>itemid_52312</th>\n",
       "      <th>itemid_52369</th>\n",
       "      <th>itemid_52391</th>\n",
       "      <th>itemid_52419</th>\n",
       "      <th>itemid_52425</th>\n",
       "      <th>itemid_52427</th>\n",
       "      <th>itemid_52769</th>\n",
       "      <th>itemid_52955</th>\n",
       "      <th>itemid_53153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99267</th>\n",
       "      <td>26793610.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 04:36:00</td>\n",
       "      <td>0 days 02:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106026</th>\n",
       "      <td>28998349.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7 days 03:35:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44791</th>\n",
       "      <td>22490490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5 days 15:25:00</td>\n",
       "      <td>0 days 02:06:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83275</th>\n",
       "      <td>28258130.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10 days 23:24:00</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100330</th>\n",
       "      <td>22205327.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>9 days 09:55:00</td>\n",
       "      <td>0 days 01:58:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58478</th>\n",
       "      <td>28872262.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8 days 18:53:00</td>\n",
       "      <td>0 days 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>21476294.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21 days 10:06:00</td>\n",
       "      <td>0 days 01:08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89565</th>\n",
       "      <td>26467376.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 14:02:00</td>\n",
       "      <td>0 days 01:28:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>21476294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 12:06:00</td>\n",
       "      <td>0 days 02:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>29276678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6 days 05:14:00</td>\n",
       "      <td>0 days 10:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53328 rows × 11680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hadm_id  value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "99267   26793610.0   19.0      19.0             22.0             32.0     1   \n",
       "106026  28998349.0   17.7      17.7             10.5             15.5     1   \n",
       "44791   22490490.0    0.0     134.0             70.0            100.0     1   \n",
       "83275   28258130.0   34.0      34.0             35.0             45.0     1   \n",
       "100330  22205327.0    2.4       2.4              1.6              2.6     0   \n",
       "...            ...    ...       ...              ...              ...   ...   \n",
       "58478   28872262.0    3.9       3.9              3.3              5.1     0   \n",
       "9921    21476294.0  100.0     100.0             96.0            108.0     0   \n",
       "89565   26467376.0   68.5      68.5              9.4             12.5     1   \n",
       "1419    21476294.0    0.0       0.0              0.0              0.0     0   \n",
       "25176   29276678.0    0.0       0.0              0.0              0.0     0   \n",
       "\n",
       "       days_since_admission           delay  priority_N/A  priority_ROUTINE  \\\n",
       "99267       0 days 04:36:00 0 days 02:53:00             0                 1   \n",
       "106026      7 days 03:35:00 0 days 00:10:00             0                 1   \n",
       "44791       5 days 15:25:00 0 days 02:06:00             0                 1   \n",
       "83275      10 days 23:24:00 0 days 00:10:00             1                 0   \n",
       "100330      9 days 09:55:00 0 days 01:58:00             0                 0   \n",
       "...                     ...             ...           ...               ...   \n",
       "58478       8 days 18:53:00 0 days 01:00:00             0                 1   \n",
       "9921       21 days 10:06:00 0 days 01:08:00             0                 0   \n",
       "89565       0 days 14:02:00 0 days 01:28:00             0                 1   \n",
       "1419        0 days 12:06:00 0 days 02:15:00             0                 0   \n",
       "25176       6 days 05:14:00 0 days 10:15:00             0                 1   \n",
       "\n",
       "        ...  itemid_52286  itemid_52312  itemid_52369  itemid_52391  \\\n",
       "99267   ...             0             0             0             0   \n",
       "106026  ...             0             0             0             0   \n",
       "44791   ...             0             0             0             0   \n",
       "83275   ...             0             0             0             0   \n",
       "100330  ...             0             0             0             0   \n",
       "...     ...           ...           ...           ...           ...   \n",
       "58478   ...             0             0             0             0   \n",
       "9921    ...             0             0             0             0   \n",
       "89565   ...             0             0             0             0   \n",
       "1419    ...             0             0             0             0   \n",
       "25176   ...             0             0             0             0   \n",
       "\n",
       "        itemid_52419  itemid_52425  itemid_52427  itemid_52769  itemid_52955  \\\n",
       "99267              0             0             0             0             0   \n",
       "106026             0             0             0             0             0   \n",
       "44791              0             0             0             0             0   \n",
       "83275              0             0             0             0             0   \n",
       "100330             0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "58478              0             0             0             0             0   \n",
       "9921               0             0             0             0             0   \n",
       "89565              0             0             0             0             0   \n",
       "1419               0             0             0             0             0   \n",
       "25176              0             0             0             0             0   \n",
       "\n",
       "        itemid_53153  \n",
       "99267              0  \n",
       "106026             0  \n",
       "44791              0  \n",
       "83275              0  \n",
       "100330             0  \n",
       "...              ...  \n",
       "58478              0  \n",
       "9921               0  \n",
       "89565              0  \n",
       "1419               0  \n",
       "25176              0  \n",
       "\n",
       "[53328 rows x 11680 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fe72355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].astype(str)\n",
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].astype(str)\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "96c7fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['delay']= X_test['delay'].astype(str)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].astype(str)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].str.split().str[0].astype(int)\n",
    "\n",
    "X_test = X_test.drop(columns=['hadm_id'])\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2090cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrices to address memory issue\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X_train_sparse = csr_matrix(X_train)\n",
    "X_test_sparse = csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b387258",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction - not enough memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f918e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 11681 to 10665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d17d8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['delay']= data['delay'].astype(str)\n",
    "# data['delay']= data['delay'].apply(convert_to_days)\n",
    "# data['days_since_admission'] = data['days_since_admission'].astype(str)\n",
    "# data['days_since_admission'] = data['days_since_admission'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14edb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# # Number of desired features (components)\n",
    "# n_components = 10665\n",
    "\n",
    "# # Initialize Truncated SVD with the desired number of components\n",
    "# svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# # Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "# svd.fit(data)\n",
    "# data = svd.transform(data)\n",
    "\n",
    "# # Get the explained variance ratio (how much variance is explained by each component)\n",
    "# explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# # Print the transformed matrix and explained variance ratio\n",
    "# # print(\"Transformed Matrix:\")\n",
    "# # print(transformed_matrix)\n",
    "# print(\"\\nExplained Variance Ratio:\")\n",
    "# print(explained_variance_ratio)\n",
    "\n",
    "# print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a942c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e81c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89911efe",
   "metadata": {},
   "source": [
    "#### Multi-output decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96655603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42, max_depth=50)\n",
    "\n",
    "# Initialize the multi-output classifier with the decision tree as the base estimator\n",
    "multi_output_tree = MultiOutputClassifier(decision_tree, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14b448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the multi-output classifier\n",
    "multi_output_tree.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Predict the outputs for the test set\n",
    "y_pred = multi_output_tree.predict(X_test_sparse)\n",
    "\n",
    "# # Evaluate the accuracy of the multi-output classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff579c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.00      0.01       370\n",
      "           1       0.00      0.00      0.00       112\n",
      "           2       0.00      0.00      0.00       101\n",
      "           3       0.00      0.00      0.00       137\n",
      "           4       0.08      0.00      0.01       504\n",
      "           5       0.00      0.00      0.00        85\n",
      "           6       0.00      0.00      0.00       184\n",
      "           7       0.00      0.00      0.00        36\n",
      "           8       0.00      0.00      0.00       322\n",
      "           9       0.00      0.00      0.00        27\n",
      "          10       0.00      0.00      0.00       123\n",
      "          11       0.00      0.00      0.00       352\n",
      "          12       0.00      0.00      0.00        72\n",
      "          13       0.00      0.00      0.00        30\n",
      "          14       0.00      0.00      0.00        46\n",
      "          15       0.00      0.00      0.00        11\n",
      "          16       0.00      0.00      0.00        32\n",
      "          17       0.03      0.00      0.01       311\n",
      "          18       0.00      0.00      0.00       117\n",
      "          19       0.00      0.00      0.00       257\n",
      "          20       0.00      0.00      0.00        27\n",
      "          21       0.00      0.00      0.00        19\n",
      "          22       0.00      0.00      0.00        31\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        49\n",
      "          25       0.00      0.00      0.00        38\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.03      0.00      0.00       404\n",
      "          28       0.00      0.00      0.00        32\n",
      "          29       0.00      0.00      0.00        55\n",
      "          30       0.00      0.00      0.00       156\n",
      "          31       0.00      0.00      0.00       150\n",
      "          32       0.03      0.00      0.01       271\n",
      "          33       0.00      0.00      0.00        34\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        64\n",
      "          36       0.00      0.00      0.00        46\n",
      "          37       0.00      0.00      0.00        93\n",
      "          38       0.00      0.00      0.00        38\n",
      "          39       0.00      0.00      0.00       232\n",
      "          40       0.06      0.02      0.03        43\n",
      "          41       0.00      0.00      0.00       118\n",
      "          42       0.00      0.00      0.00        36\n",
      "          43       0.00      0.00      0.00       151\n",
      "          44       0.00      0.00      0.00        77\n",
      "          45       0.00      0.00      0.00        24\n",
      "          46       0.00      0.00      0.00        57\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00        63\n",
      "          50       0.00      0.00      0.00         9\n",
      "          51       0.05      0.01      0.01       129\n",
      "          52       0.00      0.00      0.00        31\n",
      "          53       0.00      0.00      0.00       151\n",
      "          54       0.00      0.00      0.00        36\n",
      "          55       0.00      0.00      0.00       120\n",
      "          56       0.00      0.00      0.00         9\n",
      "          57       0.05      0.00      0.01       238\n",
      "          58       0.05      0.01      0.01       129\n",
      "          59       0.00      0.00      0.00       120\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00        93\n",
      "          62       0.03      0.00      0.00       383\n",
      "          63       0.11      0.01      0.01       529\n",
      "          64       0.00      0.00      0.00        46\n",
      "          65       0.00      0.00      0.00        32\n",
      "          66       0.00      0.00      0.00        77\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00        22\n",
      "          69       0.00      0.00      0.00        17\n",
      "          70       0.00      0.00      0.00       118\n",
      "          71       0.00      0.00      0.00        42\n",
      "          72       0.05      0.00      0.00       634\n",
      "          73       0.00      0.00      0.00        11\n",
      "          74       0.00      0.00      0.00       106\n",
      "          75       0.05      0.00      0.00      1071\n",
      "          76       0.06      0.00      0.01       322\n",
      "          77       0.00      0.00      0.00       118\n",
      "          78       0.10      0.02      0.03        53\n",
      "          79       0.00      0.00      0.00        59\n",
      "          80       0.00      0.00      0.00        71\n",
      "          81       0.00      0.00      0.00        11\n",
      "          82       0.00      0.00      0.00       133\n",
      "          83       0.00      0.00      0.00        24\n",
      "          84       0.00      0.00      0.00        58\n",
      "          85       0.00      0.00      0.00        12\n",
      "          86       0.00      0.00      0.00        25\n",
      "          87       0.00      0.00      0.00       155\n",
      "          88       0.00      0.00      0.00        27\n",
      "          89       0.00      0.00      0.00       846\n",
      "          90       0.00      0.00      0.00        25\n",
      "          91       0.00      0.00      0.00        78\n",
      "          92       0.08      0.00      0.01       814\n",
      "          93       0.21      0.01      0.02      2290\n",
      "          94       0.03      0.00      0.01       340\n",
      "          95       0.09      0.01      0.01       318\n",
      "          96       0.00      0.00      0.00       180\n",
      "          97       0.00      0.00      0.00       120\n",
      "          98       0.03      0.00      0.00       938\n",
      "          99       0.10      0.00      0.01       982\n",
      "         100       0.07      0.00      0.00      1203\n",
      "         101       0.07      0.01      0.02       218\n",
      "         102       0.00      0.00      0.00        98\n",
      "         103       0.00      0.00      0.00        55\n",
      "         104       0.00      0.00      0.00        99\n",
      "         105       0.00      0.00      0.00       499\n",
      "         106       0.00      0.00      0.00       643\n",
      "         107       0.07      0.00      0.01       619\n",
      "         108       0.00      0.00      0.00        70\n",
      "         109       0.13      0.00      0.01       932\n",
      "         110       0.00      0.00      0.00       139\n",
      "         111       0.00      0.00      0.00       244\n",
      "         112       0.00      0.00      0.00        66\n",
      "         113       0.00      0.00      0.00        44\n",
      "         114       0.08      0.01      0.01       176\n",
      "         115       0.00      0.00      0.00        70\n",
      "         116       0.00      0.00      0.00       327\n",
      "         117       0.06      0.00      0.00       475\n",
      "         118       0.00      0.00      0.00       128\n",
      "         119       0.00      0.00      0.00       321\n",
      "         120       0.00      0.00      0.00       120\n",
      "         121       0.10      0.01      0.01      1479\n",
      "         122       0.00      0.00      0.00       237\n",
      "         123       0.00      0.00      0.00       239\n",
      "         124       0.04      0.00      0.01       230\n",
      "         125       0.03      0.00      0.00       939\n",
      "         126       0.00      0.00      0.00       258\n",
      "         127       0.00      0.00      0.00       368\n",
      "         128       0.00      0.00      0.00       128\n",
      "         129       0.00      0.00      0.00        58\n",
      "         130       0.00      0.00      0.00        28\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00       397\n",
      "         133       0.00      0.00      0.00        66\n",
      "         134       0.00      0.00      0.00       139\n",
      "         135       0.04      0.00      0.01       247\n",
      "         136       0.00      0.00      0.00        56\n",
      "         137       0.00      0.00      0.00        92\n",
      "         138       0.00      0.00      0.00        22\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00        18\n",
      "         143       0.00      0.00      0.00        41\n",
      "         144       0.10      0.01      0.02       161\n",
      "         145       0.00      0.00      0.00       439\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00        72\n",
      "         148       0.00      0.00      0.00        23\n",
      "         149       0.00      0.00      0.00        60\n",
      "         150       0.14      0.01      0.01       277\n",
      "         151       0.00      0.00      0.00        36\n",
      "         152       0.00      0.00      0.00       119\n",
      "         153       0.03      0.00      0.00       425\n",
      "         154       0.00      0.00      0.00        44\n",
      "         155       0.00      0.00      0.00       181\n",
      "         156       0.00      0.00      0.00       744\n",
      "         157       0.00      0.00      0.00         7\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         4\n",
      "         160       0.00      0.00      0.00       130\n",
      "         161       0.00      0.00      0.00       109\n",
      "         162       0.06      0.00      0.01      1055\n",
      "         163       0.00      0.00      0.00       117\n",
      "         164       0.00      0.00      0.00       110\n",
      "         165       0.00      0.00      0.00        51\n",
      "         166       0.03      0.00      0.01       297\n",
      "         167       0.00      0.00      0.00        66\n",
      "         168       0.00      0.00      0.00         8\n",
      "         169       0.00      0.00      0.00        12\n",
      "         170       0.00      0.00      0.00        25\n",
      "         171       0.00      0.00      0.00        46\n",
      "         172       0.00      0.00      0.00       195\n",
      "         173       0.00      0.00      0.00         5\n",
      "         174       0.05      0.01      0.01       180\n",
      "         175       0.07      0.00      0.01       427\n",
      "         176       0.00      0.00      0.00       258\n",
      "         177       0.00      0.00      0.00        51\n",
      "         178       0.00      0.00      0.00       117\n",
      "         179       0.00      0.00      0.00        65\n",
      "         180       0.00      0.00      0.00        31\n",
      "         181       0.00      0.00      0.00        44\n",
      "         182       0.00      0.00      0.00        46\n",
      "         183       0.00      0.00      0.00        98\n",
      "         184       0.10      0.00      0.01       603\n",
      "         185       0.06      0.00      0.01       247\n",
      "         186       0.00      0.00      0.00       154\n",
      "         187       0.00      0.00      0.00        24\n",
      "         188       0.00      0.00      0.00       137\n",
      "         189       0.00      0.00      0.00        93\n",
      "         190       0.00      0.00      0.00       233\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00       136\n",
      "         193       0.00      0.00      0.00       103\n",
      "         194       0.00      0.00      0.00       118\n",
      "         195       0.00      0.00      0.00        71\n",
      "         196       0.00      0.00      0.00        36\n",
      "         197       0.00      0.00      0.00        77\n",
      "         198       0.00      0.00      0.00        77\n",
      "         199       0.00      0.00      0.00        44\n",
      "         200       0.00      0.00      0.00        12\n",
      "         201       0.00      0.00      0.00        14\n",
      "         202       0.00      0.00      0.00        14\n",
      "         203       0.00      0.00      0.00        44\n",
      "         204       0.00      0.00      0.00        47\n",
      "         205       0.00      0.00      0.00        66\n",
      "         206       0.00      0.00      0.00        36\n",
      "         207       0.00      0.00      0.00        39\n",
      "         208       0.15      0.01      0.01      2699\n",
      "         209       0.00      0.00      0.00       117\n",
      "         210       0.03      0.00      0.00      1266\n",
      "         211       0.00      0.00      0.00        45\n",
      "         212       0.00      0.00      0.00        39\n",
      "         213       0.00      0.00      0.00       150\n",
      "         214       0.00      0.00      0.00       103\n",
      "         215       0.00      0.00      0.00        33\n",
      "         216       0.00      0.00      0.00       241\n",
      "         217       0.00      0.00      0.00        50\n",
      "         218       0.00      0.00      0.00        88\n",
      "         219       0.21      0.01      0.01      1375\n",
      "         220       0.00      0.00      0.00        21\n",
      "         221       0.00      0.00      0.00       107\n",
      "         222       0.00      0.00      0.00        82\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00        32\n",
      "         225       0.00      0.00      0.00        31\n",
      "         226       0.08      0.01      0.01       312\n",
      "         227       0.00      0.00      0.00        31\n",
      "         228       0.00      0.00      0.00        79\n",
      "         229       0.10      0.00      0.01       626\n",
      "         230       0.00      0.00      0.00       157\n",
      "         231       0.04      0.00      0.01       247\n",
      "         232       0.00      0.00      0.00        92\n",
      "         233       0.00      0.00      0.00        14\n",
      "         234       0.00      0.00      0.00        77\n",
      "         235       0.00      0.00      0.00        92\n",
      "         236       0.04      0.00      0.01       284\n",
      "         237       0.03      0.00      0.00       521\n",
      "         238       0.09      0.00      0.00      1696\n",
      "         239       0.00      0.00      0.00        72\n",
      "         240       0.00      0.00      0.00        51\n",
      "         241       0.00      0.00      0.00       130\n",
      "         242       0.05      0.00      0.00      1500\n",
      "         243       0.05      0.01      0.01       139\n",
      "         244       0.00      0.00      0.00        59\n",
      "         245       0.00      0.00      0.00       213\n",
      "         246       0.00      0.00      0.00         0\n",
      "         247       0.00      0.00      0.00        34\n",
      "         248       0.06      0.01      0.01       257\n",
      "         249       0.00      0.00      0.00        51\n",
      "         250       0.00      0.00      0.00        85\n",
      "         251       0.00      0.00      0.00        21\n",
      "         252       0.00      0.00      0.00        77\n",
      "         253       0.00      0.00      0.00        54\n",
      "         254       0.00      0.00      0.00        17\n",
      "         255       0.00      0.00      0.00       134\n",
      "         256       0.00      0.00      0.00        24\n",
      "         257       0.00      0.00      0.00        26\n",
      "         258       0.00      0.00      0.00        84\n",
      "         259       0.00      0.00      0.00        37\n",
      "         260       0.00      0.00      0.00       112\n",
      "         261       0.00      0.00      0.00        42\n",
      "         262       0.00      0.00      0.00       125\n",
      "         263       0.00      0.00      0.00         7\n",
      "         264       0.00      0.00      0.00         6\n",
      "         265       0.00      0.00      0.00        10\n",
      "         266       0.00      0.00      0.00       118\n",
      "         267       0.05      0.01      0.01       181\n",
      "         268       0.00      0.00      0.00       214\n",
      "         269       0.00      0.00      0.00       151\n",
      "         270       0.00      0.00      0.00         0\n",
      "         271       0.06      0.00      0.01       244\n",
      "         272       0.07      0.01      0.01       192\n",
      "         273       0.00      0.00      0.00        17\n",
      "         274       0.00      0.00      0.00        32\n",
      "         275       0.00      0.00      0.00         8\n",
      "         276       0.00      0.00      0.00       155\n",
      "         277       0.00      0.00      0.00        45\n",
      "         278       0.00      0.00      0.00       151\n",
      "         279       0.00      0.00      0.00        12\n",
      "         280       0.00      0.00      0.00        77\n",
      "         281       0.04      0.00      0.00       423\n",
      "         282       0.00      0.00      0.00        14\n",
      "         283       0.00      0.00      0.00       597\n",
      "         284       0.04      0.00      0.01       247\n",
      "         285       0.00      0.00      0.00        89\n",
      "         286       0.00      0.00      0.00        45\n",
      "         287       0.00      0.00      0.00       120\n",
      "         288       0.00      0.00      0.00        11\n",
      "         289       0.00      0.00      0.00       254\n",
      "         290       0.00      0.00      0.00        35\n",
      "         291       0.00      0.00      0.00       258\n",
      "         292       0.00      0.00      0.00       184\n",
      "         293       0.04      0.00      0.01       284\n",
      "         294       0.00      0.00      0.00        77\n",
      "         295       0.00      0.00      0.00       117\n",
      "         296       0.00      0.00      0.00        36\n",
      "         297       0.04      0.00      0.01       245\n",
      "         298       0.10      0.00      0.01       507\n",
      "         299       0.00      0.00      0.00        32\n",
      "         300       0.00      0.00      0.00        25\n",
      "         301       0.00      0.00      0.00         5\n",
      "         302       0.06      0.00      0.00       788\n",
      "         303       0.00      0.00      0.00       148\n",
      "         304       0.00      0.00      0.00       365\n",
      "         305       0.00      0.00      0.00       538\n",
      "         306       0.00      0.00      0.00        46\n",
      "         307       0.00      0.00      0.00        36\n",
      "         308       0.00      0.00      0.00       123\n",
      "         309       0.00      0.00      0.00       411\n",
      "         310       0.00      0.00      0.00        35\n",
      "         311       0.00      0.00      0.00       379\n",
      "         312       0.05      0.01      0.01       121\n",
      "         313       0.00      0.00      0.00        66\n",
      "         314       0.00      0.00      0.00       433\n",
      "         315       0.06      0.00      0.01       267\n",
      "         316       0.04      0.00      0.01       284\n",
      "         317       0.00      0.00      0.00       155\n",
      "         318       0.05      0.00      0.00      1568\n",
      "         319       0.00      0.00      0.00       114\n",
      "         320       0.00      0.00      0.00        21\n",
      "         321       0.00      0.00      0.00        70\n",
      "         322       0.00      0.00      0.00        62\n",
      "         323       0.00      0.00      0.00        44\n",
      "         324       0.05      0.00      0.00      1034\n",
      "         325       0.00      0.00      0.00       177\n",
      "         326       0.00      0.00      0.00        84\n",
      "         327       0.00      0.00      0.00        62\n",
      "         328       0.00      0.00      0.00        82\n",
      "         329       0.00      0.00      0.00        62\n",
      "         330       0.00      0.00      0.00       262\n",
      "         331       0.00      0.00      0.00        12\n",
      "         332       0.00      0.00      0.00       155\n",
      "         333       0.00      0.00      0.00       155\n",
      "         334       0.00      0.00      0.00        20\n",
      "         335       0.00      0.00      0.00        36\n",
      "         336       0.07      0.01      0.01       192\n",
      "         337       0.00      0.00      0.00       224\n",
      "         338       0.00      0.00      0.00       136\n",
      "         339       0.00      0.00      0.00        91\n",
      "         340       0.00      0.00      0.00       508\n",
      "         341       0.08      0.01      0.01       357\n",
      "         342       0.00      0.00      0.00        10\n",
      "         343       0.00      0.00      0.00       595\n",
      "         344       0.07      0.01      0.01       192\n",
      "         345       0.00      0.00      0.00       384\n",
      "         346       0.00      0.00      0.00       224\n",
      "         347       0.00      0.00      0.00       302\n",
      "         348       0.00      0.00      0.00       184\n",
      "         349       0.00      0.00      0.00       187\n",
      "         350       0.00      0.00      0.00       155\n",
      "         351       0.00      0.00      0.00        26\n",
      "         352       0.00      0.00      0.00       234\n",
      "         353       0.00      0.00      0.00       151\n",
      "         354       0.00      0.00      0.00       103\n",
      "         355       0.00      0.00      0.00        38\n",
      "         356       0.00      0.00      0.00        62\n",
      "         357       0.10      0.03      0.05        32\n",
      "         358       0.04      0.00      0.00       455\n",
      "         359       0.00      0.00      0.00       129\n",
      "         360       0.00      0.00      0.00       164\n",
      "         361       0.00      0.00      0.00       189\n",
      "         362       0.04      0.00      0.01       284\n",
      "         363       0.03      0.01      0.01       191\n",
      "         364       0.00      0.00      0.00        45\n",
      "         365       0.04      0.00      0.00       444\n",
      "         366       0.03      0.00      0.01       242\n",
      "         367       0.00      0.00      0.00       258\n",
      "         368       0.00      0.00      0.00        22\n",
      "         369       0.00      0.00      0.00        36\n",
      "         370       0.05      0.01      0.01       139\n",
      "         371       0.00      0.00      0.00       117\n",
      "         372       0.00      0.00      0.00       137\n",
      "         373       0.00      0.00      0.00       487\n",
      "         374       0.00      0.00      0.00        84\n",
      "         375       0.03      0.00      0.00       370\n",
      "         376       0.00      0.00      0.00        17\n",
      "         377       0.00      0.00      0.00       156\n",
      "         378       0.00      0.00      0.00       297\n",
      "         379       0.00      0.00      0.00       137\n",
      "         380       0.00      0.00      0.00       117\n",
      "         381       0.05      0.01      0.01       183\n",
      "         382       0.08      0.00      0.01      1156\n",
      "         383       0.11      0.00      0.01      1272\n",
      "         384       0.04      0.00      0.00       685\n",
      "         385       0.00      0.00      0.00        10\n",
      "         386       0.00      0.00      0.00        35\n",
      "         387       0.04      0.00      0.00       828\n",
      "         388       0.00      0.00      0.00        11\n",
      "         389       0.00      0.00      0.00        65\n",
      "         390       0.00      0.00      0.00        38\n",
      "         391       0.00      0.00      0.00        27\n",
      "         392       0.06      0.01      0.01       151\n",
      "         393       0.00      0.00      0.00        10\n",
      "         394       0.00      0.00      0.00       106\n",
      "         395       0.15      0.00      0.01      1304\n",
      "         396       0.00      0.00      0.00        44\n",
      "         397       0.00      0.00      0.00        22\n",
      "         398       0.00      0.00      0.00        65\n",
      "         399       0.00      0.00      0.00        22\n",
      "         400       0.08      0.01      0.02        79\n",
      "         401       0.00      0.00      0.00        80\n",
      "         402       0.04      0.00      0.01       284\n",
      "         403       0.00      0.00      0.00       258\n",
      "         404       0.10      0.02      0.03        53\n",
      "         405       0.00      0.00      0.00        12\n",
      "         406       0.00      0.00      0.00        12\n",
      "         407       0.00      0.00      0.00         5\n",
      "         408       0.00      0.00      0.00         0\n",
      "         409       0.10      0.02      0.03        53\n",
      "         410       0.00      0.00      0.00         7\n",
      "         411       0.00      0.00      0.00       192\n",
      "         412       0.00      0.00      0.00        32\n",
      "         413       0.00      0.00      0.00        71\n",
      "         414       0.00      0.00      0.00        77\n",
      "         415       0.04      0.00      0.01       284\n",
      "         416       0.00      0.00      0.00        83\n",
      "         417       0.00      0.00      0.00       169\n",
      "         418       0.00      0.00      0.00        32\n",
      "         419       0.00      0.00      0.00       118\n",
      "         420       0.05      0.01      0.01       129\n",
      "         421       0.00      0.00      0.00       146\n",
      "         422       0.00      0.00      0.00         9\n",
      "         423       0.00      0.00      0.00       120\n",
      "         424       0.06      0.00      0.01       262\n",
      "         425       0.00      0.00      0.00         6\n",
      "         426       0.00      0.00      0.00        13\n",
      "         427       0.00      0.00      0.00       122\n",
      "         428       0.00      0.00      0.00        77\n",
      "         429       0.00      0.00      0.00       262\n",
      "         430       0.00      0.00      0.00        44\n",
      "         431       0.00      0.00      0.00        96\n",
      "         432       0.00      0.00      0.00        47\n",
      "         433       0.00      0.00      0.00        36\n",
      "         434       0.00      0.00      0.00        68\n",
      "         435       0.00      0.00      0.00        44\n",
      "         436       0.00      0.00      0.00        12\n",
      "         437       0.00      0.00      0.00        24\n",
      "         438       0.00      0.00      0.00        24\n",
      "         439       0.00      0.00      0.00        53\n",
      "         440       0.00      0.00      0.00        53\n",
      "         441       0.00      0.00      0.00        25\n",
      "         442       0.00      0.00      0.00        33\n",
      "         443       0.05      0.01      0.01       181\n",
      "         444       0.00      0.00      0.00        24\n",
      "         445       0.04      0.00      0.01       284\n",
      "         446       0.00      0.00      0.00       155\n",
      "         447       0.00      0.00      0.00        12\n",
      "         448       0.00      0.00      0.00        31\n",
      "         449       0.00      0.00      0.00         5\n",
      "         450       0.00      0.00      0.00        93\n",
      "         451       0.00      0.00      0.00        41\n",
      "         452       0.00      0.00      0.00        41\n",
      "         453       0.05      0.00      0.01       260\n",
      "         454       0.00      0.00      0.00        33\n",
      "         455       0.05      0.01      0.01       139\n",
      "         456       0.00      0.00      0.00        13\n",
      "         457       0.00      0.00      0.00        93\n",
      "         458       0.00      0.00      0.00        39\n",
      "         459       0.00      0.00      0.00        10\n",
      "         460       0.00      0.00      0.00        33\n",
      "         461       0.04      0.00      0.01       247\n",
      "         462       0.00      0.00      0.00         1\n",
      "         463       0.00      0.00      0.00        24\n",
      "         464       0.00      0.00      0.00       185\n",
      "         465       0.00      0.00      0.00        32\n",
      "         466       0.00      0.00      0.00       185\n",
      "         467       0.00      0.00      0.00        44\n",
      "         468       0.00      0.00      0.00       258\n",
      "         469       0.00      0.00      0.00        43\n",
      "         470       0.00      0.00      0.00        13\n",
      "         471       0.00      0.00      0.00        27\n",
      "         472       0.00      0.00      0.00       151\n",
      "         473       0.00      0.00      0.00       306\n",
      "         474       0.00      0.00      0.00        93\n",
      "         475       0.00      0.00      0.00        24\n",
      "         476       0.00      0.00      0.00        31\n",
      "         477       0.00      0.00      0.00       135\n",
      "         478       0.03      0.00      0.01       306\n",
      "         479       0.08      0.01      0.01       176\n",
      "         480       0.00      0.00      0.00       215\n",
      "         481       0.00      0.00      0.00       117\n",
      "         482       0.00      0.00      0.00         0\n",
      "         483       0.00      0.00      0.00        32\n",
      "         484       0.00      0.00      0.00        48\n",
      "         485       0.00      0.00      0.00        24\n",
      "         486       0.00      0.00      0.00        57\n",
      "         487       0.00      0.00      0.00        17\n",
      "         488       0.00      0.00      0.00       227\n",
      "         489       0.00      0.00      0.00       463\n",
      "         490       0.00      0.00      0.00         0\n",
      "         491       0.00      0.00      0.00        17\n",
      "         492       0.05      0.01      0.01       139\n",
      "         493       0.00      0.00      0.00       663\n",
      "         494       0.00      0.00      0.00        26\n",
      "         495       0.00      0.00      0.00       155\n",
      "         496       0.00      0.00      0.00        26\n",
      "         497       0.00      0.00      0.00       120\n",
      "         498       0.00      0.00      0.00        89\n",
      "         499       0.08      0.01      0.01       176\n",
      "         500       0.00      0.00      0.00       449\n",
      "         501       0.05      0.01      0.01       194\n",
      "         502       0.00      0.00      0.00        44\n",
      "         503       0.00      0.00      0.00        35\n",
      "         504       0.09      0.00      0.01       596\n",
      "         505       0.00      0.00      0.00       718\n",
      "         506       0.00      0.00      0.00        12\n",
      "         507       0.00      0.00      0.00       100\n",
      "         508       0.00      0.00      0.00       224\n",
      "         509       0.00      0.00      0.00       155\n",
      "         510       0.00      0.00      0.00        11\n",
      "         511       0.00      0.00      0.00         5\n",
      "         512       0.00      0.00      0.00        12\n",
      "         513       0.07      0.00      0.01       660\n",
      "         514       0.00      0.00      0.00       118\n",
      "         515       0.00      0.00      0.00        24\n",
      "         516       0.05      0.01      0.01       139\n",
      "         517       0.12      0.00      0.01       545\n",
      "         518       0.00      0.00      0.00        73\n",
      "         519       0.05      0.01      0.01       139\n",
      "         520       0.05      0.00      0.00       392\n",
      "         521       0.00      0.00      0.00       367\n",
      "         522       0.00      0.00      0.00        19\n",
      "         523       0.00      0.00      0.00        88\n",
      "         524       0.00      0.00      0.00       161\n",
      "         525       0.00      0.00      0.00        24\n",
      "         526       0.00      0.00      0.00       412\n",
      "         527       0.00      0.00      0.00       167\n",
      "         528       0.00      0.00      0.00        15\n",
      "         529       0.04      0.00      0.01       284\n",
      "         530       0.04      0.00      0.01       290\n",
      "         531       0.09      0.01      0.01       295\n",
      "         532       0.00      0.00      0.00        25\n",
      "         533       0.05      0.00      0.01       330\n",
      "         534       0.00      0.00      0.00         8\n",
      "         535       0.00      0.00      0.00        32\n",
      "         536       0.00      0.00      0.00        44\n",
      "         537       0.07      0.01      0.01       192\n",
      "         538       0.00      0.00      0.00        11\n",
      "         539       0.00      0.00      0.00        37\n",
      "         540       0.00      0.00      0.00        46\n",
      "         541       0.04      0.00      0.01       284\n",
      "         542       0.00      0.00      0.00        66\n",
      "         543       0.00      0.00      0.00        60\n",
      "         544       0.00      0.00      0.00        44\n",
      "         545       0.00      0.00      0.00        10\n",
      "         546       0.00      0.00      0.00        55\n",
      "         547       0.00      0.00      0.00        33\n",
      "         548       0.04      0.00      0.01       284\n",
      "         549       0.04      0.00      0.01       284\n",
      "         550       0.04      0.00      0.01       284\n",
      "         551       0.04      0.00      0.01       284\n",
      "         552       0.04      0.00      0.01       284\n",
      "         553       0.04      0.00      0.01       284\n",
      "         554       0.04      0.00      0.01       284\n",
      "         555       0.04      0.00      0.01       284\n",
      "         556       0.11      0.01      0.02        95\n",
      "         557       0.00      0.00      0.00        31\n",
      "         558       0.00      0.00      0.00        66\n",
      "         559       0.00      0.00      0.00        44\n",
      "         560       0.00      0.00      0.00         6\n",
      "         561       0.04      0.00      0.01       247\n",
      "         562       0.04      0.00      0.01       284\n",
      "         563       0.04      0.00      0.01       284\n",
      "         564       0.00      0.00      0.00        13\n",
      "         565       0.00      0.00      0.00        12\n",
      "         566       0.04      0.00      0.00       461\n",
      "         567       0.05      0.00      0.00       908\n",
      "         568       0.07      0.01      0.01       192\n",
      "         569       0.00      0.00      0.00         4\n",
      "         570       0.00      0.00      0.00        92\n",
      "         571       0.00      0.00      0.00        49\n",
      "         572       0.00      0.00      0.00        19\n",
      "         573       0.09      0.01      0.01       343\n",
      "         574       0.00      0.00      0.00        21\n",
      "         575       0.03      0.00      0.00       405\n",
      "         576       0.03      0.00      0.01       268\n",
      "         577       0.05      0.01      0.01       150\n",
      "         578       0.07      0.01      0.01       192\n",
      "         579       0.00      0.00      0.00       193\n",
      "         580       0.00      0.00      0.00       230\n",
      "         581       0.00      0.00      0.00        62\n",
      "         582       0.00      0.00      0.00       238\n",
      "         583       0.00      0.00      0.00       308\n",
      "         584       0.00      0.00      0.00        51\n",
      "         585       0.13      0.01      0.02       208\n",
      "         586       0.00      0.00      0.00       258\n",
      "         587       0.07      0.01      0.02        69\n",
      "         588       0.04      0.00      0.01       256\n",
      "         589       0.05      0.01      0.01       176\n",
      "         590       0.00      0.00      0.00        16\n",
      "         591       0.00      0.00      0.00        76\n",
      "         592       0.00      0.00      0.00        34\n",
      "         593       0.00      0.00      0.00       373\n",
      "         594       0.00      0.00      0.00        39\n",
      "         595       0.10      0.00      0.01       908\n",
      "         596       0.00      0.00      0.00       174\n",
      "         597       0.00      0.00      0.00        77\n",
      "         598       0.00      0.00      0.00       172\n",
      "         599       0.00      0.00      0.00        37\n",
      "         600       0.00      0.00      0.00         0\n",
      "         601       0.00      0.00      0.00        41\n",
      "         602       0.00      0.00      0.00        76\n",
      "         603       0.00      0.00      0.00        48\n",
      "         604       0.03      0.00      0.01       313\n",
      "         605       0.00      0.00      0.00        14\n",
      "         606       0.07      0.01      0.01       272\n",
      "         607       0.07      0.01      0.01       272\n",
      "         608       0.00      0.00      0.00       116\n",
      "         609       0.00      0.00      0.00       372\n",
      "         610       0.03      0.00      0.00       450\n",
      "         611       0.03      0.00      0.01       310\n",
      "         612       0.00      0.00      0.00       174\n",
      "         613       0.00      0.00      0.00        47\n",
      "         614       0.00      0.00      0.00        74\n",
      "         615       0.04      0.00      0.00       530\n",
      "         616       0.00      0.00      0.00        77\n",
      "         617       0.00      0.00      0.00        77\n",
      "         618       0.03      0.00      0.00       796\n",
      "         619       0.00      0.00      0.00        30\n",
      "         620       0.04      0.00      0.01       262\n",
      "         621       0.00      0.00      0.00        14\n",
      "         622       0.00      0.00      0.00        14\n",
      "         623       0.00      0.00      0.00        48\n",
      "         624       0.00      0.00      0.00        12\n",
      "         625       0.04      0.00      0.00       378\n",
      "         626       0.00      0.00      0.00        46\n",
      "         627       0.00      0.00      0.00         2\n",
      "         628       0.04      0.00      0.01       262\n",
      "         629       0.04      0.00      0.01       262\n",
      "         630       0.00      0.00      0.00       164\n",
      "         631       0.00      0.00      0.00       164\n",
      "         632       0.03      0.00      0.01       298\n",
      "         633       0.14      0.00      0.01       930\n",
      "         634       0.00      0.00      0.00         0\n",
      "         635       0.00      0.00      0.00        29\n",
      "         636       0.07      0.01      0.01       272\n",
      "         637       0.04      0.00      0.01       320\n",
      "         638       0.00      0.00      0.00        77\n",
      "         639       0.00      0.00      0.00        77\n",
      "         640       0.03      0.00      0.00       399\n",
      "         641       0.00      0.00      0.00        14\n",
      "         642       0.00      0.00      0.00        77\n",
      "         643       0.00      0.00      0.00       341\n",
      "         644       0.00      0.00      0.00       112\n",
      "         645       0.00      0.00      0.00        76\n",
      "         646       0.00      0.00      0.00        84\n",
      "         647       0.00      0.00      0.00       254\n",
      "         648       0.00      0.00      0.00       174\n",
      "         649       0.00      0.00      0.00       112\n",
      "         650       0.00      0.00      0.00       511\n",
      "         651       0.16      0.00      0.01      1940\n",
      "         652       0.03      0.00      0.00       772\n",
      "         653       0.00      0.00      0.00       222\n",
      "         654       0.00      0.00      0.00       650\n",
      "         655       0.00      0.00      0.00        41\n",
      "         656       0.17      0.01      0.01      1400\n",
      "         657       0.00      0.00      0.00       373\n",
      "         658       0.04      0.00      0.01       290\n",
      "         659       0.06      0.00      0.00       894\n",
      "         660       0.10      0.00      0.01       669\n",
      "         661       0.16      0.00      0.01      1718\n",
      "         662       0.00      0.00      0.00        74\n",
      "         663       0.12      0.01      0.01       592\n",
      "         664       0.00      0.00      0.00        47\n",
      "         665       0.00      0.00      0.00        17\n",
      "         666       0.00      0.00      0.00       167\n",
      "         667       0.00      0.00      0.00        53\n",
      "         668       0.07      0.01      0.01       272\n",
      "         669       0.00      0.00      0.00       179\n",
      "         670       0.35      0.01      0.02      2839\n",
      "         671       0.00      0.00      0.00        11\n",
      "         672       0.00      0.00      0.00        48\n",
      "         673       0.00      0.00      0.00         0\n",
      "         674       0.00      0.00      0.00         0\n",
      "         675       0.00      0.00      0.00        21\n",
      "         676       0.00      0.00      0.00        53\n",
      "         677       0.00      0.00      0.00        61\n",
      "         678       0.06      0.00      0.00       991\n",
      "         679       0.00      0.00      0.00       102\n",
      "         680       0.00      0.00      0.00       168\n",
      "         681       0.07      0.00      0.01       878\n",
      "         682       0.00      0.00      0.00        17\n",
      "         683       0.00      0.00      0.00       225\n",
      "         684       0.00      0.00      0.00       563\n",
      "         685       0.00      0.00      0.00        32\n",
      "         686       0.00      0.00      0.00        32\n",
      "         687       0.04      0.00      0.00       583\n",
      "         688       0.00      0.00      0.00       297\n",
      "         689       0.00      0.00      0.00        77\n",
      "         690       0.00      0.00      0.00        77\n",
      "         691       0.13      0.01      0.01      1528\n",
      "         692       0.00      0.00      0.00         4\n",
      "         693       0.04      0.00      0.00       429\n",
      "         694       0.00      0.00      0.00        28\n",
      "         695       0.09      0.00      0.01      1386\n",
      "         696       0.06      0.00      0.01       419\n",
      "         697       0.00      0.00      0.00       438\n",
      "         698       0.03      0.00      0.00       399\n",
      "         699       0.03      0.00      0.00       399\n",
      "         700       0.00      0.00      0.00       228\n",
      "         701       0.08      0.00      0.01      1128\n",
      "         702       0.05      0.01      0.01       277\n",
      "         703       0.00      0.00      0.00       363\n",
      "         704       0.00      0.00      0.00        53\n",
      "         705       0.19      0.01      0.01      2697\n",
      "         706       0.00      0.00      0.00       399\n",
      "         707       0.00      0.00      0.00        91\n",
      "         708       0.11      0.01      0.02        95\n",
      "         709       0.09      0.01      0.01       295\n",
      "         710       0.00      0.00      0.00       455\n",
      "         711       0.00      0.00      0.00       250\n",
      "         712       0.08      0.01      0.02       106\n",
      "         713       0.09      0.00      0.01      1442\n",
      "         714       0.00      0.00      0.00         4\n",
      "         715       0.06      0.00      0.01       207\n",
      "         716       0.00      0.00      0.00        13\n",
      "         717       0.03      0.00      0.00       400\n",
      "         718       0.00      0.00      0.00       117\n",
      "         719       0.04      0.00      0.01       284\n",
      "         720       0.07      0.00      0.01       687\n",
      "         721       0.00      0.00      0.00        63\n",
      "         722       0.00      0.00      0.00        49\n",
      "         723       0.00      0.00      0.00       118\n",
      "         724       0.02      0.00      0.00      1509\n",
      "         725       0.16      0.01      0.02      1648\n",
      "         726       0.03      0.00      0.00       446\n",
      "         727       0.00      0.00      0.00       292\n",
      "         728       0.09      0.01      0.01      1261\n",
      "         729       0.14      0.00      0.01       784\n",
      "         730       0.00      0.00      0.00        92\n",
      "         731       0.00      0.00      0.00        34\n",
      "         732       0.00      0.00      0.00       145\n",
      "         733       0.05      0.00      0.01       243\n",
      "         734       0.08      0.00      0.01       269\n",
      "         735       0.10      0.03      0.05        32\n",
      "         736       0.00      0.00      0.00        21\n",
      "         737       0.04      0.00      0.00      1118\n",
      "         738       0.00      0.00      0.00       330\n",
      "         739       0.04      0.00      0.00       507\n",
      "         740       0.00      0.00      0.00        68\n",
      "         741       0.00      0.00      0.00        11\n",
      "         742       0.07      0.01      0.01       192\n",
      "         743       0.00      0.00      0.00       102\n",
      "         744       0.00      0.00      0.00       280\n",
      "         745       0.00      0.00      0.00        44\n",
      "         746       0.04      0.00      0.01       247\n",
      "         747       0.00      0.00      0.00        66\n",
      "         748       0.00      0.00      0.00        31\n",
      "         749       0.00      0.00      0.00       342\n",
      "         750       0.00      0.00      0.00        63\n",
      "         751       0.12      0.01      0.02       296\n",
      "         752       0.00      0.00      0.00        87\n",
      "         753       0.00      0.00      0.00       155\n",
      "         754       0.00      0.00      0.00       258\n",
      "         755       0.00      0.00      0.00        49\n",
      "         756       0.00      0.00      0.00        70\n",
      "         757       0.00      0.00      0.00       151\n",
      "         758       0.00      0.00      0.00       117\n",
      "         759       0.00      0.00      0.00        28\n",
      "         760       0.00      0.00      0.00       101\n",
      "         761       0.00      0.00      0.00       207\n",
      "         762       0.00      0.00      0.00        15\n",
      "         763       0.00      0.00      0.00        32\n",
      "         764       0.00      0.00      0.00       628\n",
      "         765       0.00      0.00      0.00        33\n",
      "         766       0.00      0.00      0.00        50\n",
      "         767       0.00      0.00      0.00       172\n",
      "         768       0.00      0.00      0.00        85\n",
      "         769       0.00      0.00      0.00        24\n",
      "         770       0.00      0.00      0.00       585\n",
      "         771       0.05      0.01      0.01       199\n",
      "         772       0.00      0.00      0.00         0\n",
      "         773       0.00      0.00      0.00        41\n",
      "         774       0.00      0.00      0.00        31\n",
      "         775       0.00      0.00      0.00         0\n",
      "         776       0.00      0.00      0.00        10\n",
      "         777       0.00      0.00      0.00        11\n",
      "         778       0.00      0.00      0.00       179\n",
      "         779       0.00      0.00      0.00        81\n",
      "         780       0.00      0.00      0.00        10\n",
      "         781       0.00      0.00      0.00         0\n",
      "         782       0.00      0.00      0.00        70\n",
      "         783       0.03      0.00      0.00      1039\n",
      "         784       0.00      0.00      0.00        14\n",
      "         785       0.00      0.00      0.00         0\n",
      "         786       0.00      0.00      0.00       229\n",
      "         787       0.00      0.00      0.00        68\n",
      "         788       0.04      0.00      0.00       663\n",
      "         789       0.00      0.00      0.00       179\n",
      "         790       0.00      0.00      0.00        10\n",
      "         791       0.00      0.00      0.00         6\n",
      "         792       0.00      0.00      0.00       179\n",
      "         793       0.00      0.00      0.00        18\n",
      "         794       0.00      0.00      0.00        28\n",
      "         795       0.13      0.00      0.01      1565\n",
      "         796       0.00      0.00      0.00        53\n",
      "         797       0.00      0.00      0.00       232\n",
      "         798       0.03      0.00      0.00       969\n",
      "         799       0.03      0.00      0.01       349\n",
      "         800       0.00      0.00      0.00       118\n",
      "         801       0.00      0.00      0.00        28\n",
      "         802       0.00      0.00      0.00        12\n",
      "         803       0.00      0.00      0.00       179\n",
      "         804       0.00      0.00      0.00       179\n",
      "         805       0.00      0.00      0.00       179\n",
      "         806       0.18      0.02      0.04        94\n",
      "         807       0.17      0.04      0.06        28\n",
      "         808       0.00      0.00      0.00         7\n",
      "         809       0.00      0.00      0.00       112\n",
      "         810       0.08      0.01      0.01       256\n",
      "         811       0.00      0.00      0.00        28\n",
      "         812       0.00      0.00      0.00        25\n",
      "         813       0.04      0.00      0.01       320\n",
      "         814       0.04      0.00      0.01       339\n",
      "         815       0.15      0.00      0.01      1191\n",
      "         816       0.00      0.00      0.00        60\n",
      "         817       0.00      0.00      0.00         7\n",
      "         818       0.00      0.00      0.00        21\n",
      "         819       0.00      0.00      0.00       925\n",
      "         820       0.20      0.01      0.01       775\n",
      "         821       0.11      0.01      0.01       355\n",
      "         822       0.00      0.00      0.00        68\n",
      "         823       0.14      0.01      0.01       840\n",
      "         824       0.00      0.00      0.00       112\n",
      "         825       0.00      0.00      0.00        60\n",
      "         826       0.00      0.00      0.00         0\n",
      "         827       0.07      0.01      0.01       272\n",
      "         828       0.00      0.00      0.00        68\n",
      "         829       0.00      0.00      0.00        28\n",
      "         830       0.00      0.00      0.00       118\n",
      "         831       0.00      0.00      0.00       144\n",
      "         832       0.00      0.00      0.00         0\n",
      "         833       0.00      0.00      0.00        28\n",
      "         834       0.08      0.01      0.02       118\n",
      "         835       0.00      0.00      0.00         5\n",
      "         836       0.00      0.00      0.00        68\n",
      "         837       0.00      0.00      0.00        28\n",
      "         838       0.00      0.00      0.00       116\n",
      "         839       0.00      0.00      0.00        33\n",
      "         840       0.00      0.00      0.00        26\n",
      "         841       0.00      0.00      0.00        48\n",
      "         842       0.19      0.00      0.01      1339\n",
      "         843       0.11      0.00      0.01      1016\n",
      "         844       0.00      0.00      0.00       172\n",
      "         845       0.10      0.00      0.00      1833\n",
      "         846       0.00      0.00      0.00       577\n",
      "         847       0.00      0.00      0.00        33\n",
      "         848       0.19      0.01      0.01       826\n",
      "         849       0.12      0.01      0.01       375\n",
      "         850       0.12      0.00      0.01      1947\n",
      "         851       0.00      0.00      0.00       128\n",
      "         852       0.00      0.00      0.00       373\n",
      "         853       0.00      0.00      0.00        15\n",
      "         854       0.00      0.00      0.00       416\n",
      "         855       0.00      0.00      0.00       180\n",
      "         856       0.00      0.00      0.00        57\n",
      "         857       0.00      0.00      0.00       179\n",
      "         858       0.00      0.00      0.00        36\n",
      "         859       0.08      0.00      0.01       475\n",
      "         860       0.00      0.00      0.00       112\n",
      "         861       0.00      0.00      0.00         8\n",
      "         862       0.00      0.00      0.00        26\n",
      "         863       0.04      0.00      0.01       243\n",
      "         864       0.04      0.00      0.01       243\n",
      "         865       0.10      0.01      0.02       199\n",
      "         866       0.00      0.00      0.00        34\n",
      "         867       0.00      0.00      0.00       672\n",
      "         868       0.00      0.00      0.00        86\n",
      "         869       0.00      0.00      0.00        91\n",
      "         870       0.00      0.00      0.00       116\n",
      "         871       0.00      0.00      0.00        22\n",
      "         872       0.00      0.00      0.00       139\n",
      "         873       0.00      0.00      0.00        33\n",
      "         874       0.00      0.00      0.00       179\n",
      "         875       0.00      0.00      0.00        33\n",
      "         876       0.00      0.00      0.00       220\n",
      "         877       0.00      0.00      0.00        36\n",
      "         878       0.09      0.01      0.01       528\n",
      "         879       0.00      0.00      0.00       225\n",
      "         880       0.03      0.00      0.01       336\n",
      "         881       0.17      0.00      0.01      2226\n",
      "         882       0.04      0.00      0.00       550\n",
      "         883       0.04      0.00      0.00       378\n",
      "         884       0.00      0.00      0.00        88\n",
      "         885       0.03      0.00      0.00       399\n",
      "         886       0.00      0.00      0.00       281\n",
      "         887       0.09      0.00      0.01       831\n",
      "         888       0.00      0.00      0.00        60\n",
      "         889       0.04      0.00      0.00       619\n",
      "         890       0.04      0.00      0.00       519\n",
      "         891       0.00      0.00      0.00       132\n",
      "         892       0.05      0.01      0.01       176\n",
      "         893       0.03      0.00      0.01       257\n",
      "         894       0.03      0.00      0.00       399\n",
      "         895       0.00      0.00      0.00        37\n",
      "         896       0.00      0.00      0.00         7\n",
      "         897       0.00      0.00      0.00         4\n",
      "         898       0.00      0.00      0.00         1\n",
      "         899       0.00      0.00      0.00        95\n",
      "         900       0.05      0.01      0.01       176\n",
      "         901       0.08      0.01      0.02        81\n",
      "         902       0.05      0.01      0.01       176\n",
      "         903       0.00      0.00      0.00        94\n",
      "         904       0.05      0.01      0.01       176\n",
      "         905       0.00      0.00      0.00         7\n",
      "         906       0.00      0.00      0.00        51\n",
      "         907       0.00      0.00      0.00         7\n",
      "         908       0.00      0.00      0.00       101\n",
      "         909       0.00      0.00      0.00        32\n",
      "         910       0.00      0.00      0.00        39\n",
      "         911       0.00      0.00      0.00       160\n",
      "         912       0.00      0.00      0.00        74\n",
      "         913       0.00      0.00      0.00        50\n",
      "         914       0.00      0.00      0.00        55\n",
      "         915       0.00      0.00      0.00        39\n",
      "         916       0.03      0.00      0.00       399\n",
      "         917       0.00      0.00      0.00       200\n",
      "         918       0.00      0.00      0.00        30\n",
      "         919       0.00      0.00      0.00        36\n",
      "         920       0.00      0.00      0.00       112\n",
      "         921       0.00      0.00      0.00        68\n",
      "         922       0.00      0.00      0.00       164\n",
      "         923       0.04      0.00      0.00       442\n",
      "         924       0.00      0.00      0.00        27\n",
      "         925       0.00      0.00      0.00       194\n",
      "         926       0.11      0.01      0.01       496\n",
      "         927       0.00      0.00      0.00       172\n",
      "         928       0.00      0.00      0.00         8\n",
      "         929       0.05      0.00      0.00       534\n",
      "         930       0.00      0.00      0.00        60\n",
      "         931       0.00      0.00      0.00        30\n",
      "         932       0.00      0.00      0.00        60\n",
      "         933       0.00      0.00      0.00       373\n",
      "         934       0.00      0.00      0.00        60\n",
      "         935       0.00      0.00      0.00        68\n",
      "         936       0.00      0.00      0.00        53\n",
      "         937       0.07      0.01      0.01       272\n",
      "         938       0.05      0.00      0.00       645\n",
      "         939       0.00      0.00      0.00        51\n",
      "         940       0.00      0.00      0.00        68\n",
      "         941       0.00      0.00      0.00        48\n",
      "         942       0.00      0.00      0.00        28\n",
      "         943       0.12      0.01      0.01      1585\n",
      "         944       0.03      0.00      0.00       668\n",
      "         945       0.00      0.00      0.00        17\n",
      "         946       0.00      0.00      0.00       620\n",
      "         947       0.05      0.00      0.00       388\n",
      "         948       0.04      0.00      0.01       292\n",
      "         949       0.03      0.00      0.00       505\n",
      "         950       0.00      0.00      0.00       426\n",
      "         951       0.08      0.01      0.02       118\n",
      "         952       0.00      0.00      0.00        60\n",
      "         953       0.00      0.00      0.00        67\n",
      "         954       0.00      0.00      0.00        68\n",
      "         955       0.02      0.00      0.00      1040\n",
      "         956       0.00      0.00      0.00       634\n",
      "         957       0.12      0.00      0.01      1384\n",
      "         958       0.00      0.00      0.00        47\n",
      "         959       0.00      0.00      0.00       231\n",
      "         960       0.00      0.00      0.00        48\n",
      "         961       0.00      0.00      0.00        33\n",
      "         962       0.07      0.01      0.01       545\n",
      "         963       0.00      0.00      0.00        67\n",
      "         964       0.07      0.00      0.01       884\n",
      "         965       0.00      0.00      0.00       179\n",
      "         966       0.00      0.00      0.00       172\n",
      "         967       0.05      0.00      0.00      1205\n",
      "         968       0.00      0.00      0.00        48\n",
      "         969       0.00      0.00      0.00       232\n",
      "         970       0.00      0.00      0.00       172\n",
      "         971       0.00      0.00      0.00        76\n",
      "         972       0.00      0.00      0.00       153\n",
      "         973       0.00      0.00      0.00       172\n",
      "         974       0.00      0.00      0.00        27\n",
      "         975       0.00      0.00      0.00       107\n",
      "         976       0.00      0.00      0.00        77\n",
      "         977       0.04      0.00      0.01       262\n",
      "         978       0.00      0.00      0.00        53\n",
      "         979       0.00      0.00      0.00       172\n",
      "         980       0.00      0.00      0.00        30\n",
      "         981       0.00      0.00      0.00       225\n",
      "         982       0.00      0.00      0.00        68\n",
      "         983       0.04      0.00      0.01       320\n",
      "         984       0.00      0.00      0.00        90\n",
      "         985       0.04      0.00      0.01       262\n",
      "         986       0.00      0.00      0.00        65\n",
      "         987       0.00      0.00      0.00       373\n",
      "         988       0.03      0.00      0.00       399\n",
      "         989       0.00      0.00      0.00        48\n",
      "         990       0.00      0.00      0.00        36\n",
      "         991       0.00      0.00      0.00        88\n",
      "         992       0.00      0.00      0.00       116\n",
      "         993       0.00      0.00      0.00        49\n",
      "         994       0.00      0.00      0.00        49\n",
      "         995       0.00      0.00      0.00        49\n",
      "         996       0.00      0.00      0.00        49\n",
      "         997       0.00      0.00      0.00        32\n",
      "         998       0.00      0.00      0.00       373\n",
      "         999       0.00      0.00      0.00       205\n",
      "        1000       0.00      0.00      0.00       373\n",
      "        1001       0.00      0.00      0.00       438\n",
      "        1002       0.00      0.00      0.00       127\n",
      "        1003       0.06      0.00      0.01       454\n",
      "        1004       0.06      0.00      0.00       514\n",
      "        1005       0.00      0.00      0.00        58\n",
      "        1006       0.00      0.00      0.00       489\n",
      "        1007       0.00      0.00      0.00       552\n",
      "        1008       0.00      0.00      0.00       167\n",
      "        1009       0.00      0.00      0.00         0\n",
      "        1010       0.00      0.00      0.00       389\n",
      "        1011       0.03      0.00      0.00       806\n",
      "        1012       0.07      0.00      0.01       749\n",
      "        1013       0.08      0.00      0.01       527\n",
      "        1014       0.00      0.00      0.00       127\n",
      "        1015       0.00      0.00      0.00        48\n",
      "        1016       0.00      0.00      0.00       127\n",
      "        1017       0.00      0.00      0.00        39\n",
      "        1018       0.00      0.00      0.00       127\n",
      "        1019       0.00      0.00      0.00        27\n",
      "        1020       0.00      0.00      0.00       163\n",
      "        1021       0.00      0.00      0.00        16\n",
      "        1022       0.00      0.00      0.00        53\n",
      "        1023       0.00      0.00      0.00        13\n",
      "        1024       0.00      0.00      0.00       205\n",
      "        1025       0.00      0.00      0.00        67\n",
      "        1026       0.05      0.01      0.01       176\n",
      "        1027       0.00      0.00      0.00        76\n",
      "        1028       0.00      0.00      0.00        13\n",
      "        1029       0.00      0.00      0.00        28\n",
      "        1030       0.00      0.00      0.00        68\n",
      "        1031       0.00      0.00      0.00        68\n",
      "        1032       0.00      0.00      0.00        74\n",
      "        1033       0.00      0.00      0.00        34\n",
      "        1034       0.00      0.00      0.00        53\n",
      "        1035       0.00      0.00      0.00       116\n",
      "        1036       0.00      0.00      0.00         8\n",
      "        1037       0.00      0.00      0.00        32\n",
      "        1038       0.00      0.00      0.00        32\n",
      "        1039       0.00      0.00      0.00        32\n",
      "        1040       0.00      0.00      0.00        13\n",
      "        1041       0.00      0.00      0.00        77\n",
      "        1042       0.00      0.00      0.00        91\n",
      "        1043       0.00      0.00      0.00        32\n",
      "        1044       0.00      0.00      0.00       171\n",
      "        1045       0.00      0.00      0.00        48\n",
      "        1046       0.00      0.00      0.00       908\n",
      "        1047       0.00      0.00      0.00        53\n",
      "        1048       0.00      0.00      0.00         3\n",
      "        1049       0.04      0.00      0.01       262\n",
      "        1050       0.00      0.00      0.00        53\n",
      "        1051       0.00      0.00      0.00        53\n",
      "        1052       0.00      0.00      0.00         0\n",
      "        1053       0.00      0.00      0.00        48\n",
      "        1054       0.00      0.00      0.00         6\n",
      "        1055       0.00      0.00      0.00        11\n",
      "        1056       0.00      0.00      0.00        33\n",
      "        1057       0.00      0.00      0.00        49\n",
      "        1058       0.00      0.00      0.00        16\n",
      "        1059       0.00      0.00      0.00        71\n",
      "        1060       0.00      0.00      0.00        14\n",
      "        1061       0.00      0.00      0.00        67\n",
      "        1062       0.00      0.00      0.00        65\n",
      "        1063       0.00      0.00      0.00        32\n",
      "        1064       0.00      0.00      0.00         0\n",
      "        1065       0.00      0.00      0.00         0\n",
      "        1066       0.00      0.00      0.00         0\n",
      "        1067       0.00      0.00      0.00         0\n",
      "        1068       0.00      0.00      0.00        14\n",
      "        1069       0.04      0.00      0.01       350\n",
      "        1070       0.00      0.00      0.00        45\n",
      "        1071       0.00      0.00      0.00        55\n",
      "        1072       0.00      0.00      0.00        16\n",
      "        1073       0.00      0.00      0.00         7\n",
      "        1074       0.00      0.00      0.00        68\n",
      "        1075       0.00      0.00      0.00        77\n",
      "        1076       0.00      0.00      0.00        62\n",
      "        1077       0.00      0.00      0.00       151\n",
      "        1078       0.04      0.00      0.00       419\n",
      "        1079       0.00      0.00      0.00        16\n",
      "        1080       0.00      0.00      0.00        68\n",
      "        1081       0.00      0.00      0.00        77\n",
      "        1082       0.00      0.00      0.00       125\n",
      "        1083       0.00      0.00      0.00        67\n",
      "        1084       0.00      0.00      0.00        47\n",
      "        1085       0.04      0.00      0.01       262\n",
      "        1086       0.06      0.00      0.01       279\n",
      "        1087       0.17      0.01      0.01      1068\n",
      "        1088       0.12      0.00      0.00      2962\n",
      "        1089       0.11      0.00      0.01      1204\n",
      "        1090       0.04      0.00      0.00       539\n",
      "        1091       0.04      0.00      0.01       268\n",
      "        1092       0.04      0.00      0.00       618\n",
      "        1093       0.00      0.00      0.00       112\n",
      "        1094       0.00      0.00      0.00        27\n",
      "        1095       0.00      0.00      0.00        50\n",
      "        1096       0.10      0.00      0.01      1168\n",
      "        1097       0.03      0.00      0.01       250\n",
      "        1098       0.00      0.00      0.00        74\n",
      "        1099       0.04      0.00      0.01       262\n",
      "        1100       0.03      0.00      0.01       250\n",
      "        1101       0.00      0.00      0.00       125\n",
      "        1102       0.07      0.01      0.01       130\n",
      "        1103       0.00      0.00      0.00       165\n",
      "        1104       0.07      0.01      0.01       272\n",
      "        1105       0.05      0.00      0.01       341\n",
      "        1106       0.00      0.00      0.00       120\n",
      "        1107       0.07      0.00      0.01       657\n",
      "        1108       0.00      0.00      0.00         9\n",
      "        1109       0.00      0.00      0.00        12\n",
      "        1110       0.00      0.00      0.00         6\n",
      "        1111       0.00      0.00      0.00        33\n",
      "        1112       0.00      0.00      0.00       191\n",
      "        1113       0.00      0.00      0.00       116\n",
      "        1114       0.00      0.00      0.00        48\n",
      "        1115       0.05      0.01      0.01       190\n",
      "        1116       0.00      0.00      0.00       179\n",
      "        1117       0.00      0.00      0.00        48\n",
      "        1118       0.00      0.00      0.00        36\n",
      "        1119       0.00      0.00      0.00       116\n",
      "        1120       0.00      0.00      0.00       245\n",
      "        1121       0.00      0.00      0.00       389\n",
      "        1122       0.00      0.00      0.00       591\n",
      "        1123       0.00      0.00      0.00         0\n",
      "        1124       0.08      0.01      0.02       119\n",
      "        1125       0.00      0.00      0.00        27\n",
      "        1126       0.00      0.00      0.00        28\n",
      "        1127       0.00      0.00      0.00         7\n",
      "        1128       0.00      0.00      0.00       118\n",
      "        1129       0.03      0.00      0.01       339\n",
      "        1130       0.00      0.00      0.00       282\n",
      "        1131       0.10      0.01      0.02       333\n",
      "        1132       0.00      0.00      0.00       589\n",
      "        1133       0.00      0.00      0.00        74\n",
      "        1134       0.00      0.00      0.00       112\n",
      "        1135       0.00      0.00      0.00       280\n",
      "        1136       0.20      0.03      0.05        32\n",
      "        1137       0.00      0.00      0.00        10\n",
      "        1138       0.00      0.00      0.00        60\n",
      "        1139       0.00      0.00      0.00        77\n",
      "        1140       0.00      0.00      0.00       179\n",
      "        1141       0.12      0.01      0.01       592\n",
      "        1142       0.00      0.00      0.00        76\n",
      "        1143       0.04      0.00      0.00       394\n",
      "        1144       0.00      0.00      0.00         0\n",
      "        1145       0.00      0.00      0.00       118\n",
      "        1146       0.00      0.00      0.00       107\n",
      "        1147       0.00      0.00      0.00        32\n",
      "        1148       0.00      0.00      0.00        33\n",
      "        1149       0.06      0.00      0.01       703\n",
      "        1150       0.03      0.00      0.00       623\n",
      "        1151       0.04      0.00      0.01       256\n",
      "        1152       0.00      0.00      0.00        64\n",
      "        1153       0.00      0.00      0.00        12\n",
      "        1154       0.00      0.00      0.00       373\n",
      "        1155       0.04      0.00      0.01       320\n",
      "        1156       0.00      0.00      0.00        12\n",
      "        1157       0.00      0.00      0.00       614\n",
      "        1158       0.03      0.00      0.00       425\n",
      "        1159       0.03      0.00      0.00       971\n",
      "        1160       0.03      0.00      0.00       399\n",
      "        1161       0.09      0.00      0.01       611\n",
      "        1162       0.00      0.00      0.00       159\n",
      "        1163       0.00      0.00      0.00        33\n",
      "        1164       0.04      0.00      0.01       219\n",
      "        1165       0.00      0.00      0.00        80\n",
      "        1166       0.00      0.00      0.00       112\n",
      "        1167       0.00      0.00      0.00        28\n",
      "        1168       0.00      0.00      0.00        31\n",
      "        1169       0.00      0.00      0.00        23\n",
      "        1170       0.00      0.00      0.00        23\n",
      "        1171       0.00      0.00      0.00       112\n",
      "        1172       0.00      0.00      0.00       112\n",
      "        1173       0.00      0.00      0.00        81\n",
      "        1174       0.00      0.00      0.00         0\n",
      "        1175       0.00      0.00      0.00        81\n",
      "        1176       0.00      0.00      0.00        31\n",
      "        1177       0.00      0.00      0.00        31\n",
      "        1178       0.00      0.00      0.00        81\n",
      "        1179       0.00      0.00      0.00        95\n",
      "        1180       0.00      0.00      0.00         9\n",
      "        1181       0.00      0.00      0.00        95\n",
      "        1182       0.00      0.00      0.00         9\n",
      "        1183       0.00      0.00      0.00        32\n",
      "        1184       0.00      0.00      0.00        33\n",
      "        1185       0.00      0.00      0.00        81\n",
      "        1186       0.00      0.00      0.00        23\n",
      "        1187       0.00      0.00      0.00        81\n",
      "        1188       0.00      0.00      0.00        81\n",
      "        1189       0.00      0.00      0.00        23\n",
      "        1190       0.00      0.00      0.00        77\n",
      "        1191       0.00      0.00      0.00        31\n",
      "        1192       0.00      0.00      0.00        31\n",
      "        1193       0.00      0.00      0.00        68\n",
      "        1194       0.00      0.00      0.00         0\n",
      "        1195       0.00      0.00      0.00        17\n",
      "        1196       0.00      0.00      0.00         0\n",
      "        1197       0.00      0.00      0.00        31\n",
      "        1198       0.00      0.00      0.00       112\n",
      "        1199       0.00      0.00      0.00         5\n",
      "        1200       0.00      0.00      0.00        36\n",
      "        1201       0.00      0.00      0.00       179\n",
      "        1202       0.11      0.01      0.02        95\n",
      "        1203       0.00      0.00      0.00        47\n",
      "        1204       0.04      0.00      0.01       320\n",
      "        1205       0.00      0.00      0.00        74\n",
      "        1206       0.00      0.00      0.00         0\n",
      "        1207       0.00      0.00      0.00        53\n",
      "        1208       0.00      0.00      0.00       170\n",
      "        1209       0.00      0.00      0.00       179\n",
      "        1210       0.00      0.00      0.00        22\n",
      "        1211       0.06      0.01      0.01       360\n",
      "        1212       0.00      0.00      0.00       246\n",
      "        1213       0.00      0.00      0.00        18\n",
      "        1214       0.00      0.00      0.00        24\n",
      "        1215       0.00      0.00      0.00        30\n",
      "        1216       0.00      0.00      0.00        76\n",
      "        1217       0.06      0.00      0.01       232\n",
      "        1218       0.00      0.00      0.00       373\n",
      "        1219       0.00      0.00      0.00       116\n",
      "        1220       0.10      0.01      0.01       489\n",
      "        1221       0.00      0.00      0.00       378\n",
      "        1222       0.00      0.00      0.00       445\n",
      "        1223       0.00      0.00      0.00        74\n",
      "        1224       0.00      0.00      0.00         0\n",
      "        1225       0.00      0.00      0.00        77\n",
      "        1226       0.00      0.00      0.00        34\n",
      "        1227       0.00      0.00      0.00        13\n",
      "        1228       0.04      0.00      0.01       262\n",
      "        1229       0.00      0.00      0.00        53\n",
      "        1230       0.00      0.00      0.00        36\n",
      "        1231       0.06      0.01      0.01       135\n",
      "        1232       0.00      0.00      0.00        45\n",
      "        1233       0.00      0.00      0.00        91\n",
      "        1234       0.00      0.00      0.00       260\n",
      "        1235       0.00      0.00      0.00        33\n",
      "        1236       0.00      0.00      0.00        72\n",
      "        1237       0.00      0.00      0.00        63\n",
      "        1238       0.00      0.00      0.00        53\n",
      "        1239       0.04      0.00      0.01       210\n",
      "        1240       0.00      0.00      0.00        12\n",
      "        1241       0.04      0.01      0.01       192\n",
      "        1242       0.00      0.00      0.00       153\n",
      "        1243       0.00      0.00      0.00       131\n",
      "        1244       0.00      0.00      0.00         1\n",
      "        1245       0.00      0.00      0.00        38\n",
      "        1246       0.00      0.00      0.00        20\n",
      "        1247       0.00      0.00      0.00       136\n",
      "        1248       0.00      0.00      0.00        78\n",
      "        1249       0.00      0.00      0.00        25\n",
      "        1250       0.00      0.00      0.00       117\n",
      "        1251       0.10      0.01      0.02       161\n",
      "        1252       0.00      0.00      0.00       134\n",
      "        1253       0.00      0.00      0.00       103\n",
      "        1254       0.00      0.00      0.00        11\n",
      "        1255       0.00      0.00      0.00       175\n",
      "        1256       0.00      0.00      0.00        92\n",
      "        1257       0.00      0.00      0.00         5\n",
      "        1258       0.00      0.00      0.00        35\n",
      "        1259       0.00      0.00      0.00        54\n",
      "        1260       0.00      0.00      0.00        38\n",
      "        1261       0.04      0.00      0.01       284\n",
      "        1262       0.08      0.01      0.01       176\n",
      "        1263       0.00      0.00      0.00        46\n",
      "        1264       0.00      0.00      0.00       303\n",
      "        1265       0.00      0.00      0.00        19\n",
      "        1266       0.00      0.00      0.00        13\n",
      "        1267       0.00      0.00      0.00       307\n",
      "        1268       0.14      0.00      0.01      1662\n",
      "        1269       0.00      0.00      0.00        24\n",
      "        1270       0.00      0.00      0.00        26\n",
      "        1271       0.00      0.00      0.00        50\n",
      "        1272       0.00      0.00      0.00        77\n",
      "        1273       0.00      0.00      0.00        77\n",
      "        1274       0.00      0.00      0.00        24\n",
      "        1275       0.00      0.00      0.00         0\n",
      "        1276       0.00      0.00      0.00        97\n",
      "        1277       0.00      0.00      0.00        30\n",
      "        1278       0.00      0.00      0.00        81\n",
      "        1279       0.00      0.00      0.00         0\n",
      "        1280       0.00      0.00      0.00        26\n",
      "        1281       0.00      0.00      0.00        77\n",
      "        1282       0.00      0.00      0.00        77\n",
      "        1283       0.00      0.00      0.00       179\n",
      "        1284       0.00      0.00      0.00        32\n",
      "        1285       0.00      0.00      0.00       111\n",
      "        1286       0.00      0.00      0.00        38\n",
      "        1287       0.00      0.00      0.00        52\n",
      "        1288       0.00      0.00      0.00       136\n",
      "        1289       0.00      0.00      0.00        11\n",
      "        1290       0.00      0.00      0.00        11\n",
      "        1291       0.00      0.00      0.00        19\n",
      "        1292       0.00      0.00      0.00        25\n",
      "        1293       0.00      0.00      0.00        77\n",
      "        1294       0.00      0.00      0.00        43\n",
      "        1295       0.00      0.00      0.00       344\n",
      "        1296       0.00      0.00      0.00        22\n",
      "        1297       0.00      0.00      0.00         2\n",
      "        1298       0.00      0.00      0.00         0\n",
      "        1299       0.12      0.00      0.01       527\n",
      "        1300       0.00      0.00      0.00        42\n",
      "        1301       0.00      0.00      0.00        59\n",
      "        1302       0.00      0.00      0.00       151\n",
      "        1303       0.00      0.00      0.00        89\n",
      "        1304       0.00      0.00      0.00        28\n",
      "        1305       0.00      0.00      0.00       553\n",
      "        1306       0.07      0.00      0.01       425\n",
      "        1307       0.00      0.00      0.00        14\n",
      "        1308       0.00      0.00      0.00        39\n",
      "        1309       0.00      0.00      0.00        62\n",
      "        1310       0.00      0.00      0.00        46\n",
      "        1311       0.00      0.00      0.00        62\n",
      "        1312       0.10      0.00      0.01      1155\n",
      "        1313       0.00      0.00      0.00        72\n",
      "        1314       0.00      0.00      0.00       471\n",
      "        1315       0.10      0.00      0.01       669\n",
      "        1316       0.00      0.00      0.00        13\n",
      "        1317       0.00      0.00      0.00         1\n",
      "        1318       0.00      0.00      0.00        17\n",
      "        1319       0.00      0.00      0.00       258\n",
      "        1320       0.00      0.00      0.00        21\n",
      "        1321       0.00      0.00      0.00        66\n",
      "        1322       0.07      0.01      0.01       192\n",
      "        1323       0.00      0.00      0.00       373\n",
      "        1324       0.08      0.00      0.00       940\n",
      "        1325       0.00      0.00      0.00       155\n",
      "        1326       0.00      0.00      0.00        29\n",
      "        1327       0.00      0.00      0.00        10\n",
      "        1328       0.00      0.00      0.00        39\n",
      "        1329       0.00      0.00      0.00        85\n",
      "        1330       0.00      0.00      0.00       214\n",
      "        1331       0.07      0.01      0.01       192\n",
      "        1332       0.00      0.00      0.00        36\n",
      "        1333       0.00      0.00      0.00         7\n",
      "        1334       0.00      0.00      0.00        36\n",
      "        1335       0.00      0.00      0.00       118\n",
      "        1336       0.00      0.00      0.00        66\n",
      "        1337       0.00      0.00      0.00         0\n",
      "        1338       0.00      0.00      0.00        11\n",
      "        1339       0.00      0.00      0.00        26\n",
      "        1340       0.00      0.00      0.00       329\n",
      "        1341       0.00      0.00      0.00        66\n",
      "        1342       0.00      0.00      0.00        17\n",
      "        1343       0.00      0.00      0.00        31\n",
      "        1344       0.00      0.00      0.00        37\n",
      "        1345       0.00      0.00      0.00        68\n",
      "        1346       0.00      0.00      0.00         0\n",
      "        1347       0.00      0.00      0.00       121\n",
      "        1348       0.00      0.00      0.00        36\n",
      "        1349       0.00      0.00      0.00        77\n",
      "        1350       0.00      0.00      0.00        23\n",
      "        1351       0.00      0.00      0.00        13\n",
      "        1352       0.00      0.00      0.00         0\n",
      "        1353       0.00      0.00      0.00       151\n",
      "        1354       0.00      0.00      0.00       184\n",
      "        1355       0.00      0.00      0.00        60\n",
      "        1356       0.00      0.00      0.00        97\n",
      "        1357       0.00      0.00      0.00       174\n",
      "        1358       0.03      0.00      0.00      1328\n",
      "        1359       0.00      0.00      0.00       124\n",
      "        1360       0.00      0.00      0.00        31\n",
      "        1361       0.00      0.00      0.00        17\n",
      "        1362       0.00      0.00      0.00         0\n",
      "        1363       0.00      0.00      0.00         5\n",
      "        1364       0.16      0.01      0.02      1796\n",
      "        1365       0.00      0.00      0.00        30\n",
      "        1366       0.04      0.00      0.01       300\n",
      "        1367       0.05      0.00      0.01       630\n",
      "        1368       0.00      0.00      0.00        11\n",
      "        1369       0.00      0.00      0.00        32\n",
      "        1370       0.00      0.00      0.00        33\n",
      "        1371       0.07      0.01      0.01       238\n",
      "        1372       0.10      0.01      0.01       399\n",
      "        1373       0.00      0.00      0.00       174\n",
      "        1374       0.00      0.00      0.00       116\n",
      "        1375       0.00      0.00      0.00       116\n",
      "        1376       0.00      0.00      0.00       179\n",
      "        1377       0.04      0.00      0.01       320\n",
      "        1378       0.00      0.00      0.00        14\n",
      "        1379       0.04      0.00      0.01       221\n",
      "        1380       0.00      0.00      0.00        47\n",
      "        1381       0.04      0.00      0.01       262\n",
      "        1382       0.14      0.05      0.08        19\n",
      "        1383       0.03      0.00      0.00       439\n",
      "        1384       0.00      0.00      0.00       116\n",
      "        1385       0.00      0.00      0.00        47\n",
      "        1386       0.04      0.00      0.00       407\n",
      "        1387       0.10      0.00      0.01      1290\n",
      "        1388       0.00      0.00      0.00       188\n",
      "        1389       0.00      0.00      0.00       182\n",
      "        1390       0.16      0.00      0.01      1720\n",
      "        1391       0.03      0.00      0.00       415\n",
      "        1392       0.00      0.00      0.00        33\n",
      "        1393       0.00      0.00      0.00        90\n",
      "        1394       0.05      0.00      0.01       348\n",
      "        1395       0.04      0.00      0.01       320\n",
      "        1396       0.00      0.00      0.00       143\n",
      "        1397       0.00      0.00      0.00       218\n",
      "        1398       0.00      0.00      0.00       130\n",
      "        1399       0.00      0.00      0.00       109\n",
      "        1400       0.00      0.00      0.00        53\n",
      "        1401       0.00      0.00      0.00       125\n",
      "        1402       0.00      0.00      0.00        77\n",
      "        1403       0.00      0.00      0.00        68\n",
      "        1404       0.06      0.01      0.01       319\n",
      "        1405       0.00      0.00      0.00       213\n",
      "        1406       0.00      0.00      0.00       507\n",
      "        1407       0.00      0.00      0.00        12\n",
      "        1408       0.03      0.00      0.00       837\n",
      "        1409       0.11      0.00      0.01      1506\n",
      "        1410       0.02      0.00      0.00       717\n",
      "        1411       0.04      0.00      0.01       320\n",
      "        1412       0.11      0.00      0.01      2049\n",
      "        1413       0.04      0.00      0.01       320\n",
      "        1414       0.00      0.00      0.00       234\n",
      "        1415       0.00      0.00      0.00        26\n",
      "        1416       0.00      0.00      0.00        12\n",
      "        1417       0.00      0.00      0.00        36\n",
      "        1418       0.00      0.00      0.00        30\n",
      "        1419       0.00      0.00      0.00        30\n",
      "        1420       0.04      0.00      0.01       320\n",
      "        1421       0.00      0.00      0.00       164\n",
      "        1422       0.12      0.00      0.01      1419\n",
      "        1423       0.00      0.00      0.00         5\n",
      "        1424       0.00      0.00      0.00       327\n",
      "        1425       0.00      0.00      0.00       229\n",
      "        1426       0.00      0.00      0.00         5\n",
      "        1427       0.00      0.00      0.00         9\n",
      "        1428       0.00      0.00      0.00        81\n",
      "        1429       0.00      0.00      0.00        14\n",
      "        1430       0.00      0.00      0.00         8\n",
      "        1431       0.00      0.00      0.00        50\n",
      "        1432       0.03      0.00      0.00       530\n",
      "        1433       0.08      0.01      0.01       274\n",
      "        1434       0.00      0.00      0.00        68\n",
      "        1435       0.00      0.00      0.00        14\n",
      "        1436       0.00      0.00      0.00        61\n",
      "        1437       0.00      0.00      0.00        12\n",
      "        1438       0.00      0.00      0.00       132\n",
      "        1439       0.00      0.00      0.00         8\n",
      "        1440       0.00      0.00      0.00        21\n",
      "        1441       0.28      0.01      0.01      2280\n",
      "        1442       0.00      0.00      0.00       128\n",
      "        1443       0.00      0.00      0.00        13\n",
      "        1444       0.12      0.01      0.01       592\n",
      "        1445       0.00      0.00      0.00        12\n",
      "        1446       0.00      0.00      0.00       116\n",
      "        1447       0.00      0.00      0.00        24\n",
      "        1448       0.00      0.00      0.00        10\n",
      "        1449       0.00      0.00      0.00       179\n",
      "        1450       0.00      0.00      0.00       111\n",
      "        1451       0.00      0.00      0.00        77\n",
      "        1452       0.00      0.00      0.00       133\n",
      "        1453       0.10      0.02      0.04        47\n",
      "        1454       0.00      0.00      0.00        63\n",
      "        1455       0.00      0.00      0.00        68\n",
      "        1456       0.11      0.00      0.01       621\n",
      "        1457       0.03      0.00      0.00       394\n",
      "        1458       0.00      0.00      0.00       220\n",
      "        1459       0.00      0.00      0.00         5\n",
      "        1460       0.00      0.00      0.00       132\n",
      "        1461       0.11      0.00      0.01      1684\n",
      "        1462       0.00      0.00      0.00       225\n",
      "        1463       0.00      0.00      0.00        15\n",
      "        1464       0.00      0.00      0.00         0\n",
      "        1465       0.00      0.00      0.00         3\n",
      "        1466       0.00      0.00      0.00        27\n",
      "        1467       0.00      0.00      0.00        25\n",
      "        1468       0.06      0.00      0.00       985\n",
      "        1469       0.08      0.01      0.02       206\n",
      "        1470       0.00      0.00      0.00       191\n",
      "        1471       0.00      0.00      0.00       197\n",
      "\n",
      "   micro avg       0.03      0.00      0.00    309858\n",
      "   macro avg       0.02      0.00      0.00    309858\n",
      "weighted avg       0.06      0.00      0.00    309858\n",
      " samples avg       0.02      0.00      0.00    309858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2fff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e882d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "282fe67f",
   "metadata": {},
   "source": [
    "#### \tMultilabel KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae3d77",
   "metadata": {},
   "source": [
    "Training time is fine but testing would take like 16 hours to predict 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a6ff292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Create a MultiOutputClassifier to handle multi-output classification\n",
    "multi_output_knn = MultiOutputClassifier(knn_classifier)\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    multi_output_knn.fit(X_train_sparse[:500, :100], y_train.iloc[:500, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbe79dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=KNeighborsClassifier())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=KNeighborsClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=KNeighborsClassifier())"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_output_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8e3507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    y_pred = multi_output_knn.predict(X_test_sparse[:10, :100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab318919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>priority_STAT</th>\n",
       "      <th>...</th>\n",
       "      <th>specimen_id_321525</th>\n",
       "      <th>specimen_id_324268</th>\n",
       "      <th>specimen_id_330995</th>\n",
       "      <th>specimen_id_331179</th>\n",
       "      <th>specimen_id_335177</th>\n",
       "      <th>specimen_id_341449</th>\n",
       "      <th>specimen_id_342098</th>\n",
       "      <th>specimen_id_356984</th>\n",
       "      <th>specimen_id_358710</th>\n",
       "      <th>specimen_id_368713</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.40</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.134028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.30</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.063194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>27.30</td>\n",
       "      <td>27.30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.047222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "0    10.00     10.00              6.0             20.0     0   \n",
       "1     3.76      3.76              4.2              5.4     1   \n",
       "2     4.40      4.40              3.3              5.1     0   \n",
       "3   101.00    101.00             96.0            108.0     0   \n",
       "4     1.00      1.00              0.5              1.2     0   \n",
       "..     ...       ...              ...              ...   ...   \n",
       "95    2.30      2.30              2.7              4.5     1   \n",
       "96    4.10      4.10              3.5              5.2     0   \n",
       "97   27.30     27.30             40.0             52.0     1   \n",
       "98   91.00     91.00             40.0            130.0     0   \n",
       "99    1.00      1.00              0.9              1.1     0   \n",
       "\n",
       "    days_since_admission     delay  priority_N/A  priority_ROUTINE  \\\n",
       "0                      2  0.114583             0                 1   \n",
       "1                      1  0.018056             0                 1   \n",
       "2                      4  0.134028             0                 1   \n",
       "3                      2  0.068056             0                 1   \n",
       "4                      2  0.053472             0                 0   \n",
       "..                   ...       ...           ...               ...   \n",
       "95                     9  0.063194             0                 0   \n",
       "96                     0  0.084722             0                 1   \n",
       "97                     3  0.025694             0                 0   \n",
       "98                    42  0.054167             0                 1   \n",
       "99                     7  0.047222             0                 0   \n",
       "\n",
       "    priority_STAT  ...  specimen_id_321525  specimen_id_324268  \\\n",
       "0               0  ...                   0                   0   \n",
       "1               0  ...                   0                   0   \n",
       "2               0  ...                   0                   0   \n",
       "3               0  ...                   0                   0   \n",
       "4               1  ...                   0                   0   \n",
       "..            ...  ...                 ...                 ...   \n",
       "95              1  ...                   0                   0   \n",
       "96              0  ...                   0                   0   \n",
       "97              1  ...                   0                   0   \n",
       "98              0  ...                   0                   0   \n",
       "99              1  ...                   0                   0   \n",
       "\n",
       "    specimen_id_330995  specimen_id_331179  specimen_id_335177  \\\n",
       "0                    0                   0                   0   \n",
       "1                    0                   0                   0   \n",
       "2                    0                   0                   0   \n",
       "3                    0                   0                   0   \n",
       "4                    0                   0                   0   \n",
       "..                 ...                 ...                 ...   \n",
       "95                   0                   0                   0   \n",
       "96                   0                   0                   0   \n",
       "97                   0                   0                   0   \n",
       "98                   0                   0                   0   \n",
       "99                   0                   0                   0   \n",
       "\n",
       "    specimen_id_341449  specimen_id_342098  specimen_id_356984  \\\n",
       "0                    0                   0                   0   \n",
       "1                    0                   0                   0   \n",
       "2                    0                   0                   0   \n",
       "3                    0                   0                   0   \n",
       "4                    0                   0                   0   \n",
       "..                 ...                 ...                 ...   \n",
       "95                   0                   0                   0   \n",
       "96                   0                   0                   0   \n",
       "97                   0                   0                   0   \n",
       "98                   0                   0                   0   \n",
       "99                   0                   0                   0   \n",
       "\n",
       "    specimen_id_358710  specimen_id_368713  \n",
       "0                    0                   0  \n",
       "1                    0                   0  \n",
       "2                    0                   0  \n",
       "3                    0                   0  \n",
       "4                    0                   0  \n",
       "..                 ...                 ...  \n",
       "95                   0                   0  \n",
       "96                   0                   0  \n",
       "97                   0                   0  \n",
       "98                   0                   0  \n",
       "99                   0                   0  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[:100, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486f196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1990e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33f22052",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56644cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>delay</th>\n",
       "      <th>priority_N/A</th>\n",
       "      <th>priority_ROUTINE</th>\n",
       "      <th>priority_STAT</th>\n",
       "      <th>...</th>\n",
       "      <th>specimen_id_321525</th>\n",
       "      <th>specimen_id_324268</th>\n",
       "      <th>specimen_id_330995</th>\n",
       "      <th>specimen_id_331179</th>\n",
       "      <th>specimen_id_335177</th>\n",
       "      <th>specimen_id_341449</th>\n",
       "      <th>specimen_id_342098</th>\n",
       "      <th>specimen_id_356984</th>\n",
       "      <th>specimen_id_358710</th>\n",
       "      <th>specimen_id_368713</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12013888888888888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.700</td>\n",
       "      <td>17.700</td>\n",
       "      <td>10.500</td>\n",
       "      <td>15.500</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006944444444444444</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>134.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006944444444444444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.400</td>\n",
       "      <td>2.400</td>\n",
       "      <td>1.600</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.08194444444444444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000</td>\n",
       "      <td>134.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07222222222222222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.500</td>\n",
       "      <td>4.800</td>\n",
       "      <td>5.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5895833333333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>138.000</td>\n",
       "      <td>138.000</td>\n",
       "      <td>133.000</td>\n",
       "      <td>145.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09444444444444444</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.032</td>\n",
       "      <td>1.032</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.03680555555555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3.510</td>\n",
       "      <td>3.510</td>\n",
       "      <td>4.600</td>\n",
       "      <td>6.100</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       value  valuenum  ref_range_lower  ref_range_upper  flag  \\\n",
       "0     19.000    19.000           22.000           32.000     1   \n",
       "1     17.700    17.700           10.500           15.500     1   \n",
       "2      0.000   134.000           70.000          100.000     1   \n",
       "3     34.000    34.000           35.000           45.000     1   \n",
       "4      2.400     2.400            1.600            2.600     0   \n",
       "..       ...       ...              ...              ...   ...   \n",
       "195    0.000   134.000           70.000          100.000     1   \n",
       "196    0.000     5.500            4.800            5.900     0   \n",
       "197  138.000   138.000          133.000          145.000     0   \n",
       "198    1.032     1.032            1.001            1.035     0   \n",
       "199    3.510     3.510            4.600            6.100     1   \n",
       "\n",
       "     days_since_admission                 delay  priority_N/A  \\\n",
       "0                       0   0.12013888888888888             0   \n",
       "1                       7  0.006944444444444444             0   \n",
       "2                       5                0.0875             0   \n",
       "3                      10  0.006944444444444444             1   \n",
       "4                       9   0.08194444444444444             0   \n",
       "..                    ...                   ...           ...   \n",
       "195                     1   0.07222222222222222             0   \n",
       "196                     0    0.5895833333333333             0   \n",
       "197                     2   0.09444444444444444             0   \n",
       "198                     4   0.03680555555555556             0   \n",
       "199                    -1                0.0125             0   \n",
       "\n",
       "     priority_ROUTINE  priority_STAT  ...  specimen_id_321525  \\\n",
       "0                   1              0  ...                   0   \n",
       "1                   1              0  ...                   0   \n",
       "2                   1              0  ...                   0   \n",
       "3                   0              0  ...                   0   \n",
       "4                   0              1  ...                   0   \n",
       "..                ...            ...  ...                 ...   \n",
       "195                 1              0  ...                   0   \n",
       "196                 0              1  ...                   0   \n",
       "197                 1              0  ...                   0   \n",
       "198                 0              1  ...                   0   \n",
       "199                 0              1  ...                   0   \n",
       "\n",
       "     specimen_id_324268  specimen_id_330995  specimen_id_331179  \\\n",
       "0                     0                   0                   0   \n",
       "1                     0                   0                   0   \n",
       "2                     0                   0                   0   \n",
       "3                     0                   0                   0   \n",
       "4                     0                   0                   0   \n",
       "..                  ...                 ...                 ...   \n",
       "195                   0                   0                   0   \n",
       "196                   0                   0                   0   \n",
       "197                   0                   0                   0   \n",
       "198                   0                   0                   0   \n",
       "199                   0                   0                   0   \n",
       "\n",
       "     specimen_id_335177  specimen_id_341449  specimen_id_342098  \\\n",
       "0                     0                   0                   0   \n",
       "1                     0                   0                   0   \n",
       "2                     0                   0                   0   \n",
       "3                     0                   0                   0   \n",
       "4                     0                   0                   0   \n",
       "..                  ...                 ...                 ...   \n",
       "195                   0                   0                   0   \n",
       "196                   0                   0                   0   \n",
       "197                   0                   0                   0   \n",
       "198                   0                   0                   0   \n",
       "199                   0                   0                   0   \n",
       "\n",
       "     specimen_id_356984  specimen_id_358710  specimen_id_368713  \n",
       "0                     0                   0                   0  \n",
       "1                     0                   0                   0  \n",
       "2                     0                   0                   0  \n",
       "3                     0                   0                   0  \n",
       "4                     0                   0                   0  \n",
       "..                  ...                 ...                 ...  \n",
       "195                   0                   0                   0  \n",
       "196                   0                   0                   0  \n",
       "197                   0                   0                   0  \n",
       "198                   0                   0                   0  \n",
       "199                   0                   0                   0  \n",
       "\n",
       "[200 rows x 100 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:200, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fae0cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [13:40<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m svm_clf \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[1;32m---> 11\u001b[0m     svm_clf\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m3000\u001b[39m, :\u001b[38;5;241m10\u001b[39m], y_train\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m3000\u001b[39m, :])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:538\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    513\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:273\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    274\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y[:, i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    278\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:60\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     58\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    330\u001b[0m     X,\n\u001b[0;32m    331\u001b[0m     y,\n\u001b[0;32m    332\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[0;32m    333\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;66;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_class_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    336\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    337\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m    338\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[0;32m    339\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[0;32m    340\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    341\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[0;32m    342\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m    343\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    344\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    345\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    346\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    347\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    348\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    349\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize multi-label SVM classifier\n",
    "svm_clf = MultiOutputClassifier(SVC(kernel='linear'))\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    svm_clf.fit(X_train_sparse[:3000, :10], y_train.iloc[:3000, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca837b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0544c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = svm_clf.predict(X_test_sparse[:100, :100])\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22b10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f326c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b73c7a40",
   "metadata": {},
   "source": [
    "#### Classifier Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bdcfc8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53328, 11679)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3eca8b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52761, 240)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "22890509",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [53328, 52761]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m classifier_chain \u001b[38;5;241m=\u001b[39m ClassifierChain(LogisticRegression())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the classifier chain\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m classifier_chain\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Predict labels for test data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m classifier_chain\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:928\u001b[0m, in \u001b[0;36mClassifierChain.fit\u001b[1;34m(self, X, Y, **fit_params)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_params \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    924\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_params is only supported if enable_metadata_routing=True. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    925\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee the User Guide for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    926\u001b[0m     )\n\u001b[1;32m--> 928\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    930\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m chain_idx, estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[0;32m    931\u001b[0m ]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:676\u001b[0m, in \u001b[0;36m_BaseChain.fit\u001b[1;34m(self, X, Y, **fit_params)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    656\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 676\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, Y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    678\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1165\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1165\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [53328, 52761]"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a chain of logistic regression classifiers\n",
    "classifier_chain = ClassifierChain(LogisticRegression())\n",
    "\n",
    "# Train the classifier chain\n",
    "classifier_chain.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = classifier_chain.predict(X_test_sparse)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa21d0",
   "metadata": {},
   "source": [
    "#### Random forest for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40e9bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a multi-output Random Forest classifier\n",
    "forest_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = forest_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce63e76",
   "metadata": {},
   "source": [
    "#### \tProbabilistic graphical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint inference of multiple diagnoses (Bayesian Networks or Markov Random Fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f89e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2bf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c2df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978cc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ce91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de637681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291861e",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7be06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115797c",
   "metadata": {},
   "source": [
    "### emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"emar_data_train.csv\"\n",
    "full_path = path + file\n",
    "emar_data_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_data_test.csv\"\n",
    "full_path = path + file\n",
    "emar_data_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_label_train.csv\"\n",
    "full_path = path + file\n",
    "emar_label_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_label_test.csv\"\n",
    "full_path = path + file\n",
    "emar_label_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4a3ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "emar_label_train['los'] = emar_label_train['los'].astype(str)\n",
    "emar_label_train.fillna(0, inplace=True)\n",
    "emar_label_test['los'] = emar_label_test['los'].astype(str)\n",
    "emar_label_test.fillna(0, inplace=True)\n",
    "emar_label_train.loc[~emar_label_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "emar_label_test.loc[~emar_label_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emar_label_train['los'] = emar_label_train['los'].apply(convert_to_days)\n",
    "emar_label_test['los'] = emar_label_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emar_data_train['delay']= emar_data_train['delay'].apply(convert_to_days)\n",
    "emar_data_test['delay']= emar_data_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "emar_label_test['los'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1ee7a",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f260b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc333c",
   "metadata": {},
   "source": [
    "### emar_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c222fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"emar_detail_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_detail_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_detail_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"emar_detail_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e76a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e75b1",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beebfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f9c5a",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b4ae1",
   "metadata": {},
   "source": [
    "### omr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70805265",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"omr_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"omr_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"omr_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"omr_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b117b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce to 12 features, this is an especially sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df361f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 12\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "transformed_matrix = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf43d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba526c44",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f67e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927bcf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e9fbd",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2bf34",
   "metadata": {},
   "source": [
    "### Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"admissions_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"admissions_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"admissions_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"admissions_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['ed_duration']= X_train['ed_duration'].apply(convert_to_days)\n",
    "X_test['ed_duration']= X_test['ed_duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381f5ef",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef357a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02638ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13568e3",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b6f9e",
   "metadata": {},
   "source": [
    "### hcpcsevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dad259",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"hcpcsevents_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"hcpcsevents_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"hcpcsevents_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"hcpcsevents_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 13 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to integers\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad38f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 9\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "transformed_matrix = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab301b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544c09b",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd69cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6cd4db",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234fa01",
   "metadata": {},
   "source": [
    "### microbiologyevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bea284",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"microbio_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"microbio_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"microbio_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"microbio_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83878b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491dc32",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5435010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4266ce4",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc414f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0bf75",
   "metadata": {},
   "source": [
    "### patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1283e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"patients_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"patients_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"patients_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"patients_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f5376",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fa5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5026f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c2e95",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1996ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32011e7",
   "metadata": {},
   "source": [
    "### pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6266819",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"pharmacy_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"pharmacy_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"pharmacy_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"pharmacy_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['medication_duration']= X_train['medication_duration'].apply(convert_to_days)\n",
    "X_test['medication_duration']= X_test['medication_duration'].apply(convert_to_days)\n",
    "# Convert strings to integers\n",
    "X_train['verification_delay'] = X_train['verification_delay'].str.split().str[0].astype(int)\n",
    "X_test['verification_delay'] = X_test['verification_delay'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d973d5",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72842428",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4651f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a82431",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8d16a",
   "metadata": {},
   "source": [
    "### poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac235211",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"poe_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"poe_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"poe_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"poe_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03982781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901fbb4",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162c812",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7411a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b92565",
   "metadata": {},
   "source": [
    "###  prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"prescriptions_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"prescriptions_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"prescriptions_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"prescriptions_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b06476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a03a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 4890 to 2874 or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 2874\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "transformed_matrix = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d9c60",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a518d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129fd236",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9be482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c019a8",
   "metadata": {},
   "source": [
    "### procedures_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f983508",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"procedures_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedures_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedures_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedures_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef34365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to integers\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 355 to 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 115\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "transformed_matrix = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fbdc8f",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf7bc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ccd42c",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e37823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132d96c",
   "metadata": {},
   "source": [
    "### services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"services_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"services_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"services_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"services_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d23ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ee661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70006c1",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d415c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad1e2d",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4801b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f0a25",
   "metadata": {},
   "source": [
    "### transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e33b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"transfers_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"transfers_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"transfers_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"transfers_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223dee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f566456e",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb390b23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5beeb2",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4fadc",
   "metadata": {},
   "source": [
    "### chartevents - unable to allocate memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"chart_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"chart_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"chart_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"chart_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13515a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e0528",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af735a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f4d06",
   "metadata": {},
   "source": [
    "### icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30424c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"icustays_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"icustays_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"icustays_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"icustays_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25835e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fac17",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c2f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538fa17",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ba412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b7bb23",
   "metadata": {},
   "source": [
    "### ingredientevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6dcc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"ingredient_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"ingredient_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"ingredient_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"ingredient_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cdc92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16607cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 7727 to 4116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 4116\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "transformed_matrix = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ea5dec",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7434ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ada7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb28dd2",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73dae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e06f3",
   "metadata": {},
   "source": [
    "### inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70017657",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"input_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"input_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"input_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"input_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efc1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41be1b0",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1727a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf839155",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89627e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47468784",
   "metadata": {},
   "source": [
    "### outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"output_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"output_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"output_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"output_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa567d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e713d5ca",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c25b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c2b64",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ff1cb",
   "metadata": {},
   "source": [
    "### procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"procedure_events_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedure_events_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedure_events_label_train.csv\"\n",
    "full_path = path + file\n",
    "y_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedure_events_label_test.csv\"\n",
    "full_path = path + file\n",
    "y_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "y_train['los'] = y_train['los'].astype(str)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test['los'] = y_test['los'].astype(str)\n",
    "y_test.fillna(0, inplace=True)\n",
    "y_train.loc[~y_train['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "y_test.loc[~y_test['los'].str.contains('days'), 'los'] = '0 days 00:00:00'\n",
    "\n",
    "y_train['los'] = y_train['los'].apply(convert_to_days)\n",
    "y_test['los'] = y_test['los'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5ec84",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427663be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['los'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb730598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to 1D array using ravel()\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Initialize and fit the Random Forest regression model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Values (Random Forest Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00330a77",
   "metadata": {},
   "source": [
    "#### Compare to MSE of always guessing average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648da47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of training set target variable\n",
    "mean_prediction = np.mean(y_train)\n",
    "\n",
    "# Generate an array of the same length as pred_values with the mean value\n",
    "mean_guesses = np.full_like(y_test, mean_prediction)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) between the predicted values and the mean guesses\n",
    "mse = np.mean((y_pred - mean_guesses) ** 2)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e64af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
