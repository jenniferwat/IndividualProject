{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "efc90b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.24.3\n",
      "Pandas version: 1.5.3\n",
      "Scikit version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# External libraries for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "#To render graphs within notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Versions of libraries\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Scikit version: {}\".format(sk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "79ab6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592894b9",
   "metadata": {},
   "source": [
    "#### Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d1d424ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "362da870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_days(duration_str):\n",
    "    parts = duration_str.split(' days ')  # Split string into form ['22', '20:55:00']\n",
    "    days = float(parts[0])  # Extract number of days and convert to float\n",
    "    time_parts = parts[1].split(':')  # Split time part (hh:mm:ss) ['20', '55', '00']\n",
    "    hours = float(time_parts[0])  # Extract hours and convert to float\n",
    "    minutes = float(time_parts[1])  # Extract minutes and convert to float\n",
    "    seconds = float(time_parts[2])  # Extract seconds and convert to float\n",
    "    total_days = days + (hours / 24) + (minutes / (24 * 60)) + (seconds / (24 * 3600))  # Calculate total days\n",
    "    return total_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a0a24ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)\n",
    "\n",
    "df_admissions['dischtime'] = pd.to_datetime(df_admissions['dischtime'], format='%d/%m/%Y %H:%M')\n",
    "df_admissions['admittime'] = pd.to_datetime(df_admissions['admittime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_admittime= pd.DataFrame()\n",
    "df_admittime['hadm_id'] = df_admissions['hadm_id']\n",
    "df_admittime['admittime'] = df_admissions['admittime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5b684",
   "metadata": {},
   "source": [
    "### Target variable calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "166230cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/procedures_icd.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_procedures = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6f909384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10011398</td>\n",
       "      <td>27505812</td>\n",
       "      <td>3</td>\n",
       "      <td>2146-12-15</td>\n",
       "      <td>3961</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011398</td>\n",
       "      <td>27505812</td>\n",
       "      <td>2</td>\n",
       "      <td>2146-12-15</td>\n",
       "      <td>3615</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011398</td>\n",
       "      <td>27505812</td>\n",
       "      <td>1</td>\n",
       "      <td>2146-12-15</td>\n",
       "      <td>3614</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10014729</td>\n",
       "      <td>23300884</td>\n",
       "      <td>4</td>\n",
       "      <td>2125-03-23</td>\n",
       "      <td>3897</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10014729</td>\n",
       "      <td>23300884</td>\n",
       "      <td>1</td>\n",
       "      <td>2125-03-20</td>\n",
       "      <td>3403</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>3</td>\n",
       "      <td>2174-12-20</td>\n",
       "      <td>4513</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>10021118</td>\n",
       "      <td>24490144</td>\n",
       "      <td>4</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>5A1221Z</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>10021118</td>\n",
       "      <td>24490144</td>\n",
       "      <td>3</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>06BP4ZZ</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>10021118</td>\n",
       "      <td>24490144</td>\n",
       "      <td>1</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>02100Z9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>10021118</td>\n",
       "      <td>24490144</td>\n",
       "      <td>2</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>02110Z3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject_id   hadm_id  seq_num   chartdate icd_code  icd_version\n",
       "0      10011398  27505812        3  2146-12-15     3961            9\n",
       "1      10011398  27505812        2  2146-12-15     3615            9\n",
       "2      10011398  27505812        1  2146-12-15     3614            9\n",
       "3      10014729  23300884        4  2125-03-23     3897            9\n",
       "4      10014729  23300884        1  2125-03-20     3403            9\n",
       "..          ...       ...      ...         ...      ...          ...\n",
       "717    10004733  27411876        3  2174-12-20     4513            9\n",
       "718    10021118  24490144        4  2161-11-19  5A1221Z           10\n",
       "719    10021118  24490144        3  2161-11-19  06BP4ZZ           10\n",
       "720    10021118  24490144        1  2161-11-19  02100Z9           10\n",
       "721    10021118  24490144        2  2161-11-19  02110Z3           10\n",
       "\n",
       "[722 rows x 6 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8ebfa6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/d_icd_procedures.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_codes = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a10ea3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns \n",
    "df_procedures = df_procedures.drop(columns=['subject_id', 'seq_num','icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "df45bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "df_procedures['chartdate'] = pd.to_datetime(df_procedures['chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "055ec26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>icd_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27505812</td>\n",
       "      <td>2146-12-15</td>\n",
       "      <td>3961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27505812</td>\n",
       "      <td>2146-12-15</td>\n",
       "      <td>3615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27505812</td>\n",
       "      <td>2146-12-15</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23300884</td>\n",
       "      <td>2125-03-23</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23300884</td>\n",
       "      <td>2125-03-20</td>\n",
       "      <td>3403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>27411876</td>\n",
       "      <td>2174-12-20</td>\n",
       "      <td>4513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>24490144</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>5A1221Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>24490144</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>06BP4ZZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>24490144</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>02100Z9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>24490144</td>\n",
       "      <td>2161-11-19</td>\n",
       "      <td>02110Z3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  chartdate icd_code\n",
       "0    27505812 2146-12-15     3961\n",
       "1    27505812 2146-12-15     3615\n",
       "2    27505812 2146-12-15     3614\n",
       "3    23300884 2125-03-23     3897\n",
       "4    23300884 2125-03-20     3403\n",
       "..        ...        ...      ...\n",
       "717  27411876 2174-12-20     4513\n",
       "718  24490144 2161-11-19  5A1221Z\n",
       "719  24490144 2161-11-19  06BP4ZZ\n",
       "720  24490144 2161-11-19  02100Z9\n",
       "721  24490144 2161-11-19  02110Z3\n",
       "\n",
       "[722 rows x 3 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db477f88",
   "metadata": {},
   "source": [
    "# Loading pretrained procedure prediction learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "61ccd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/procedures_learners/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5e857",
   "metadata": {},
   "source": [
    "### emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f3232dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_emar.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_emar = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ab502465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_emar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc034d",
   "metadata": {},
   "source": [
    "### microbiologyevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "244aa48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_microbio.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_microbio = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4f3192a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=&#x27;l1&#x27;,\n",
       "                                                   random_state=42,\n",
       "                                                   solver=&#x27;saga&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=&#x27;l1&#x27;,\n",
       "                                                   random_state=42,\n",
       "                                                   solver=&#x27;saga&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty='l1',\n",
       "                                                   random_state=42,\n",
       "                                                   solver='saga'))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_microbio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df70157",
   "metadata": {},
   "source": [
    "### pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a5c94f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_pharmacy.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_pharmacy = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5a5bd639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_pharmacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e26199",
   "metadata": {},
   "source": [
    "### icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8a09dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_icustays.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_icustays = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2035199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(fit_intercept=False,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_icustays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d2fd8",
   "metadata": {},
   "source": [
    "### inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "881b7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_input.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_input = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "71eb3582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5e8a5",
   "metadata": {},
   "source": [
    "### outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "32c675d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_output.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_output = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6dad4b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a089f96",
   "metadata": {},
   "source": [
    "### procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b74e5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_procedure_events.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_procedure_events = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e1e60784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                   multi_class='multinomial',\n",
       "                                                   penalty=None,\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_procedure_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45878acb",
   "metadata": {},
   "source": [
    "### datetimeevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "989b4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"logistic_clf_datetime_events.joblib\"\n",
    "full_path = path + file\n",
    "\n",
    "logistic_clf_datetime_events = joblib.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2b58b383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(multi_class=&#x27;multinomial&#x27;,\n",
       "                                                   random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(multi_class='multinomial',\n",
       "                                                   random_state=42))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf_datetime_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce261930",
   "metadata": {},
   "source": [
    "## Load and preprocess evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4b7dac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4c438b",
   "metadata": {},
   "source": [
    "### emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "39c46deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_emar_evaluation.csv')\n",
    "\n",
    "df_emar = pd.read_csv(file_path)\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_emar_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432920b9",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6a743b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar.drop(columns=['hadm_id','charttime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "db2d9691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "86339230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert '0 days' to timedelta\n",
    "zero_timedelta = pd.Timedelta(0)\n",
    "\n",
    "# Replace '0 days' with the desired timedelta value\n",
    "data['delay'] = data['delay'].replace('0 days', zero_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "46c19ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delay']= data['delay'].astype(str)\n",
    "data['delay']= data['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fde37",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "70445f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "da26c9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472491"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_emar.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7af94642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_emar, axis=1))\n",
    "# 2201 available to predict \n",
    "# underpredicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f4ecc551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41927782751417486\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.75      0.08      0.15       109\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.11      0.03      0.04       228\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00       137\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00       100\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00       100\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00        80\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00        47\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00       161\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00        37\n",
      "          54       0.53      0.03      0.06       340\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       1.00      0.04      0.08        77\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00        45\n",
      "          78       0.00      0.00      0.00        45\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00        47\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.03      0.02      0.02       181\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.45      0.08      0.13       129\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         4\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.71      0.09      0.16       109\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         2\n",
      "         116       0.00      0.00      0.00        47\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00        18\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.31      0.08      0.12        52\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.05      0.03      0.03      2202\n",
      "   macro avg       0.03      0.00      0.01      2202\n",
      "weighted avg       0.24      0.03      0.04      2202\n",
      " samples avg       0.01      0.01      0.01      2202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_emar = logistic_clf_emar.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_emar)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target, y_pred_emar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f3e1d",
   "metadata": {},
   "source": [
    "### microbiologyevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY PREDICTING 0 FOR ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4eedc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "031e60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_microbio_evaluation.csv')\n",
    "\n",
    "df_microbio = pd.read_csv(file_path)\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_microbio_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9c651",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e3d888cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_microbio.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d723499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duration strings to floats\n",
    "\n",
    "data['delay']= data['delay'].astype(str)\n",
    "data['delay']= data['delay'].apply(convert_to_days)\n",
    "data['days_since_admission'] = data['days_since_admission'].astype(str)\n",
    "data['days_since_admission'] = data['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92658747",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fb9615a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    245\n",
       "Name: 3, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred_microbio)[3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4e9dcdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31115"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_microbio.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "df7670ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_microbio, axis=1))\n",
    "# 194 available to predict \n",
    "# underpredicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a7393552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30612244897959184\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00        14\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         4\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       0.00      0.00      0.00         4\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00        22\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00        18\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00        31\n",
      "          65       0.00      0.00      0.00         5\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         3\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         3\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         6\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00        10\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         1\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00        41\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       194\n",
      "   macro avg       0.00      0.00      0.00       194\n",
      "weighted avg       0.00      0.00      0.00       194\n",
      " samples avg       0.00      0.00      0.00       194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_microbio = logistic_clf_microbio.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_microbio)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target, y_pred_microbio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281059d4",
   "metadata": {},
   "source": [
    "### pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bd588001",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bc4b1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_pharmacy_evaluation.csv')\n",
    "\n",
    "df_pharmacy = pd.read_csv(file_path)\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_pharmacy_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d31b2",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "44f8d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_pharmacy.drop(columns=['hadm_id','duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2ed0064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verification_delay'] = data['verification_delay'].replace('0 days', zero_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "77d776bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medication_duration']= data['medication_duration'].astype(str)\n",
    "data['medication_duration']= data['medication_duration'].apply(convert_to_days)\n",
    "data['verification_delay'] = data['verification_delay'].astype(str)\n",
    "data['verification_delay'] = data['verification_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a1ea3",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "69ac40de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312417"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pharmacy.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "af78ac3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_pharmacy, axis=1))\n",
    "# 1438 available to predict \n",
    "# underpredicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4b0257b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2930474333983106\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00        26\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00        42\n",
      "          11       0.20      0.03      0.05       112\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00        25\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00        46\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00        34\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.50      0.06      0.11        34\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00        39\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00        44\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00        76\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00        17\n",
      "          64       0.00      0.00      0.00        75\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00        42\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00        29\n",
      "          87       0.00      0.00      0.00        29\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00        16\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00        42\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00        16\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       1.00      0.12      0.22        16\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00       129\n",
      "         113       0.00      0.00      0.00        38\n",
      "         114       0.00      0.00      0.00         4\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.57      0.25      0.35        16\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00        44\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00        91\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00        20\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00        11\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00        55\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       1.00      0.04      0.07        26\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00        10\n",
      "         157       0.00      0.00      0.00        44\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.00      0.00      0.00         0\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.33      0.02      0.04        98\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       0.00      0.00      0.00         0\n",
      "         188       0.00      0.00      0.00         0\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00        38\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00        42\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         0\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.11      0.01      0.02      1438\n",
      "   macro avg       0.02      0.00      0.00      1438\n",
      "weighted avg       0.09      0.01      0.02      1438\n",
      " samples avg       0.01      0.01      0.01      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_pharmacy = logistic_clf_pharmacy.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_pharmacy)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target, y_pred_pharmacy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fe431",
   "metadata": {},
   "source": [
    "### icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b90371ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5419f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_icustays_evaluation.csv')\n",
    "\n",
    "df_icustays = pd.read_csv(file_path)\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_icustays_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6c6a6",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "07b9044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_icustays.drop(columns=['hadm_id'])\n",
    "file_path = os.path.join(folder_name, 'df_icustays_evaluation_target.csv')\n",
    "target = pd.read_csv(file_path)\n",
    "# target = target.drop(columns=['hadm_id','chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "64a8e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['days_since_admission']= data['days_since_admission'].astype(str)\n",
    "data['days_since_admission']= data['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642cc37",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "50fc296b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_icustays.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5c17b7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_icustays, axis=1))\n",
    "# 1 available to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2d20c3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00         1\n",
      "   macro avg       0.00      0.00      0.00         1\n",
      "weighted avg       0.00      0.00      0.00         1\n",
      " samples avg       0.00      0.00      0.00         1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_icustays = logistic_clf_icustays.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_icustays)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target.values, y_pred_icustays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12553982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     0B978ZX       0.00      0.00      0.00       1.0\n",
      "     0D598ZZ       0.00      0.00      0.00       1.0\n",
      "        3491       0.00      0.00      0.00       1.0\n",
      "        3893       0.00      0.00      0.00       0.0\n",
      "        3897       0.00      0.00      0.00       0.0\n",
      "        4311       0.00      0.00      0.00       0.0\n",
      "        5491       0.00      0.00      0.00       1.0\n",
      "        8604       0.00      0.00      0.00       1.0\n",
      "        9604       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       5.0\n",
      "   macro avg       0.00      0.00      0.00       5.0\n",
      "weighted avg       0.00      0.00      0.00       5.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# # Make predictions on the testing set\n",
    "# y_pred_icustays = logistic_clf_icustays.predict(data)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(target, y_pred_icustays)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(target, y_pred_icustays))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141fa5aa",
   "metadata": {},
   "source": [
    "### inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "76980458",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "34e84f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_input_evaluation.csv')\n",
    "\n",
    "df_input = pd.read_csv(file_path)\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_input_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b1c45",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6f53690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_input.drop(columns=['hadm_id','duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bf50ff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>rate</th>\n",
       "      <th>patientweight</th>\n",
       "      <th>totalamount</th>\n",
       "      <th>isopenbag</th>\n",
       "      <th>originalamount</th>\n",
       "      <th>originalrate</th>\n",
       "      <th>recording_delay</th>\n",
       "      <th>rateuom_N/A</th>\n",
       "      <th>rateuom_grams/hour</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_229014</th>\n",
       "      <th>itemid_229058</th>\n",
       "      <th>itemid_229069</th>\n",
       "      <th>itemid_229072</th>\n",
       "      <th>itemid_229295</th>\n",
       "      <th>itemid_229296</th>\n",
       "      <th>itemid_229297</th>\n",
       "      <th>itemid_229420</th>\n",
       "      <th>itemid_229615</th>\n",
       "      <th>itemid_229639</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.5</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.040972</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.800001</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>59.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.498611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>0.319770</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>96.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.076389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>0.110377</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>96.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.532536</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.075694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>96.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.680346</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2728 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount      rate  patientweight  totalamount  isopenbag  \\\n",
       "0      1.000000  0.000000           59.5        200.0          0   \n",
       "1      2.000000  0.000000           59.5        100.0          0   \n",
       "2      2.000000  0.000000           59.5        100.0          0   \n",
       "3      2.000000  0.000000           59.5        100.0          0   \n",
       "4     71.800001  6.000000           59.5        100.0          0   \n",
       "...         ...       ...            ...          ...        ...   \n",
       "2723   0.500000  0.000000           96.0          0.0          0   \n",
       "2724   0.500000  0.000000           96.0          0.0          0   \n",
       "2725   0.319770  0.030008           96.0        250.0          0   \n",
       "2726   0.110377  0.009998           96.0        250.0          0   \n",
       "2727   0.147810  0.019996           96.0        250.0          0   \n",
       "\n",
       "      originalamount  originalrate  recording_delay  rateuom_N/A  \\\n",
       "0           1.000000      1.000000        -0.000694            1   \n",
       "1           2.000000      0.033333        -0.040972            1   \n",
       "2           2.000000      0.033333        -0.041667            1   \n",
       "3           2.000000      0.033333        -0.041667            1   \n",
       "4         100.000000      6.000000        -0.498611            0   \n",
       "...              ...           ...              ...          ...   \n",
       "2723        0.500000      0.500000        -0.000694            1   \n",
       "2724        0.500000      0.500000         0.057639            1   \n",
       "2725        8.000000      0.030000        -0.076389            0   \n",
       "2726        7.532536      0.010000        -0.075694            0   \n",
       "2727        7.680346      0.020000         0.004167            0   \n",
       "\n",
       "      rateuom_grams/hour  ...  itemid_229014  itemid_229058  itemid_229069  \\\n",
       "0                      0  ...              0              0              0   \n",
       "1                      0  ...              0              0              0   \n",
       "2                      0  ...              0              0              0   \n",
       "3                      0  ...              0              0              0   \n",
       "4                      0  ...              0              0              0   \n",
       "...                  ...  ...            ...            ...            ...   \n",
       "2723                   0  ...              0              0              0   \n",
       "2724                   0  ...              0              0              0   \n",
       "2725                   0  ...              0              0              0   \n",
       "2726                   0  ...              0              0              0   \n",
       "2727                   0  ...              0              0              0   \n",
       "\n",
       "      itemid_229072  itemid_229295  itemid_229296  itemid_229297  \\\n",
       "0                 0              0              0              0   \n",
       "1                 0              0              0              0   \n",
       "2                 0              0              0              0   \n",
       "3                 0              0              0              0   \n",
       "4                 0              0              0              0   \n",
       "...             ...            ...            ...            ...   \n",
       "2723              0              0              0              0   \n",
       "2724              0              0              0              0   \n",
       "2725              0              0              0              0   \n",
       "2726              0              0              0              0   \n",
       "2727              0              0              0              0   \n",
       "\n",
       "      itemid_229420  itemid_229615  itemid_229639  \n",
       "0                 0              0              0  \n",
       "1                 0              0              0  \n",
       "2                 0              0              0  \n",
       "3                 0              0              0  \n",
       "4                 0              0              0  \n",
       "...             ...            ...            ...  \n",
       "2723              0              0              0  \n",
       "2724              0              0              0  \n",
       "2725              0              0              0  \n",
       "2726              0              0              0  \n",
       "2727              0              0              0  \n",
       "\n",
       "[2728 rows x 202 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e4414",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f40c1ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332816"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_input.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c344e098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6129"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_input, axis=1))\n",
    "# 2173 available to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ea736cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27089442815249265\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.18      0.01      0.02       285\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00        50\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00       161\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00       109\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00       117\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00       397\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00       443\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00       211\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00        11\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00       172\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         6\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00       200\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      2173\n",
      "   macro avg       0.00      0.00      0.00      2173\n",
      "weighted avg       0.02      0.00      0.00      2173\n",
      " samples avg       0.00      0.00      0.00      2173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_input = logistic_clf_input.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_input)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target, y_pred_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d530f47",
   "metadata": {},
   "source": [
    "### outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5eb233e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bde34b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_output_evaluation.csv')\n",
    "\n",
    "df_output = pd.read_csv(file_path)\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_output_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2adf59",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6ee0eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_output.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "db4dd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['days_since_admission']= data['days_since_admission'].astype(str)\n",
    "data['days_since_admission']= data['days_since_admission'].apply(convert_to_days)\n",
    "data['recording_delay']= data['recording_delay'].astype(str)\n",
    "data['recording_delay']= data['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb89e45",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "6616f908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117000"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_output.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "b36777b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_output, axis=1))\n",
    "# 814 available to predict \n",
    "# underpredicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5ca9a8ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21128205128205127\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00        36\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00        24\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00        52\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00       225\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00       165\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00        70\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         5\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00       102\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.07      0.06      0.07        47\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.03      0.00      0.01       814\n",
      "   macro avg       0.00      0.00      0.00       814\n",
      "weighted avg       0.00      0.00      0.00       814\n",
      " samples avg       0.00      0.00      0.00       814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_output = logistic_clf_output.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_output)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target, y_pred_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc416e26",
   "metadata": {},
   "source": [
    "### procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8ea8d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "29ebcbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_procedure_events_evaluation.csv')\n",
    "\n",
    "df_procedure_events = pd.read_csv(file_path)\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_procedure_events_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d4440",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "63e178cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_procedure_events.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362eeeb",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "9680981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15729"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_procedure_events.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "36d9c61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_procedure_events, axis=1))\n",
    "# 123 available to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "44307da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17006802721088435\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         4\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00        10\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00        20\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00        39\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00        13\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         7\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       123\n",
      "   macro avg       0.00      0.00      0.00       123\n",
      "weighted avg       0.00      0.00      0.00       123\n",
      " samples avg       0.00      0.00      0.00       123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_procedure_events = logistic_clf_procedure_events.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_procedure_events)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target, y_pred_procedure_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c1ecc",
   "metadata": {},
   "source": [
    "### datetimeevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ed79f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'EnsembleEvaluationData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ea0907f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_name, 'df_datetime_events_evaluation.csv')\n",
    "\n",
    "df_datetime_events = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "file_path = os.path.join(folder_name, 'df_datetime_events_evaluation_target.csv')\n",
    "\n",
    "target = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c6645",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "545691a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_datetime_events.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763dc9b",
   "metadata": {},
   "source": [
    "#### Testing the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "8f3f9406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377454"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_datetime_events.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f8cd8a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_datetime_events, axis=1))\n",
    "# 2442 available to predict \n",
    "# underpredicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a3815c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1799265605875153\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00       100\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00        12\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00       279\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00        56\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00       113\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00       100\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.18      0.09      0.12       195\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00       477\n",
      "          85       0.00      0.00      0.00        27\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00       434\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00       243\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00        61\n",
      "         123       0.00      0.00      0.00        56\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00        25\n",
      "         141       0.00      0.00      0.00       223\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00        39\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         2\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.06      0.01      0.01      2442\n",
      "   macro avg       0.00      0.00      0.00      2442\n",
      "weighted avg       0.01      0.01      0.01      2442\n",
      " samples avg       0.00      0.01      0.00      2442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_datetime_events = logistic_clf_datetime_events.predict(data.values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(target, y_pred_datetime_events)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(target, y_pred_datetime_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "61deba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377454"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_datetime_events.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "af72f1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(y_pred_datetime_events, axis=1))\n",
    "# 2442 available to predict \n",
    "# underpredicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "1f052e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2451"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred_datetime_events, axis=1).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d3205",
   "metadata": {},
   "source": [
    "Instead of combining the predictions (because they are all trash) I am going to analyse each individually to provide insights into which procedures are easiest to predict, the most informative tables etc. and try to explain why"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
