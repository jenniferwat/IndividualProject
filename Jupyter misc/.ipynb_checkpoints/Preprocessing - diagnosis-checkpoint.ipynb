{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fce576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.24.3\n",
      "Pandas version: 1.5.3\n",
      "Scikit version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# External libraries for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "#To render graphs within notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import os\n",
    "\n",
    "# Versions of libraries\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Scikit version: {}\".format(sk.__version__))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d433a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7451cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)\n",
    "\n",
    "df_admissions['dischtime'] = pd.to_datetime(df_admissions['dischtime'], format='%d/%m/%Y %H:%M')\n",
    "df_admissions['admittime'] = pd.to_datetime(df_admissions['admittime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_admittime= pd.DataFrame()\n",
    "df_admittime['hadm_id'] = df_admissions['hadm_id']\n",
    "df_admittime['admittime'] = df_admissions['admittime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5fb61",
   "metadata": {},
   "source": [
    "### Target variable calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a808e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# admission id and one hot encoding of the icd_codes (or drgcodes) related to it\n",
    "# first one-hot encode the code column and then aggregate by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bc2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/diagnoses_icd.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_diagnoses = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85bb133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10035185</td>\n",
       "      <td>22580999</td>\n",
       "      <td>3</td>\n",
       "      <td>4139</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10035185</td>\n",
       "      <td>22580999</td>\n",
       "      <td>10</td>\n",
       "      <td>V707</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10035185</td>\n",
       "      <td>22580999</td>\n",
       "      <td>1</td>\n",
       "      <td>41401</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10035185</td>\n",
       "      <td>22580999</td>\n",
       "      <td>9</td>\n",
       "      <td>3899</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10035185</td>\n",
       "      <td>22580999</td>\n",
       "      <td>11</td>\n",
       "      <td>V8532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num icd_code  icd_version\n",
       "0    10035185  22580999        3     4139            9\n",
       "1    10035185  22580999       10     V707            9\n",
       "2    10035185  22580999        1    41401            9\n",
       "3    10035185  22580999        9     3899            9\n",
       "4    10035185  22580999       11    V8532            9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diagnoses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69292245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses = df_diagnoses.drop(columns=['subject_id','seq_num','icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2f42e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22580999</td>\n",
       "      <td>4139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22580999</td>\n",
       "      <td>V707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22580999</td>\n",
       "      <td>41401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22580999</td>\n",
       "      <td>3899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22580999</td>\n",
       "      <td>V8532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id icd_code\n",
       "0  22580999     4139\n",
       "1  22580999     V707\n",
       "2  22580999    41401\n",
       "3  22580999     3899\n",
       "4  22580999    V8532"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diagnoses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d11e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_diagnoses['icd_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_diagnoses[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd38977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>00845</th>\n",
       "      <th>0088</th>\n",
       "      <th>0380</th>\n",
       "      <th>0383</th>\n",
       "      <th>03842</th>\n",
       "      <th>03843</th>\n",
       "      <th>03849</th>\n",
       "      <th>0388</th>\n",
       "      <th>0389</th>\n",
       "      <th>...</th>\n",
       "      <th>Z95810</th>\n",
       "      <th>Z95820</th>\n",
       "      <th>Z961</th>\n",
       "      <th>Z96651</th>\n",
       "      <th>Z980</th>\n",
       "      <th>Z981</th>\n",
       "      <th>Z9884</th>\n",
       "      <th>Z9911</th>\n",
       "      <th>Z992</th>\n",
       "      <th>Z9981</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>29820177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  00845  0088  0380  0383  03842  03843  03849  0388  0389  ...  \\\n",
       "0    20044587      0     0     0     0      0      0      0     0     0  ...   \n",
       "1    20093566      0     0     0     0      0      0      0     0     0  ...   \n",
       "2    20192635      0     0     0     0      0      0      0     0     0  ...   \n",
       "3    20199380      0     0     0     0      0      0      0     0     0  ...   \n",
       "4    20214994      0     0     0     0      0      0      0     0     0  ...   \n",
       "..        ...    ...   ...   ...   ...    ...    ...    ...   ...   ...  ...   \n",
       "270  29820177      0     0     0     0      0      0      0     0     0  ...   \n",
       "271  29839885      0     0     0     0      0      0      0     0     0  ...   \n",
       "272  29842315      0     0     0     0      0      0      0     0     0  ...   \n",
       "273  29858644      0     0     0     0      0      0      0     0     0  ...   \n",
       "274  29974575      0     0     0     0      0      0      1     0     0  ...   \n",
       "\n",
       "     Z95810  Z95820  Z961  Z96651  Z980  Z981  Z9884  Z9911  Z992  Z9981  \n",
       "0         0       0     0       0     0     0      0      0     0      0  \n",
       "1         0       0     0       0     0     0      1      0     1      0  \n",
       "2         0       0     0       0     0     0      0      0     0      0  \n",
       "3         0       0     0       0     0     0      0      0     0      0  \n",
       "4         0       0     0       0     0     0      0      0     0      0  \n",
       "..      ...     ...   ...     ...   ...   ...    ...    ...   ...    ...  \n",
       "270       0       0     0       0     0     0      0      0     0      0  \n",
       "271       0       0     0       0     0     0      0      0     0      0  \n",
       "272       0       0     0       0     0     0      0      0     1      1  \n",
       "273       0       0     0       0     0     0      0      0     0      0  \n",
       "274       0       0     0       0     0     0      0      0     0      0  \n",
       "\n",
       "[275 rows x 1473 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diagnoses = df_aggregated\n",
    "df_diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1e5af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/drgcodes.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_drgcodes = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "923cdcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>drg_type</th>\n",
       "      <th>drg_code</th>\n",
       "      <th>description</th>\n",
       "      <th>drg_severity</th>\n",
       "      <th>drg_mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004235</td>\n",
       "      <td>22187210</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>864</td>\n",
       "      <td>FEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026255</td>\n",
       "      <td>22059910</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>180</td>\n",
       "      <td>RESPIRATORY NEOPLASMS W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10032725</td>\n",
       "      <td>20611640</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>54</td>\n",
       "      <td>NERVOUS SYSTEM NEOPLASMS W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005866</td>\n",
       "      <td>21636229</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>393</td>\n",
       "      <td>OTHER DIGESTIVE SYSTEM DIAGNOSES W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10008454</td>\n",
       "      <td>20291550</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>956</td>\n",
       "      <td>LIMB REATTACHMENT, HIP &amp; FEMUR PROC FOR MULTIP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id drg_type  drg_code  \\\n",
       "0    10004235  22187210     HCFA       864   \n",
       "1    10026255  22059910     HCFA       180   \n",
       "2    10032725  20611640     HCFA        54   \n",
       "3    10005866  21636229     HCFA       393   \n",
       "4    10008454  20291550     HCFA       956   \n",
       "\n",
       "                                         description  drg_severity  \\\n",
       "0                                              FEVER           NaN   \n",
       "1                        RESPIRATORY NEOPLASMS W MCC           NaN   \n",
       "2                     NERVOUS SYSTEM NEOPLASMS W MCC           NaN   \n",
       "3             OTHER DIGESTIVE SYSTEM DIAGNOSES W MCC           NaN   \n",
       "4  LIMB REATTACHMENT, HIP & FEMUR PROC FOR MULTIP...           NaN   \n",
       "\n",
       "   drg_mortality  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d418db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drgcodes = df_drgcodes.drop(columns=['subject_id','drg_type','description','drg_severity','drg_mortality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e9b2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_drgcodes['drg_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_drgcodes[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a96022ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>29802992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0    20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1    20093566   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2    20192635   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3    20199380   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4    20214994   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "..        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "228  29802992   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "229  29839885   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "230  29842315   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "231  29858644   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "232  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "     957  981  982  983  987  988  \n",
       "0      0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  \n",
       "228    0    0    0    0    0    0  \n",
       "229    0    0    0    0    0    0  \n",
       "230    0    0    0    0    0    0  \n",
       "231    0    0    0    0    0    0  \n",
       "232    0    0    0    0    0    0  \n",
       "\n",
       "[233 rows x 241 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes = df_aggregated\n",
    "df_drgcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608348c3",
   "metadata": {},
   "source": [
    "### admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_admissions['subject_id'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7b666",
   "metadata": {},
   "source": [
    "To drop: subject_id, admittime, dischtime, deathtime, hospital_expire_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an ed_duration feature for edouttime - edregtime (how long the patient stayed in the emergency department)\n",
    "\n",
    "# Convert to datetime\n",
    "df_admissions['edouttime'] = pd.to_datetime(df_admissions['edouttime'], format='%d/%m/%Y %H:%M')\n",
    "df_admissions['edregtime'] = pd.to_datetime(df_admissions['edregtime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_admissions['ed_duration'] = df_admissions['edouttime'] - df_admissions['edregtime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_admissions['ed_duration'] = df_admissions['ed_duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admissions = df_admissions.drop(columns=['subject_id', 'admittime', 'dischtime', 'deathtime', 'hospital_expire_flag'\n",
    "                            , 'edregtime', 'edouttime', 'admit_provider_id','discharge_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null with N/A and then one hot encode\n",
    "df_admissions['marital_status'] = df_admissions['marital_status'].fillna('N/A')\n",
    "df_admissions = pd.get_dummies(df_admissions, columns=['admission_type', 'admission_location', \n",
    "                                                      'insurance','language', 'marital_status','race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cddf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd1052",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d506b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_admissions\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "admissions_data_train, admissions_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", admissions_data_train.shape)\n",
    "print(\"Testing set shape:\", admissions_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa131f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "admissions_data_train.to_csv('admissions_data_train.csv', index=False)\n",
    "admissions_data_test.to_csv('admissions_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71208a89",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d829cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d6953",
   "metadata": {},
   "source": [
    "### emar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ddfd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records for 65 different patients \n",
    "# 181 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76008ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/emar.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_emar = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23cf656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar.info()\n",
    "# print(df_emar.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10bca4",
   "metadata": {},
   "source": [
    "Impute with N/A and encode: enter_provider_id, medication\n",
    "\n",
    "Drop: subject_id, emar_id, poe_id, pharmacy_id, event_txt, storetime\n",
    "\n",
    "poe_id is an identifier which links administrations in emar to orders in poe and prescriptions\n",
    "storetime is when it was recorded in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature called delay using scheduletime - charttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_emar['scheduletime'] = pd.to_datetime(df_emar['scheduletime'], format='%Y/%m/%d %H:%M')\n",
    "df_emar['charttime'] = pd.to_datetime(df_emar['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_emar['delay'] = df_emar['charttime'] - df_emar['scheduletime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_emar['delay'] = df_emar['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9419c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar = df_emar.drop(columns=['subject_id','emar_id','poe_id','pharmacy_id',\n",
    "                               'event_txt','charttime','scheduletime','storetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efc81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null with N/A and then one hot encode\n",
    "df_emar['enter_provider_id'] = df_emar['enter_provider_id'].fillna('N/A')\n",
    "df_emar['medication'] = df_emar['medication'].fillna('N/A')\n",
    "df_emar = pd.get_dummies(df_emar, columns=['enter_provider_id', 'medication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a774a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar['delay'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebb578",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9a7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_emar\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "emar_data_train, emar_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", emar_data_train.shape)\n",
    "print(\"Testing set shape:\", emar_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c51cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "emar_data_train.to_csv('emar_data_train.csv', index=False)\n",
    "emar_data_test.to_csv('emar_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1b3a5",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1db930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ccf94",
   "metadata": {},
   "source": [
    "### emar_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c981640",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/emar_detail.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_emar_detail = pd.read_csv(full_path,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bea463",
   "metadata": {},
   "source": [
    "Fields that have lots of null values:\n",
    "reason_for_no_barcode: drop\n",
    "prior_infusion_rate: impute with zeroes\n",
    "infusion_rate: impute with zeroes\n",
    "infusion_rate_adjustment: impute with 'N/A', then one hot encoding\n",
    "infusion_rate_adjustment_amount: impute with zeroes\n",
    "infusion_rate_unit: impute with 'N/A', then one hot encoding\n",
    "infusion_complete: impute with 'N/A', then one hot encoding\n",
    "completion_interval: impute with 0, then ordinal encoding \n",
    "new_iv_bag_hung: impute with N, then binary encoding \n",
    "\n",
    "Text data to remove but maybe consider later:\n",
    "product_description, product_description_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail = df_emar_detail.drop(columns=['reason_for_no_barcode']) # Too hard to encode, adds not much value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with 0s\n",
    "df_emar_detail['prior_infusion_rate'] = df_emar_detail['prior_infusion_rate'].fillna(0)\n",
    "df_emar_detail['infusion_rate'] = df_emar_detail['infusion_rate'].fillna(0)\n",
    "df_emar_detail['infusion_rate_adjustment_amount'] = df_emar_detail['infusion_rate_adjustment_amount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_emar_detail['infusion_rate_adjustment'] = df_emar_detail['infusion_rate_adjustment'].fillna('N/A')\n",
    "df_emar_detail['infusion_rate_unit'] = df_emar_detail['infusion_rate_unit'].fillna('N/A')\n",
    "df_emar_detail['infusion_complete'] = df_emar_detail['infusion_complete'].fillna('N/A')\n",
    "df_emar_detail = pd.get_dummies(df_emar_detail, columns=['infusion_rate_adjustment','infusion_complete',\n",
    "                                                         'infusion_rate_unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].fillna(0)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('PRN', 0)\n",
    "#Converting all the intervals to minutes\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 2 hours', 120)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 4 hours', 240)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 1 hour', 60)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 1.5 hours', 90)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 8 hours', 480)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 15 minutes', 15)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 12 hours', 720)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 30 minutes', 30)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 24 hours', 1140)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 1 minutes', 1)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 14 hours', 840)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 7 hours', 420)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 5 hours', 300)\n",
    "df_emar_detail['completion_interval'] = df_emar_detail['completion_interval'].replace('within 3 hours', 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ae7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['new_iv_bag_hung'] = df_emar_detail['new_iv_bag_hung'].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding\n",
    "df_emar_detail['new_iv_bag_hung'] = df_emar_detail['new_iv_bag_hung'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and one hot encode:\n",
    "# administration_type\n",
    "# barcode_type\n",
    "# complete_dose_not_given\n",
    "# dose_due_unit\n",
    "# dose_given_unit\n",
    "# will_remainder_of_dose_be_given\n",
    "# product_unit\n",
    "# product_code\n",
    "# route\n",
    "# side\n",
    "# site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['administration_type'] = df_emar_detail['administration_type'].fillna('N/A')\n",
    "df_emar_detail['barcode_type'] = df_emar_detail['barcode_type'].fillna('N/A')\n",
    "df_emar_detail['complete_dose_not_given'] = df_emar_detail['complete_dose_not_given'].fillna('N/A')\n",
    "df_emar_detail['dose_due_unit'] = df_emar_detail['dose_due_unit'].fillna('N/A')\n",
    "df_emar_detail['dose_given_unit'] = df_emar_detail['dose_given_unit'].fillna('N/A')\n",
    "df_emar_detail['will_remainder_of_dose_be_given'] = df_emar_detail['will_remainder_of_dose_be_given'].fillna('N/A')\n",
    "df_emar_detail['product_unit'] = df_emar_detail['product_unit'].fillna('N/A')\n",
    "df_emar_detail['product_code'] = df_emar_detail['product_code'].fillna('N/A')\n",
    "df_emar_detail['route'] = df_emar_detail['route'].fillna('N/A')\n",
    "df_emar_detail['side'] = df_emar_detail['side'].fillna('N/A')\n",
    "df_emar_detail['site'] = df_emar_detail['site'].fillna('N/A')\n",
    "df_emar_detail = pd.get_dummies(df_emar_detail, columns=['administration_type','barcode_type','complete_dose_not_given',\n",
    "                                                        'dose_due_unit','dose_given_unit',\n",
    "                                                        'will_remainder_of_dose_be_given','product_unit','product_code',\n",
    "                                                        'route','side','site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with zeroes:\n",
    "# dose_due and dose_given, but also need to deal with some of them being ranges\n",
    "# product_amount_given\n",
    "# restart_interval, then ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7594bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['product_amount_given'] = df_emar_detail['product_amount_given'].fillna(0)\n",
    "df_emar_detail['dose_due'] = df_emar_detail['dose_due'].fillna(0)\n",
    "df_emar_detail['dose_given'] = df_emar_detail['dose_given'].fillna(0)\n",
    "df_emar_detail['restart_interval'] = df_emar_detail['restart_interval'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['dose_due'] = df_emar_detail['dose_due'].astype(str)\n",
    "df_emar_detail['dose_given'] = df_emar_detail['dose_given'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_middle_value(range_string):\n",
    "    if '-' in range_string:\n",
    "        start, end = map(float, range_string.split('-'))\n",
    "        return (start + end) / 2\n",
    "    else:\n",
    "        return range_string\n",
    "\n",
    "df_emar_detail['dose_due'] = df_emar_detail['dose_due'].apply(find_middle_value)\n",
    "df_emar_detail['dose_given'] = df_emar_detail['dose_given'].apply(find_middle_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['restart_interval'] = df_emar_detail['restart_interval'].replace('PRN', 0)\n",
    "#Converting all the intervals to minutes\n",
    "df_emar_detail['restart_interval'] = df_emar_detail['restart_interval'].replace('within 2 hours', 120)\n",
    "df_emar_detail['restart_interval'] = df_emar_detail['restart_interval'].replace('within 4 hours', 240)\n",
    "df_emar_detail['restart_interval'] = df_emar_detail['restart_interval'].replace('within 1 hour', 60)\n",
    "df_emar_detail['restart_interval'] = df_emar_detail['restart_interval'].replace('within 30 minutes', 30)\n",
    "df_emar_detail['restart_interval'] = df_emar_detail['restart_interval'].replace('within 24 hours', 1140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N and map to binary encoding:\n",
    "# continued_infusion_in_other_location\n",
    "# non_formulary_visual_verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['continued_infusion_in_other_location'] = df_emar_detail['continued_infusion_in_other_location'].fillna('N')\n",
    "df_emar_detail['non_formulary_visual_verification'] = df_emar_detail['non_formulary_visual_verification'].fillna('N')\n",
    "# Binary encoding\n",
    "df_emar_detail['continued_infusion_in_other_location'] = df_emar_detail['continued_infusion_in_other_location'].map({'Y': 1, 'N': 0})\n",
    "df_emar_detail['non_formulary_visual_verification'] = df_emar_detail['non_formulary_visual_verification'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail = df_emar_detail.drop(columns=['pharmacy_id']) # Contains NaN values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c80f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail = df_emar_detail.drop(columns=['emar_id']) # Practically unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01348878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace blanks with zero\n",
    "df_emar_detail['dose_due'] = df_emar_detail['dose_due'].replace('___', 0)\n",
    "df_emar_detail['dose_given'] = df_emar_detail['dose_given'].replace('___', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail['dose_due'] = df_emar_detail['dose_due'].astype(float)\n",
    "df_emar_detail['dose_given'] = df_emar_detail['dose_given'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b06e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A or 0\n",
    "# One hot encode the categorical features \n",
    "\n",
    "df_emar_detail['product_description'] = df_emar_detail['product_description'].fillna('N/A')\n",
    "df_emar_detail['product_description_other'] = df_emar_detail['product_description_other'].fillna('N/A')\n",
    "df_emar_detail['parent_field_ordinal'] = df_emar_detail['parent_field_ordinal'].fillna(0)\n",
    "df_emar_detail = pd.get_dummies(df_emar_detail, columns=['product_description_other','product_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emar_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a629de",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748caaf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_emar_detail\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "emar_detail_data_train, emar_detail_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", emar_detail_data_train.shape)\n",
    "print(\"Testing set shape:\", emar_detail_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69723ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "emar_detail_data_train.to_csv('emar_detail_data_train.csv', index=False)\n",
    "emar_detail_data_test.to_csv('emar_detail_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c39217",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b11516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658b118",
   "metadata": {},
   "source": [
    "### hcpcsevents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c18d3e",
   "metadata": {},
   "source": [
    "Contains info for 18 different patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_hcpcs has longer descriptions (connected by code) but no other useful info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/hcpcsevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_hcpcsevents = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcpcsevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient, admission, date, uniquely identifying billed code, sequence number, description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794be5d",
   "metadata": {},
   "source": [
    "To drop: subject_id, chartdate, hcpcs_cd (code that links to longer description in d_hcpcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f83c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcpcsevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49faa7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature for days_since_admission using chartdate - admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_hcpcsevents['chartdate'] = pd.to_datetime(df_hcpcsevents['chartdate'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_hcpcsevents = df_hcpcsevents.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# Discard the time part and keep only the date\n",
    "df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_hcpcsevents['days_since_admission'] = df_hcpcsevents['chartdate'] - df_hcpcsevents['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_hcpcsevents['days_since_admission'] = df_hcpcsevents['days_since_admission'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcpcsevents['days_since_admission'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcpcsevents = df_hcpcsevents.drop(columns=['subject_id','chartdate','hcpcs_cd'])\n",
    "# Not enough samples to include code as after encoding there would be a lot more features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae82538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcpcsevents = pd.get_dummies(df_hcpcsevents, columns=['short_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a339e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcpcsevents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5f1e1",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d107fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_hcpcsevents\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "hcpcsevents_data_train, hcpcsevents_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", hcpcsevents_data_train.shape)\n",
    "print(\"Testing set shape:\", hcpcsevents_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ffce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "hcpcsevents_data_train.to_csv('hcpcsevents_data_train.csv', index=False)\n",
    "hcpcsevents_data_test.to_csv('hcpcsevents_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f5c81",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 15 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dd936",
   "metadata": {},
   "source": [
    "### labevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information regarding 252 different admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39087c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/labevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_labevents = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents['value'] = pd.to_numeric(df_labevents['value'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca829786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents['storetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60785952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature for days_since_admission using charttime - admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['charttime'] = pd.to_datetime(df_labevents['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_labevents = df_labevents.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_labevents['days_since_admission'] = df_labevents['charttime'] - df_labevents['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['days_since_admission'] = df_labevents['days_since_admission'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069686c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add storetime - charttime feature called delay\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['storetime'] = pd.to_datetime(df_labevents['storetime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_labevents['delay'] = df_labevents['storetime'] - df_labevents['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['delay'] = df_labevents['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ecf60",
   "metadata": {},
   "source": [
    "Drop: labevent_id, subject_id, order_provider_id (too many Null), charttime, storetime, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03052b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = df_labevents.drop(columns=['labevent_id','subject_id','order_provider_id','charttime','storetime','comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For flag make abnormal = 1 and fill Null with 0\n",
    "df_labevents['flag'] = df_labevents['flag'].fillna(0)\n",
    "df_labevents['flag'] = df_labevents['flag'].replace('abnormal', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For priority fill Null with N/A and then one hot encode\n",
    "df_labevents['priority'] = df_labevents['priority'].fillna('N/A')\n",
    "df_labevents = pd.get_dummies(df_labevents, columns=['priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7430ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = pd.get_dummies(df_labevents, columns=['valueuom','specimen_id','itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6dcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null values \n",
    "df_labevents = df_labevents.dropna()\n",
    "# Reduced from 107727 rows to 66660"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a6e2f",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c3e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_labevents\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "labevents_data_train, labevents_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", labevents_data_train.shape)\n",
    "print(\"Testing set shape:\", labevents_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3742458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "labevents_data_train.to_csv('labevents_data_train.csv', index=False)\n",
    "labevents_data_test.to_csv('labevents_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac93c86",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 11681 to 10665"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39543660",
   "metadata": {},
   "source": [
    "### microbiologyevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/microbiologyevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_microbio = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed71851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461feda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make days_since_admission using charttime \n",
    "\n",
    "# Convert to datetime\n",
    "df_microbio['charttime'] = pd.to_datetime(df_microbio['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_microbio = df_microbio.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_microbio['days_since_admission'] = df_microbio['charttime'] - df_microbio['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_microbio['days_since_admission'] = df_microbio['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_microbio = df_microbio.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add storetime - charttime feature (call it delay)\n",
    "\n",
    "# Convert to datetime\n",
    "df_microbio['storetime'] = pd.to_datetime(df_microbio['storetime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_microbio['delay'] = df_microbio['storetime'] - df_microbio['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_microbio['delay'] = df_microbio['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffde6ec",
   "metadata": {},
   "source": [
    "Drop: microevent_id, subject_id, chartdate, charttime, test_seq, storedate, storetime, test_name and org_itemid (since info in name), quantity, ab_name, comments, micro_specimen_id (unique identifier for sample as some measurements are made on the same sample)\n",
    "Keep but categorical: order_provider_id, spec_type_desc, dilution_text, dilution_comparison\n",
    "Impute null with 0: order_provider_id, org_itemid, isolate_num, ab_itemid, dilution_value\n",
    "Impute with N/A and then one hot encode: interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b50d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "# spec_itemid , test_itemid\n",
    "df_microbio = df_microbio.drop(columns=['microevent_id','subject_id','chartdate','charttime','test_seq','storedate',\n",
    "                                       'storetime','quantity','comments','ab_itemid',\n",
    "                                       'spec_itemid','test_itemid','org_itemid','micro_specimen_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33adb9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute null with 0: order_provider_id, org_itemid, isolate_num, ab_itemid, dilution_value\n",
    "df_microbio['order_provider_id'] = df_microbio['order_provider_id'].fillna(0)\n",
    "df_microbio['isolate_num'] = df_microbio['isolate_num'].fillna(0)\n",
    "df_microbio['dilution_value'] = df_microbio['dilution_value'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f78ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and then one hot encode: interpretation\n",
    "# encode test_name, ab_name\n",
    "\n",
    "df_microbio['interpretation'] = df_microbio['interpretation'].fillna('N/A')\n",
    "df_microbio['test_name'] = df_microbio['test_name'].fillna('N/A')\n",
    "df_microbio['ab_name'] = df_microbio['ab_name'].fillna('N/A')\n",
    "df_microbio['org_name'] = df_microbio['org_name'].fillna('None')\n",
    "df_microbio = pd.get_dummies(df_microbio, columns=['org_name','interpretation','ab_name','test_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f754dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep but categorical: order_provider_id, spec_type_desc, dilution_text, dilution_comparison\n",
    "df_microbio = pd.get_dummies(df_microbio, columns=['order_provider_id','spec_type_desc','dilution_text',\n",
    "                                                  'dilution_comparison'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio = df_microbio.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a963751",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654c85e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_microbio\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "microbio_data_train, microbio_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", microbio_data_train.shape)\n",
    "print(\"Testing set shape:\", microbio_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "microbio_data_train.to_csv('microbio_data_train.csv', index=False)\n",
    "microbio_data_test.to_csv('microbio_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "microbio_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b50bbd",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb8cdd",
   "metadata": {},
   "source": [
    "### patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/patients.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_patients = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9922481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients['anchor_age'].value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12203d8a",
   "metadata": {},
   "source": [
    "Drop: anchor_year\n",
    "Encode: gender (M to 0 and F to 1), dod (change all to 1 and nulls to 0)\n",
    "Dummies: anchor_year_group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7220553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "df_patients = df_patients.drop(columns=['anchor_year','dod']) \n",
    "# Since this is the shifted year and dod is an outcome value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode: gender (M to 0 and F to 1), dod (change all to 1 and nulls to 0)\n",
    "df_patients['gender'] = df_patients['gender'].replace('M', 0)\n",
    "df_patients['gender'] = df_patients['gender'].replace('F', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies: anchor_year_group  \n",
    "df_patients = pd.get_dummies(df_patients, columns=['anchor_year_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042beba",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d674b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_patients\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "patients_data_train, patients_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", patients_data_train.shape)\n",
    "print(\"Testing set shape:\", patients_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "patients_data_train.to_csv('patients_data_train.csv', index=False)\n",
    "patients_data_test.to_csv('patients_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5371472",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f419664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ad2dd",
   "metadata": {},
   "source": [
    "### pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/pharmacy.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_pharmacy = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharmacy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178eef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharmacy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648db89",
   "metadata": {},
   "source": [
    "drop: subject_id, pharmacy_id, poe_id, starttime, stoptime, entertime, verifiedtime, disp_sched, basal_rate, one_hr_max,\n",
    "expirationdate, fill_quantity\n",
    "Encode: proc_type, status\n",
    "Impute with N/A and encode: infusion_type, sliding_scale, duration_interval, expiration_unit, dispensation, medication, route, frequency\n",
    "Impute with 0: lockout_interval, doses_per_24_hrs, duration, expiration_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoptime-starttime for a duration feature\n",
    "\n",
    "# Convert to datetime\n",
    "df_pharmacy['stoptime'] = pd.to_datetime(df_pharmacy['stoptime'], format='%Y/%m/%d %H:%M')\n",
    "df_pharmacy['starttime'] = pd.to_datetime(df_pharmacy['starttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "\n",
    "df_pharmacy['medication_duration'] = df_pharmacy['stoptime'] - df_pharmacy['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_pharmacy['medication_duration'] = df_pharmacy['medication_duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiedtime - entertime for verification_delay feature \n",
    "\n",
    "# Convert to datetime\n",
    "df_pharmacy['verifiedtime'] = pd.to_datetime(df_pharmacy['verifiedtime'], format='%Y/%m/%d %H:%M')\n",
    "df_pharmacy['entertime'] = pd.to_datetime(df_pharmacy['entertime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_pharmacy['verification_delay'] = df_pharmacy['verifiedtime'] - df_pharmacy['entertime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_pharmacy['verification_delay'] = df_pharmacy['verification_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_value = [0] \n",
    "\n",
    "# Fill null values with the list\n",
    "df_pharmacy['disp_sched'] = df_pharmacy['disp_sched'].fillna(pd.Series([fill_value]*len(df_pharmacy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f594f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categories to strings\n",
    "df_pharmacy['disp_sched'] = df_pharmacy['disp_sched'].apply(lambda x: [str(item) for item in x])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "encoded_feature = pd.DataFrame(mlb.fit_transform(df_pharmacy['disp_sched']),\n",
    "                               columns=mlb.classes_,\n",
    "                               index=df_pharmacy.index)\n",
    "\n",
    "df_pharmacy = pd.concat([df_pharmacy, encoded_feature], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_pharmacy = df_pharmacy.drop(columns=['subject_id','pharmacy_id','poe_id','starttime','stoptime','entertime',\n",
    "                                       'verifiedtime','expirationdate', 'fill_quantity','disp_sched'])\n",
    "# expiration date and fill quantity are all empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode: proc_type, status\n",
    "df_pharmacy = pd.get_dummies(df_pharmacy, columns=['proc_type','status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11172fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_pharmacy['infusion_type'] = df_pharmacy['infusion_type'].fillna('N/A')\n",
    "df_pharmacy['sliding_scale'] = df_pharmacy['sliding_scale'].fillna('N/A')\n",
    "df_pharmacy['duration_interval'] = df_pharmacy['duration_interval'].fillna('N/A')\n",
    "df_pharmacy['expiration_unit'] = df_pharmacy['expiration_unit'].fillna('N/A')\n",
    "df_pharmacy['dispensation'] = df_pharmacy['dispensation'].fillna('N/A')\n",
    "df_pharmacy['medication'] = df_pharmacy['medication'].fillna('N/A')\n",
    "df_pharmacy['route'] = df_pharmacy['route'].fillna('N/A')\n",
    "df_pharmacy['frequency'] = df_pharmacy['frequency'].fillna('N/A')\n",
    "df_pharmacy = pd.get_dummies(df_pharmacy, columns=['infusion_type','sliding_scale','duration_interval','expiration_unit',\n",
    "                                                  'dispensation','medication','route','frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61180b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with 0: lockout_interval, doses_per_24_hrs, duration, expiration_value\n",
    "df_pharmacy['lockout_interval'] = df_pharmacy['lockout_interval'].fillna(0)\n",
    "df_pharmacy['doses_per_24_hrs'] = df_pharmacy['doses_per_24_hrs'].fillna(0)\n",
    "df_pharmacy['expiration_value'] = df_pharmacy['expiration_value'].fillna(0)\n",
    "df_pharmacy['basal_rate'] = df_pharmacy['basal_rate'].fillna(0)\n",
    "df_pharmacy['one_hr_max'] = df_pharmacy['one_hr_max'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2f39d",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede12649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_pharmacy\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "pharmacy_data_train, pharmacy_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", pharmacy_data_train.shape)\n",
    "print(\"Testing set shape:\", pharmacy_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "pharmacy_data_train.to_csv('pharmacy_data_train.csv', index=False)\n",
    "pharmacy_data_test.to_csv('pharmacy_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1c40c",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1fa18",
   "metadata": {},
   "source": [
    "### poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/poe.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_poe = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc090da",
   "metadata": {},
   "source": [
    "To drop: poe_id, subject_id, ordertime, discontinue_of_poe_id, discontinued_by_poe_id (all unique), order_status (all inactive)\n",
    "Encode: order_type, transaction_type\n",
    "Impute with N/A and then encode: order_subtype, order_provider_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5dafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a feature of ordertime - admittime for days_since_admission\n",
    "\n",
    "# Convert to datetime\n",
    "df_poe['ordertime'] = pd.to_datetime(df_poe['ordertime'], format='%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_poe = df_poe.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_poe['days_since_admission'] = df_poe['ordertime'] - df_poe['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_poe['days_since_admission'] = df_poe['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_poe = df_poe.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_poe = df_poe.drop(columns=['poe_id','subject_id','ordertime','discontinue_of_poe_id','discontinued_by_poe_id',\n",
    "                                       'order_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "df_poe = pd.get_dummies(df_poe, columns=['order_type','transaction_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820cbf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_poe['order_subtype'] = df_poe['order_subtype'].fillna('N/A')\n",
    "df_poe['order_provider_id'] = df_poe['order_provider_id'].fillna('N/A')\n",
    "df_poe = pd.get_dummies(df_poe, columns=['order_subtype','order_provider_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c2add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebe71f",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ba4a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_poe\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "poe_data_train, poe_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", poe_data_train.shape)\n",
    "print(\"Testing set shape:\", poe_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb068f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "poe_data_train.to_csv('poe_data_train.csv', index=False)\n",
    "poe_data_test.to_csv('poe_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d429156",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0adbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bb935",
   "metadata": {},
   "source": [
    "### prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ada77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/prescriptions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_prescriptions = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prescriptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed596e",
   "metadata": {},
   "source": [
    "Drop na and encode: dose_val_rx, form_val_disp, order_provider_id\n",
    "Drop: subject_id, pharmacy_id, starttime, stoptime, form_rx (mostly null), poe_id\n",
    "Impute with N/A and encode: formulary_drug_cd, gsn, prod_strength, route\n",
    "Encode: drug_type, drug, dose_unit_rx, form_unit_disp\n",
    "Impute with 0: doses_per_24_hrs\n",
    "\n",
    "Drop rows with na\n",
    "\n",
    "order_provider_id\n",
    "Was going to impute with N/A and encode but going to drop as too many features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature of stoptime-starttime called duration \n",
    "\n",
    "# Convert to datetime\n",
    "df_prescriptions['stoptime'] = pd.to_datetime(df_prescriptions['stoptime'], format='%Y/%m/%d %H:%M')\n",
    "df_prescriptions['starttime'] = pd.to_datetime(df_prescriptions['starttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_prescriptions['duration'] = df_prescriptions['stoptime'] - df_prescriptions['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_prescriptions['duration'] = df_prescriptions['duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d367cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop na\n",
    "df_prescriptions.dropna(subset=['dose_val_rx', 'form_val_disp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbefe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_prescriptions = df_prescriptions.drop(columns=['subject_id','pharmacy_id','starttime','stoptime','form_rx','poe_id',\n",
    "                                                 'order_provider_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b364333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_prescriptions['formulary_drug_cd'] = df_prescriptions['formulary_drug_cd'].fillna('N/A')\n",
    "df_prescriptions['gsn'] = df_prescriptions['gsn'].fillna('N/A')\n",
    "df_prescriptions['prod_strength'] = df_prescriptions['prod_strength'].fillna('N/A')\n",
    "df_prescriptions['route'] = df_prescriptions['route'].fillna('N/A')\n",
    "\n",
    "# Impute with 0\n",
    "df_prescriptions['ndc'] = df_prescriptions['ndc'].fillna(0)\n",
    "\n",
    "df_prescriptions = pd.get_dummies(df_prescriptions, columns=['formulary_drug_cd','gsn','prod_strength',\n",
    "                                                            'route','drug_type','drug','dose_unit_rx','form_unit_disp',\n",
    "                                                            'dose_val_rx','form_val_disp','ndc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prescriptions['doses_per_24_hrs'] = df_prescriptions['doses_per_24_hrs'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null values \n",
    "df_prescriptions = df_prescriptions.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ae675",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab54e80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_prescriptions\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "prescriptions_data_train, prescriptions_data_test= train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", prescriptions_data_train.shape)\n",
    "print(\"Testing set shape:\", prescriptions_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "prescriptions_data_train.to_csv('prescriptions_data_train.csv', index=False)\n",
    "prescriptions_data_test.to_csv('prescriptions_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b32ff",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28492dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 4890 to 2874 or less"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3341ac",
   "metadata": {},
   "source": [
    "### procedures_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/procedures_icd.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_procedures = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545710a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedures['icd_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d1e4ae",
   "metadata": {},
   "source": [
    "Drop: subject_id, chartdate\n",
    "Encode: icd_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf864de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a feature called days_since_admission of chartdate - admitdate\n",
    "\n",
    "# Convert to datetime\n",
    "df_procedures['chartdate'] = pd.to_datetime(df_procedures['chartdate'], format='%Y-%m-%d')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_procedures = df_procedures.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "df_procedures['admittime'] = df_procedures['admittime'].dt.date\n",
    "df_procedures['chartdate'] = df_procedures['chartdate'].dt.date\n",
    "\n",
    "df_procedures['days_since_admission'] = df_procedures['chartdate'] - df_procedures['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_procedures['days_since_admission'] = df_procedures['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_procedures = df_procedures.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df385e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_procedures = df_procedures.drop(columns=['subject_id','chartdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622fd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "df_procedures = pd.get_dummies(df_procedures, columns=['icd_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4ba50",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb03ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_procedures\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "procedures_data_train, procedures_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", procedures_data_train.shape)\n",
    "print(\"Testing set shape:\", procedures_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "procedures_data_train.to_csv('procedures_data_train.csv', index=False)\n",
    "procedures_data_test.to_csv('procedures_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93521dd1",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 355 to 115"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc9661",
   "metadata": {},
   "source": [
    "### services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/services.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_services = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_services.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c32b",
   "metadata": {},
   "source": [
    "Drop: subject_id, transfertime\n",
    "Impute with N/A and encode: prev_service\n",
    "Encode: curr_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature called days_since_admission using transfertime-admittime \n",
    "\n",
    "# Convert to datetime\n",
    "df_services['transfertime'] = pd.to_datetime(df_services['transfertime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_services = df_services.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_services['days_since_admission'] = df_services['transfertime'] - df_services['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_services['days_since_admission'] = df_services['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_services = df_services.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d765fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_services = df_services.drop(columns=['subject_id','transfertime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a352cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_services['prev_service'] = df_services['prev_service'].fillna('N/A')\n",
    "df_services = pd.get_dummies(df_services, columns=['prev_service','curr_service'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea60ac",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b462d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_services\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "services_data_train, services_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", services_data_train.shape)\n",
    "print(\"Testing set shape:\", services_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf636d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "services_data_train.to_csv('services_data_train.csv', index=False)\n",
    "services_data_test.to_csv('services_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e8414",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c0b28",
   "metadata": {},
   "source": [
    "### transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/transfers.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_transfers = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transfers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2565229",
   "metadata": {},
   "source": [
    "Drop: subject_id, transfer_id, intime, outtime\n",
    "Encode: eventtype\n",
    "Impute with N/A and encode: careunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a days_since_admission feature of intime-admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_transfers['intime'] = pd.to_datetime(df_transfers['intime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_transfers = df_transfers.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "df_transfers['days_since_admission'] = df_transfers['intime'] - df_transfers['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_transfers['days_since_admission'] = df_transfers['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_transfers = df_transfers.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a duration feature of outtime-intime \n",
    "\n",
    "# Convert to datetime\n",
    "df_transfers['outtime'] = pd.to_datetime(df_transfers['outtime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_transfers['duration'] = df_transfers['outtime'] - df_transfers['intime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_transfers['duration'] = df_transfers['duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567492b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_transfers = df_transfers.drop(columns=['subject_id','transfer_id','intime','outtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_transfers['careunit'] = df_transfers['careunit'].fillna('N/A')\n",
    "df_transfers = pd.get_dummies(df_transfers, columns=['eventtype','careunit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653b3d8",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9f2d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_transfers\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "transfers_data_train, transfers_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", transfers_data_train.shape)\n",
    "print(\"Testing set shape:\", transfers_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19195cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "transfers_data_train.to_csv('transfers_data_train.csv', index=False)\n",
    "transfers_data_test.to_csv('transfers_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e47613",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e4c106",
   "metadata": {},
   "source": [
    "### chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc097ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/chartevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_chart = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b9a085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227969    19330\n",
       "220045    13913\n",
       "220210    13913\n",
       "220277    13540\n",
       "220048    12460\n",
       "          ...  \n",
       "229448        1\n",
       "227847        1\n",
       "229592        1\n",
       "225743        1\n",
       "229160        1\n",
       "Name: itemid, Length: 1318, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chart['itemid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6a2a5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>caregiver_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>itemid</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>warning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10005817</td>\n",
       "      <td>20626031</td>\n",
       "      <td>32604416</td>\n",
       "      <td>6770.0</td>\n",
       "      <td>2132-12-16 00:00:00</td>\n",
       "      <td>2132-12-15 23:45:00</td>\n",
       "      <td>225054</td>\n",
       "      <td>On</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10005817</td>\n",
       "      <td>20626031</td>\n",
       "      <td>32604416</td>\n",
       "      <td>6770.0</td>\n",
       "      <td>2132-12-16 00:00:00</td>\n",
       "      <td>2132-12-15 23:43:00</td>\n",
       "      <td>223769</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10005817</td>\n",
       "      <td>20626031</td>\n",
       "      <td>32604416</td>\n",
       "      <td>6770.0</td>\n",
       "      <td>2132-12-16 00:00:00</td>\n",
       "      <td>2132-12-15 23:47:00</td>\n",
       "      <td>223956</td>\n",
       "      <td>Atrial demand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005817</td>\n",
       "      <td>20626031</td>\n",
       "      <td>32604416</td>\n",
       "      <td>6770.0</td>\n",
       "      <td>2132-12-16 00:00:00</td>\n",
       "      <td>2132-12-15 23:47:00</td>\n",
       "      <td>224866</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005817</td>\n",
       "      <td>20626031</td>\n",
       "      <td>32604416</td>\n",
       "      <td>6770.0</td>\n",
       "      <td>2132-12-16 00:00:00</td>\n",
       "      <td>2132-12-15 23:45:00</td>\n",
       "      <td>227341</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   stay_id  caregiver_id            charttime  \\\n",
       "0    10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
       "1    10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
       "2    10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
       "3    10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
       "4    10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
       "\n",
       "             storetime  itemid          value  valuenum valueuom  warning  \n",
       "0  2132-12-15 23:45:00  225054            On        NaN      NaN      0.0  \n",
       "1  2132-12-15 23:43:00  223769            100     100.0        %      0.0  \n",
       "2  2132-12-15 23:47:00  223956  Atrial demand       NaN      NaN      0.0  \n",
       "3  2132-12-15 23:47:00  224866            Yes       NaN      NaN      0.0  \n",
       "4  2132-12-15 23:45:00  227341             No       0.0      NaN      0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d98b9d",
   "metadata": {},
   "source": [
    "Drop: subject_id, charttime, storetime, stay_id, caregiver_id (the person who documented the data)\n",
    "Encode: value,itemid\n",
    "Impute with 0: valuenum, warning\n",
    "Impute with N/A and encode: valueuom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a738bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a days_since_admission feature of charttime-admittime \n",
    "\n",
    "# Convert to datetime\n",
    "df_chart['charttime'] = pd.to_datetime(df_chart['charttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_chart = df_chart.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_chart['days_since_admission'] = df_chart['charttime'] - df_chart['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_chart['days_since_admission'] = df_chart['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_chart = df_chart.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5684379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a delay feature of storetime-charttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_chart['storetime'] = pd.to_datetime(df_chart['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_chart['delay'] = df_chart['storetime'] - df_chart['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_chart['delay'] = df_chart['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df7ed761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_chart = df_chart.drop(columns=['subject_id','charttime','storetime', 'stay_id','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d19afceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.64 GiB for an array with shape (4242, 668862) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Impute with N/A and encode\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_chart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalueuom\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_chart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalueuom\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df_chart \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_chart, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalueuom\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitemid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:202\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    192\u001b[0m         dummy \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    193\u001b[0m             col[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    194\u001b[0m             prefix\u001b[38;5;241m=\u001b[39mpre,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    201\u001b[0m         with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[1;32m--> 202\u001b[0m     result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     result \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    205\u001b[0m         data,\n\u001b[0;32m    206\u001b[0m         prefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    212\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:212\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    210\u001b[0m values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m--> 212\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.64 GiB for an array with shape (4242, 668862) and data type uint8"
     ]
    }
   ],
   "source": [
    "# Impute with N/A and encode\n",
    "df_chart['valueuom'] = df_chart['valueuom'].fillna('N/A')\n",
    "df_chart = pd.get_dummies(df_chart, columns=['valueuom','value','itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with 0\n",
    "df_chart['valuenum'] = df_chart['valuenum'].fillna(0)\n",
    "df_chart['warning'] = df_chart['warning'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_chart.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe470a",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ab4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df_chart\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "chart_data_train, chart_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", chart_data_train.shape)\n",
    "print(\"Testing set shape:\", chart_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfe4f13a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chart_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# uncomment and run if changes are made\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m chart_data_train\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchart_data_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m chart_data_test\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchart_data_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chart_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "chart_data_train.to_csv('chart_data_train.csv', index=False)\n",
    "chart_data_test.to_csv('chart_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80079d25",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f492f",
   "metadata": {},
   "source": [
    "### icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2d51b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/icustays.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_icustays = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58a3df93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>last_careunit</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10018328</td>\n",
       "      <td>23786647</td>\n",
       "      <td>31269608</td>\n",
       "      <td>Neuro Stepdown</td>\n",
       "      <td>Neuro Stepdown</td>\n",
       "      <td>2154-04-24 23:03:44</td>\n",
       "      <td>2154-05-02 15:55:21</td>\n",
       "      <td>7.702512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10020187</td>\n",
       "      <td>24104168</td>\n",
       "      <td>37509585</td>\n",
       "      <td>Neuro Surgical Intensive Care Unit (Neuro SICU)</td>\n",
       "      <td>Neuro Stepdown</td>\n",
       "      <td>2169-01-15 04:56:00</td>\n",
       "      <td>2169-01-20 15:47:50</td>\n",
       "      <td>5.452662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10020187</td>\n",
       "      <td>26842957</td>\n",
       "      <td>32554129</td>\n",
       "      <td>Neuro Intermediate</td>\n",
       "      <td>Neuro Intermediate</td>\n",
       "      <td>2170-02-24 18:18:46</td>\n",
       "      <td>2170-02-25 15:15:26</td>\n",
       "      <td>0.872685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10012853</td>\n",
       "      <td>27882036</td>\n",
       "      <td>31338022</td>\n",
       "      <td>Trauma SICU (TSICU)</td>\n",
       "      <td>Trauma SICU (TSICU)</td>\n",
       "      <td>2176-11-26 02:34:49</td>\n",
       "      <td>2176-11-29 20:58:54</td>\n",
       "      <td>3.766725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10020740</td>\n",
       "      <td>25826145</td>\n",
       "      <td>32145159</td>\n",
       "      <td>Trauma SICU (TSICU)</td>\n",
       "      <td>Trauma SICU (TSICU)</td>\n",
       "      <td>2150-06-03 20:12:32</td>\n",
       "      <td>2150-06-04 21:05:58</td>\n",
       "      <td>1.037106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   stay_id  \\\n",
       "0    10018328  23786647  31269608   \n",
       "1    10020187  24104168  37509585   \n",
       "2    10020187  26842957  32554129   \n",
       "3    10012853  27882036  31338022   \n",
       "4    10020740  25826145  32145159   \n",
       "\n",
       "                                    first_careunit        last_careunit  \\\n",
       "0                                   Neuro Stepdown       Neuro Stepdown   \n",
       "1  Neuro Surgical Intensive Care Unit (Neuro SICU)       Neuro Stepdown   \n",
       "2                               Neuro Intermediate   Neuro Intermediate   \n",
       "3                              Trauma SICU (TSICU)  Trauma SICU (TSICU)   \n",
       "4                              Trauma SICU (TSICU)  Trauma SICU (TSICU)   \n",
       "\n",
       "                intime              outtime       los  \n",
       "0  2154-04-24 23:03:44  2154-05-02 15:55:21  7.702512  \n",
       "1  2169-01-15 04:56:00  2169-01-20 15:47:50  5.452662  \n",
       "2  2170-02-24 18:18:46  2170-02-25 15:15:26  0.872685  \n",
       "3  2176-11-26 02:34:49  2176-11-29 20:58:54  3.766725  \n",
       "4  2150-06-03 20:12:32  2150-06-04 21:05:58  1.037106  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_icustays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a97bf492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2154-05-02 15:55:21    1\n",
       "2141-12-18 14:16:17    1\n",
       "2137-10-14 17:08:34    1\n",
       "2118-11-19 20:34:51    1\n",
       "2120-05-14 16:28:21    1\n",
       "                      ..\n",
       "2150-03-28 22:20:47    1\n",
       "2129-01-05 14:11:03    1\n",
       "2156-04-26 18:58:41    1\n",
       "2131-03-08 18:30:38    1\n",
       "2177-03-29 18:03:36    1\n",
       "Name: outtime, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_icustays['outtime'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b03ca",
   "metadata": {},
   "source": [
    "Drop: subject_id, stay_id, intime, outtime\n",
    "Encode: first_careunit, last_careunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e68baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a feature called days_since_admission using intime-admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_icustays['intime'] = pd.to_datetime(df_icustays['intime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_icustays = df_icustays.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_icustays['days_since_admission'] = df_icustays['intime'] - df_icustays['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_icustays['days_since_admission'] = df_icustays['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_icustays = df_icustays.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d0adc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_icustays = df_icustays.drop(columns=['subject_id','stay_id','intime','outtime'])\n",
    "\n",
    "# Rename los to icu_los\n",
    "df_icustays = df_icustays.rename(columns={'los': 'icu_los'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2d02448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "df_icustays = pd.get_dummies(df_icustays, columns=['first_careunit','last_careunit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b9028",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb4ceb1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (112, 21)\n",
      "Testing set shape: (28, 21)\n"
     ]
    }
   ],
   "source": [
    "data = df_icustays\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "icustays_data_train, icustays_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", icustays_data_train.shape)\n",
    "print(\"Testing set shape:\", icustays_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf6ffe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "icustays_data_train.to_csv('icustays_data_train.csv', index=False)\n",
    "icustays_data_test.to_csv('icustays_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ccb624",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509a270",
   "metadata": {},
   "source": [
    "### ingredientevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b471e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/ingredientevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_ingredient = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a037775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25728 entries, 0 to 25727\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   subject_id         25728 non-null  int64  \n",
      " 1   hadm_id            25728 non-null  int64  \n",
      " 2   stay_id            25728 non-null  int64  \n",
      " 3   caregiver_id       25728 non-null  int64  \n",
      " 4   starttime          25728 non-null  object \n",
      " 5   endtime            25728 non-null  object \n",
      " 6   storetime          25728 non-null  object \n",
      " 7   itemid             25728 non-null  int64  \n",
      " 8   amount             25728 non-null  float64\n",
      " 9   amountuom          25728 non-null  object \n",
      " 10  rate               16643 non-null  float64\n",
      " 11  rateuom            16643 non-null  object \n",
      " 12  orderid            25728 non-null  int64  \n",
      " 13  linkorderid        25728 non-null  int64  \n",
      " 14  statusdescription  25728 non-null  object \n",
      " 15  originalamount     25728 non-null  int64  \n",
      " 16  originalrate       25728 non-null  float64\n",
      "dtypes: float64(3), int64(8), object(6)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ingredient.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54437de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2132-12-17 06:01:00\n",
       "1        2132-12-17 06:01:00\n",
       "2        2132-12-17 12:48:00\n",
       "3        2132-12-17 12:48:00\n",
       "4        2132-12-15 16:42:00\n",
       "                ...         \n",
       "25723    2153-03-28 23:22:00\n",
       "25724    2153-03-28 02:58:00\n",
       "25725    2153-03-28 02:58:00\n",
       "25726    2153-03-29 20:58:00\n",
       "25727    2153-03-29 20:58:00\n",
       "Name: storetime, Length: 25728, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ingredient['storetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a7f9a",
   "metadata": {},
   "source": [
    "Drop: subject_id, starttime, endtime, storetime, orderid, originalamount, stay_id, caregiver_id\n",
    "Encode: amountuom, statusdescription, itemid\n",
    "Impute with 0: rate\n",
    "Impute with N/A and encode: rateuom, linkorderid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3505177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a duration feature of endtime-starttime \n",
    "\n",
    "# Convert to datetime\n",
    "df_ingredient['endtime'] = pd.to_datetime(df_ingredient['endtime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_ingredient['starttime'] = pd.to_datetime(df_ingredient['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "df_ingredient['duration'] = df_ingredient['endtime'] - df_ingredient['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_ingredient['duration'] = df_ingredient['duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ec2d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a recording_delay feature of storetime-endtime\n",
    "\n",
    "# Convert to datetime\n",
    "df_ingredient['storetime'] = pd.to_datetime(df_ingredient['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_ingredient['recording_delay'] = df_ingredient['storetime'] - df_ingredient['endtime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_ingredient['recording_delay'] = df_ingredient['recording_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cd0ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_ingredient = df_ingredient.drop(columns=['subject_id','starttime','endtime','storetime','orderid','originalamount',\n",
    "                                           'stay_id','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bd5aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_ingredient['rateuom'] = df_ingredient['rateuom'].fillna('N/A')\n",
    "df_ingredient['linkorderid'] = df_ingredient['linkorderid'].fillna('N/A')\n",
    "df_ingredient = pd.get_dummies(df_ingredient, columns=['rateuom','amountuom','statusdescription','itemid','linkorderid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c3b49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with 0\n",
    "df_ingredient['rate'] = df_ingredient['rate'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c996b8c",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5f3166c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (20582, 7729)\n",
      "Testing set shape: (5146, 7729)\n"
     ]
    }
   ],
   "source": [
    "data = df_ingredient\n",
    "# Split the dataset into training and testing sets\n",
    "ingredient_data_train, ingredient_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", ingredient_data_train.shape)\n",
    "print(\"Testing set shape:\", ingredient_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf8b9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "ingredient_data_train.to_csv('ingredient_data_train.csv', index=False)\n",
    "ingredient_data_test.to_csv('ingredient_data_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544db7e6",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beec90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 7727 to 4116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1b0f6",
   "metadata": {},
   "source": [
    "### inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2f8bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/inputevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_input = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2272fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20404 entries, 0 to 20403\n",
      "Data columns (total 26 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   subject_id                     20404 non-null  int64  \n",
      " 1   hadm_id                        20404 non-null  int64  \n",
      " 2   stay_id                        20404 non-null  int64  \n",
      " 3   caregiver_id                   20404 non-null  int64  \n",
      " 4   starttime                      20404 non-null  object \n",
      " 5   endtime                        20404 non-null  object \n",
      " 6   storetime                      20404 non-null  object \n",
      " 7   itemid                         20404 non-null  int64  \n",
      " 8   amount                         20404 non-null  float64\n",
      " 9   amountuom                      20404 non-null  object \n",
      " 10  rate                           11038 non-null  float64\n",
      " 11  rateuom                        11038 non-null  object \n",
      " 12  orderid                        20404 non-null  int64  \n",
      " 13  linkorderid                    20404 non-null  int64  \n",
      " 14  ordercategoryname              20404 non-null  object \n",
      " 15  secondaryordercategoryname     14144 non-null  object \n",
      " 16  ordercomponenttypedescription  20404 non-null  object \n",
      " 17  ordercategorydescription       20404 non-null  object \n",
      " 18  patientweight                  20404 non-null  float64\n",
      " 19  totalamount                    17090 non-null  float64\n",
      " 20  totalamountuom                 17092 non-null  object \n",
      " 21  isopenbag                      20404 non-null  int64  \n",
      " 22  continueinnextdept             20404 non-null  int64  \n",
      " 23  statusdescription              20404 non-null  object \n",
      " 24  originalamount                 20404 non-null  float64\n",
      " 25  originalrate                   20404 non-null  float64\n",
      "dtypes: float64(6), int64(9), object(11)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_input.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662c45c",
   "metadata": {},
   "source": [
    "Drop: subject_id, starttime, endtime, storetime, orderid, linkorderid, continueinnextdept, stay_id, caregiver_id,\n",
    "totalamountuom\n",
    "Encode: amountuom, ordercategoryname, ordercomponenttypedescription, ordercategorydescription, statusdescription, itemid\n",
    "Impute with 0: rate, totalamount\n",
    "Impute with N/A and encode: rateuom, secondaryordercategoryname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9663a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a duration feature using endtime-starttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_input['endtime'] = pd.to_datetime(df_input['endtime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_input['starttime'] = pd.to_datetime(df_input['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "df_input['duration'] = df_input['endtime'] - df_input['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_input['duration'] = df_input['duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bd3b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a recording_delay feature using storetime-endtime\n",
    "\n",
    "# Convert to datetime\n",
    "df_input['storetime'] = pd.to_datetime(df_input['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_input['recording_delay'] = df_input['storetime'] - df_input['endtime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_input['recording_delay'] = df_input['recording_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aba4714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_input = df_input.drop(columns=['subject_id','stay_id','starttime','endtime','storetime','orderid','linkorderid',\n",
    "                                  'continueinnextdept','totalamountuom', 'stay_id','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af90068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_input['rateuom'] = df_input['rateuom'].fillna('N/A')\n",
    "df_input['secondaryordercategoryname'] = df_input['secondaryordercategoryname'].fillna('N/A')\n",
    "df_input = pd.get_dummies(df_input, columns=['rateuom','secondaryordercategoryname','amountuom','ordercategoryname',\n",
    "                                            'ordercomponenttypedescription','ordercategorydescription','statusdescription',\n",
    "                                            'itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb4c6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with 0\n",
    "df_input['rate'] = df_input['rate'].fillna(0)\n",
    "df_input['totalamount'] = df_input['totalamount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fce9432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_input.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b05792",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af1d8149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (16323, 222)\n",
      "Testing set shape: (4081, 222)\n"
     ]
    }
   ],
   "source": [
    "data = df_input\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "input_data_train, input_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", input_data_train.shape)\n",
    "print(\"Testing set shape:\", input_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccf63a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "input_data_train.to_csv('input_data_train.csv', index=False)\n",
    "input_data_test.to_csv('input_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dfb7de",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc11f4",
   "metadata": {},
   "source": [
    "### outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27810950",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/outputevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_output = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709537d6",
   "metadata": {},
   "source": [
    "Drop: subject_id, charttime, storetime, valueuom, stay_id, caregiver_id'\n",
    "Encode: itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cab39c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a days_since_admission feature using charttime-admittime \n",
    "\n",
    "# Convert to datetime\n",
    "df_output['charttime'] = pd.to_datetime(df_output['charttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_output = df_output.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "df_output['days_since_admission'] = df_output['charttime'] - df_output['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_output['days_since_admission'] = df_output['days_since_admission'].fillna(pd.Timedelta(0))\n",
    "\n",
    "# Drop the admission time column\n",
    "df_output = df_output.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a5e32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a recording_delay feature using storetime-charttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_output['storetime'] = pd.to_datetime(df_output['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_output['recording_delay'] = df_output['storetime'] - df_output['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_output['recording_delay'] = df_output['recording_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8aff93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_output = df_output.drop(columns=['subject_id','stay_id','charttime','storetime','storetime','valueuom','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00509966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode\n",
    "df_output = pd.get_dummies(df_output, columns=['itemid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193906d",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a2a70a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (7489, 43)\n",
      "Testing set shape: (1873, 43)\n"
     ]
    }
   ],
   "source": [
    "data = df_output\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "output_data_train, output_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", output_data_train.shape)\n",
    "print(\"Testing set shape:\", output_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da8020e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "output_data_train.to_csv('output_data_train.csv', index=False)\n",
    "output_data_test.to_csv('output_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbedaa",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e151a754",
   "metadata": {},
   "source": [
    "### procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6eb562c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"icu/procedureevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_procedure_events = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a737a0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1468 entries, 0 to 1467\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   subject_id                1468 non-null   int64  \n",
      " 1   hadm_id                   1468 non-null   int64  \n",
      " 2   stay_id                   1468 non-null   int64  \n",
      " 3   caregiver_id              1226 non-null   float64\n",
      " 4   starttime                 1468 non-null   object \n",
      " 5   endtime                   1468 non-null   object \n",
      " 6   storetime                 1468 non-null   object \n",
      " 7   itemid                    1468 non-null   int64  \n",
      " 8   value                     1468 non-null   float64\n",
      " 9   valueuom                  1468 non-null   object \n",
      " 10  location                  353 non-null    object \n",
      " 11  locationcategory          353 non-null    object \n",
      " 12  orderid                   1468 non-null   int64  \n",
      " 13  linkorderid               1468 non-null   int64  \n",
      " 14  ordercategoryname         1468 non-null   object \n",
      " 15  ordercategorydescription  1468 non-null   object \n",
      " 16  patientweight             1468 non-null   float64\n",
      " 17  isopenbag                 1468 non-null   int64  \n",
      " 18  continueinnextdept        1468 non-null   int64  \n",
      " 19  statusdescription         1468 non-null   object \n",
      " 20  ORIGINALAMOUNT            1468 non-null   float64\n",
      " 21  ORIGINALRATE              1468 non-null   int64  \n",
      "dtypes: float64(4), int64(9), object(9)\n",
      "memory usage: 252.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_procedure_events.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d9af05",
   "metadata": {},
   "source": [
    "Drop: subject_id, starttime, endtime, storetime, orderid, linkorderid, continueinnextdept, stay_id, caregiver_id\n",
    "Encode: valueuom, ordercategoryname, ordercategorydescription, statusdescription, itemid\n",
    "Impute with N/A and encode: location, locationcategory\n",
    "MAKE DURATION FEATURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfebd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a duration feature using endtime-starttime\n",
    "\n",
    "# Convert to datetime\n",
    "df_procedure_events['endtime'] = pd.to_datetime(df_procedure_events['endtime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_procedure_events['starttime'] = pd.to_datetime(df_procedure_events['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "df_procedure_events['duration'] = df_procedure_events['endtime'] - df_procedure_events['starttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_procedure_events['duration'] = df_procedure_events['duration'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7ab8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a recording_delay feature using storetime-endtime\n",
    "\n",
    "# Convert to datetime\n",
    "df_procedure_events['storetime'] = pd.to_datetime(df_procedure_events['storetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_procedure_events['recording_delay'] = df_procedure_events['storetime'] - df_procedure_events['endtime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_procedure_events['recording_delay'] = df_procedure_events['recording_delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "885c3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \n",
    "df_procedure_events = df_procedure_events.drop(columns=['subject_id','stay_id','starttime','endtime','storetime','orderid',\n",
    "                                                        'linkorderid','continueinnextdept','caregiver_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5405f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with N/A and encode\n",
    "df_procedure_events['location'] = df_procedure_events['location'].fillna('N/A')\n",
    "df_procedure_events['locationcategory'] = df_procedure_events['locationcategory'].fillna('N/A')\n",
    "df_procedure_events = pd.get_dummies(df_procedure_events, columns=['location','locationcategory','valueuom',\n",
    "                                                                   'ordercategoryname','ordercategorydescription',\n",
    "                                                                   'statusdescription','itemid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76831c55",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01069273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1174, 163)\n",
      "Testing set shape: (294, 163)\n"
     ]
    }
   ],
   "source": [
    "data = df_procedure_events\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "procedure_events_data_train, procedure_events_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", procedure_events_data_train.shape)\n",
    "print(\"Testing set shape:\", procedure_events_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0860197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run if changes are made\n",
    "\n",
    "procedure_events_data_train.to_csv('procedure_events_data_train.csv', index=False)\n",
    "procedure_events_data_test.to_csv('procedure_events_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714b243",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a903e3",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
