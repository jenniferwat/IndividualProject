{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397b0aa8",
   "metadata": {},
   "source": [
    "#### Notes from phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8636aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.24.3\n",
      "Pandas version: 1.5.3\n",
      "Scikit version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# External libraries for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "#To render graphs within notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Versions of libraries\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Scikit version: {}\".format(sk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93008b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df208946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_days(duration_str):\n",
    "    parts = duration_str.split(' days ')  # Split string into form ['22', '20:55:00']\n",
    "    days = float(parts[0])  # Extract number of days and convert to float\n",
    "    time_parts = parts[1].split(':')  # Split time part (hh:mm:ss) ['20', '55', '00']\n",
    "    hours = float(time_parts[0])  # Extract hours and convert to float\n",
    "    minutes = float(time_parts[1])  # Extract minutes and convert to float\n",
    "    seconds = float(time_parts[2])  # Extract seconds and convert to float\n",
    "    total_days = days + (hours / 24) + (minutes / (24 * 60)) + (seconds / (24 * 3600))  # Calculate total days\n",
    "    return total_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d22e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a6b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/admissions.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_admissions = pd.read_csv(full_path)\n",
    "\n",
    "df_admissions['dischtime'] = pd.to_datetime(df_admissions['dischtime'], format='%d/%m/%Y %H:%M')\n",
    "df_admissions['admittime'] = pd.to_datetime(df_admissions['admittime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "df_admittime= pd.DataFrame()\n",
    "df_admittime['hadm_id'] = df_admissions['hadm_id']\n",
    "df_admittime['admittime'] = df_admissions['admittime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03dcef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/diagnoses_icd.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_diagnoses = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e9311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses = df_diagnoses.drop(columns=['subject_id','seq_num','icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9952635",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_diagnoses['icd_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_diagnoses[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b134c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>00845</th>\n",
       "      <th>0088</th>\n",
       "      <th>0380</th>\n",
       "      <th>0383</th>\n",
       "      <th>03842</th>\n",
       "      <th>03843</th>\n",
       "      <th>03849</th>\n",
       "      <th>0388</th>\n",
       "      <th>0389</th>\n",
       "      <th>...</th>\n",
       "      <th>Z95810</th>\n",
       "      <th>Z95820</th>\n",
       "      <th>Z961</th>\n",
       "      <th>Z96651</th>\n",
       "      <th>Z980</th>\n",
       "      <th>Z981</th>\n",
       "      <th>Z9884</th>\n",
       "      <th>Z9911</th>\n",
       "      <th>Z992</th>\n",
       "      <th>Z9981</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>29820177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  00845  0088  0380  0383  03842  03843  03849  0388  0389  ...  \\\n",
       "0    20044587      0     0     0     0      0      0      0     0     0  ...   \n",
       "1    20093566      0     0     0     0      0      0      0     0     0  ...   \n",
       "2    20192635      0     0     0     0      0      0      0     0     0  ...   \n",
       "3    20199380      0     0     0     0      0      0      0     0     0  ...   \n",
       "4    20214994      0     0     0     0      0      0      0     0     0  ...   \n",
       "..        ...    ...   ...   ...   ...    ...    ...    ...   ...   ...  ...   \n",
       "270  29820177      0     0     0     0      0      0      0     0     0  ...   \n",
       "271  29839885      0     0     0     0      0      0      0     0     0  ...   \n",
       "272  29842315      0     0     0     0      0      0      0     0     0  ...   \n",
       "273  29858644      0     0     0     0      0      0      0     0     0  ...   \n",
       "274  29974575      0     0     0     0      0      0      1     0     0  ...   \n",
       "\n",
       "     Z95810  Z95820  Z961  Z96651  Z980  Z981  Z9884  Z9911  Z992  Z9981  \n",
       "0         0       0     0       0     0     0      0      0     0      0  \n",
       "1         0       0     0       0     0     0      1      0     1      0  \n",
       "2         0       0     0       0     0     0      0      0     0      0  \n",
       "3         0       0     0       0     0     0      0      0     0      0  \n",
       "4         0       0     0       0     0     0      0      0     0      0  \n",
       "..      ...     ...   ...     ...   ...   ...    ...    ...   ...    ...  \n",
       "270       0       0     0       0     0     0      0      0     0      0  \n",
       "271       0       0     0       0     0     0      0      0     0      0  \n",
       "272       0       0     0       0     0     0      0      0     1      1  \n",
       "273       0       0     0       0     0     0      0      0     0      0  \n",
       "274       0       0     0       0     0     0      0      0     0      0  \n",
       "\n",
       "[275 rows x 1473 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diagnoses = df_aggregated\n",
    "df_diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b17e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/drgcodes.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_drgcodes = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329d7c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22187210    2\n",
       "27505812    2\n",
       "25926192    2\n",
       "27089790    2\n",
       "24490144    2\n",
       "           ..\n",
       "22539296    1\n",
       "20385771    1\n",
       "20199380    1\n",
       "20973395    1\n",
       "23559586    1\n",
       "Name: hadm_id, Length: 233, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes['hadm_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37288755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>drg_type</th>\n",
       "      <th>drg_code</th>\n",
       "      <th>description</th>\n",
       "      <th>drg_severity</th>\n",
       "      <th>drg_mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004235</td>\n",
       "      <td>22187210</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>864</td>\n",
       "      <td>FEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026255</td>\n",
       "      <td>22059910</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>180</td>\n",
       "      <td>RESPIRATORY NEOPLASMS W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10032725</td>\n",
       "      <td>20611640</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>54</td>\n",
       "      <td>NERVOUS SYSTEM NEOPLASMS W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005866</td>\n",
       "      <td>21636229</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>393</td>\n",
       "      <td>OTHER DIGESTIVE SYSTEM DIAGNOSES W MCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10008454</td>\n",
       "      <td>20291550</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>956</td>\n",
       "      <td>LIMB REATTACHMENT, HIP &amp; FEMUR PROC FOR MULTIP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id drg_type  drg_code  \\\n",
       "0    10004235  22187210     HCFA       864   \n",
       "1    10026255  22059910     HCFA       180   \n",
       "2    10032725  20611640     HCFA        54   \n",
       "3    10005866  21636229     HCFA       393   \n",
       "4    10008454  20291550     HCFA       956   \n",
       "\n",
       "                                         description  drg_severity  \\\n",
       "0                                              FEVER           NaN   \n",
       "1                        RESPIRATORY NEOPLASMS W MCC           NaN   \n",
       "2                     NERVOUS SYSTEM NEOPLASMS W MCC           NaN   \n",
       "3             OTHER DIGESTIVE SYSTEM DIAGNOSES W MCC           NaN   \n",
       "4  LIMB REATTACHMENT, HIP & FEMUR PROC FOR MULTIP...           NaN   \n",
       "\n",
       "   drg_mortality  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15d4236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drgcodes = df_drgcodes.drop(columns=['subject_id','drg_type','description','drg_severity','drg_mortality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0836367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_drgcodes['drg_code'])\n",
    "\n",
    "df_encoded = pd.concat([df_drgcodes[['hadm_id']], one_hot_encoded], axis=1)\n",
    "\n",
    "df_aggregated = df_encoded.groupby('hadm_id').sum().reset_index()\n",
    "\n",
    "# If you want to replace NaN values (where the category did not appear for a particular ID) with 0\n",
    "df_aggregated = df_aggregated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6caaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20044587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20093566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20192635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20199380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20214994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>29802992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>29839885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>29842315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>29858644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>29974575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  14  20  21  22  23  24  25  26  27  ...  950  951  952  956  \\\n",
       "0    20044587   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1    20093566   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2    20192635   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3    20199380   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4    20214994   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "..        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "228  29802992   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "229  29839885   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "230  29842315   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "231  29858644   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "232  29974575   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "     957  981  982  983  987  988  \n",
       "0      0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  \n",
       "228    0    0    0    0    0    0  \n",
       "229    0    0    0    0    0    0  \n",
       "230    0    0    0    0    0    0  \n",
       "231    0    0    0    0    0    0  \n",
       "232    0    0    0    0    0    0  \n",
       "\n",
       "[233 rows x 241 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drgcodes = df_aggregated\n",
    "df_drgcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5d829",
   "metadata": {},
   "source": [
    "### microbiologyevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e402c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"microbio_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"microbio_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcff0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c133b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee426675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa02a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf330577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique label classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42581e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique rows\n",
    "num_unique_rows = y_train.drop_duplicates().shape[0]\n",
    "\n",
    "print(\"Number of unique rows in y_train:\", num_unique_rows)\n",
    "\n",
    "num_unique_rows = y_test.drop_duplicates().shape[0]\n",
    "\n",
    "print(\"Number of unique rows in y_test:\", num_unique_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dbe5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65060db",
   "metadata": {},
   "source": [
    "There are several ways to measure a classifier’s generalization quality:\n",
    "\n",
    "Hamming loss measures how well the classifier predicts each of the labels, averaged over samples, then over labels\n",
    "accuracy score measures how well the classifier predicts label combinations, averaged over samples\n",
    "\n",
    "jaccard similarity measures the proportion of predicted labels for a sample to its correct assignment, averaged over samples\n",
    "\n",
    "precision measures how many samples with ,\n",
    "\n",
    "recall measures how many samples ,\n",
    "\n",
    "F1 score measures a weighted average of precision and recall, where both have the same impact on the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115797c",
   "metadata": {},
   "source": [
    "### emar - ignore (medication comes after diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47468784",
   "metadata": {},
   "source": [
    "### outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95aef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"output_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"output_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa567d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d759b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6accb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabfcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17fee79",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80529c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d7208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ff1cb",
   "metadata": {},
   "source": [
    "### procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4224289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"procedure_events_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"procedure_events_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a181c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f88d5",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3128471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45230025",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf152ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7509133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19407f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67682005",
   "metadata": {},
   "source": [
    "### poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5ce3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"poe_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"poe_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab5aebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f73102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cadb4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed316151",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e3a3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b808096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ec1ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ae2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "999f9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9284180",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b353b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "000a3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bb39fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8722019186843307\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        34\n",
      "           1       0.98      0.91      0.94       192\n",
      "           2       0.99      0.82      0.90       218\n",
      "           3       1.00      0.70      0.82        33\n",
      "           4       1.00      0.72      0.84        65\n",
      "           5       0.99      0.88      0.93       116\n",
      "           6       1.00      0.97      0.99       136\n",
      "           7       0.95      0.90      0.93        70\n",
      "           8       0.95      0.79      0.86        24\n",
      "           9       1.00      0.60      0.75        10\n",
      "          10       1.00      1.00      1.00        18\n",
      "          11       1.00      0.89      0.94        18\n",
      "          12       1.00      1.00      1.00        30\n",
      "          13       0.99      0.84      0.91       112\n",
      "          14       0.96      0.79      0.87        29\n",
      "          15       1.00      1.00      1.00        18\n",
      "          16       0.90      0.77      0.83        61\n",
      "          17       0.94      0.76      0.84        38\n",
      "          18       1.00      0.60      0.75        20\n",
      "          19       1.00      1.00      1.00        30\n",
      "          20       0.99      0.83      0.90        99\n",
      "          21       1.00      1.00      1.00        13\n",
      "          22       0.93      0.86      0.89        44\n",
      "          23       1.00      0.65      0.79        17\n",
      "          24       0.96      0.79      0.87        29\n",
      "          25       1.00      1.00      1.00        23\n",
      "          26       0.97      0.95      0.96        73\n",
      "          27       1.00      0.89      0.94        53\n",
      "          28       0.99      0.85      0.92       449\n",
      "          29       1.00      0.79      0.88        28\n",
      "          30       0.99      0.88      0.93       116\n",
      "          31       0.94      0.71      0.81        24\n",
      "          32       1.00      0.78      0.88        55\n",
      "          33       1.00      0.98      0.99        65\n",
      "          34       1.00      0.73      0.85        15\n",
      "          35       1.00      0.93      0.96       144\n",
      "          36       1.00      0.95      0.98        22\n",
      "          37       1.00      0.80      0.89        15\n",
      "          38       1.00      0.97      0.98        96\n",
      "          39       1.00      1.00      1.00        23\n",
      "          40       1.00      1.00      1.00        11\n",
      "          41       1.00      1.00      1.00        50\n",
      "          42       0.99      0.88      0.93       198\n",
      "          43       0.97      0.95      0.96        73\n",
      "          44       0.98      0.92      0.94       131\n",
      "          45       0.97      0.90      0.94       409\n",
      "          46       1.00      0.92      0.96        39\n",
      "          47       0.98      0.87      0.92        54\n",
      "          48       0.95      0.80      0.87        96\n",
      "          49       1.00      0.89      0.94       120\n",
      "          50       0.94      0.71      0.81        24\n",
      "          51       0.98      0.89      0.93        96\n",
      "          52       1.00      0.98      0.99        65\n",
      "          53       1.00      0.93      0.96        14\n",
      "          54       1.00      0.67      0.80        15\n",
      "          55       1.00      0.80      0.89        15\n",
      "          56       1.00      0.93      0.96        43\n",
      "          57       0.96      1.00      0.98        55\n",
      "          58       1.00      0.97      0.99        36\n",
      "          59       0.94      0.81      0.87        21\n",
      "          60       1.00      0.92      0.96       135\n",
      "          61       1.00      0.92      0.96       281\n",
      "          62       1.00      0.94      0.97        68\n",
      "          63       1.00      0.89      0.94        57\n",
      "          64       1.00      0.92      0.96        12\n",
      "          65       1.00      0.80      0.89        40\n",
      "          66       0.92      0.79      0.85        14\n",
      "          67       1.00      0.93      0.96        71\n",
      "          68       1.00      1.00      1.00        66\n",
      "          69       1.00      0.91      0.95        22\n",
      "          70       0.99      0.83      0.91       568\n",
      "          71       0.99      0.90      0.94        73\n",
      "          72       1.00      1.00      1.00        50\n",
      "          73       1.00      0.85      0.92       212\n",
      "          74       1.00      0.92      0.96        26\n",
      "          75       0.98      0.94      0.96       109\n",
      "          76       1.00      0.95      0.98        44\n",
      "          77       1.00      0.95      0.98        42\n",
      "          78       1.00      1.00      1.00        11\n",
      "          79       1.00      0.67      0.80        15\n",
      "          80       1.00      0.80      0.89        35\n",
      "          81       1.00      0.88      0.94        17\n",
      "          82       0.97      0.92      0.94       119\n",
      "          83       0.97      0.81      0.89        91\n",
      "          84       0.97      0.92      0.95       310\n",
      "          85       1.00      0.94      0.97        67\n",
      "          86       0.99      0.94      0.96        81\n",
      "          87       1.00      1.00      1.00        21\n",
      "          88       1.00      0.96      0.98        45\n",
      "          89       1.00      0.91      0.95       123\n",
      "          90       1.00      0.75      0.86        24\n",
      "          91       1.00      0.87      0.93        67\n",
      "          92       1.00      0.91      0.95        34\n",
      "          93       1.00      0.93      0.96        14\n",
      "          94       1.00      0.87      0.93        55\n",
      "          95       1.00      0.97      0.99        77\n",
      "          96       1.00      0.86      0.92        92\n",
      "          97       0.99      0.90      0.94        81\n",
      "          98       1.00      1.00      1.00        15\n",
      "          99       0.98      0.90      0.94       358\n",
      "         100       1.00      0.89      0.94        62\n",
      "         101       0.96      0.81      0.88        58\n",
      "         102       1.00      0.92      0.96        24\n",
      "         103       0.96      0.98      0.97       111\n",
      "         104       0.97      1.00      0.98        58\n",
      "         105       0.96      0.91      0.93        53\n",
      "         106       0.98      0.89      0.94        57\n",
      "         107       1.00      0.96      0.97       224\n",
      "         108       1.00      0.92      0.96        78\n",
      "         109       1.00      1.00      1.00        19\n",
      "         110       1.00      0.91      0.95        43\n",
      "         111       0.92      0.86      0.89        14\n",
      "         112       1.00      0.92      0.96        12\n",
      "         113       1.00      0.88      0.94        60\n",
      "         114       0.92      0.79      0.85        14\n",
      "         115       1.00      0.90      0.95       142\n",
      "         116       1.00      0.95      0.98        88\n",
      "         117       1.00      0.95      0.97        39\n",
      "         118       1.00      0.93      0.96        14\n",
      "         119       1.00      0.91      0.96        70\n",
      "         120       1.00      0.86      0.92        86\n",
      "         121       1.00      0.92      0.96        24\n",
      "         122       1.00      0.96      0.98        49\n",
      "         123       1.00      0.88      0.93        32\n",
      "         124       0.99      0.97      0.98       129\n",
      "         125       1.00      0.92      0.96        26\n",
      "         126       1.00      0.95      0.98        42\n",
      "         127       1.00      0.95      0.98        44\n",
      "         128       1.00      0.67      0.80        15\n",
      "         129       0.98      0.94      0.96       109\n",
      "         130       0.98      0.88      0.92        48\n",
      "         131       0.99      0.89      0.94       101\n",
      "         132       1.00      0.91      0.95        22\n",
      "         133       0.97      0.97      0.97        33\n",
      "         134       1.00      0.94      0.97        34\n",
      "         135       1.00      0.95      0.97       135\n",
      "         136       0.98      0.89      0.94        66\n",
      "         137       1.00      1.00      1.00        10\n",
      "         138       1.00      1.00      1.00        25\n",
      "         139       1.00      1.00      1.00        15\n",
      "         140       1.00      0.92      0.96        13\n",
      "         141       1.00      1.00      1.00        16\n",
      "         142       1.00      0.74      0.85        39\n",
      "         143       1.00      0.86      0.92        21\n",
      "         144       1.00      0.80      0.89        20\n",
      "         145       1.00      0.88      0.93         8\n",
      "         146       1.00      0.82      0.90        44\n",
      "         147       1.00      0.96      0.98        48\n",
      "         148       1.00      1.00      1.00        15\n",
      "         149       0.97      0.90      0.93       195\n",
      "         150       1.00      0.92      0.96        24\n",
      "         151       1.00      0.88      0.93        16\n",
      "         152       0.99      0.85      0.91       156\n",
      "         153       1.00      0.86      0.92        21\n",
      "         154       1.00      0.86      0.92        21\n",
      "         155       0.97      1.00      0.98        58\n",
      "         156       0.96      0.96      0.96       139\n",
      "         157       1.00      0.97      0.98        29\n",
      "         158       1.00      1.00      1.00        22\n",
      "         159       1.00      0.93      0.96        14\n",
      "         160       1.00      0.85      0.92        46\n",
      "         161       0.97      0.89      0.93        37\n",
      "         162       0.71      0.71      0.71         7\n",
      "         163       0.97      1.00      0.98        31\n",
      "         164       1.00      0.95      0.98        88\n",
      "         165       1.00      0.93      0.96        71\n",
      "         166       1.00      0.93      0.96        14\n",
      "         167       1.00      0.82      0.90        11\n",
      "         168       1.00      1.00      1.00        10\n",
      "         169       1.00      1.00      1.00        15\n",
      "         170       1.00      0.92      0.96        24\n",
      "         171       0.98      0.88      0.93        57\n",
      "         172       0.92      0.69      0.79        52\n",
      "         173       1.00      0.94      0.97       146\n",
      "         174       1.00      0.90      0.95        40\n",
      "         175       1.00      0.86      0.92        21\n",
      "         176       1.00      0.97      0.98        32\n",
      "         177       1.00      1.00      1.00         9\n",
      "         178       1.00      0.77      0.87        30\n",
      "         179       1.00      1.00      1.00         7\n",
      "         180       0.93      0.95      0.94        39\n",
      "         181       0.98      0.95      0.97        61\n",
      "         182       1.00      1.00      1.00         7\n",
      "         183       1.00      0.89      0.94       132\n",
      "         184       0.98      0.98      0.98        86\n",
      "         185       1.00      0.95      0.97       247\n",
      "         186       1.00      0.95      0.98       176\n",
      "         187       0.97      0.78      0.87       699\n",
      "         188       1.00      0.83      0.91        65\n",
      "         189       1.00      0.67      0.80         6\n",
      "         190       1.00      0.95      0.98        21\n",
      "         191       1.00      0.82      0.90        11\n",
      "         192       1.00      0.88      0.93         8\n",
      "         193       1.00      0.75      0.86         4\n",
      "         194       1.00      1.00      1.00        20\n",
      "         195       1.00      0.90      0.95        10\n",
      "         196       1.00      0.89      0.94        28\n",
      "         197       1.00      0.75      0.86         8\n",
      "         198       1.00      0.98      0.99       193\n",
      "         199       1.00      0.97      0.98        32\n",
      "         200       1.00      0.94      0.97        17\n",
      "         201       0.93      0.82      0.87        17\n",
      "         202       1.00      0.77      0.87        30\n",
      "         203       1.00      0.80      0.89        56\n",
      "         204       1.00      1.00      1.00         7\n",
      "         205       1.00      0.50      0.67         8\n",
      "         206       1.00      0.95      0.97        76\n",
      "         207       1.00      1.00      1.00        79\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       1.00      0.95      0.97       247\n",
      "         210       1.00      0.94      0.97        16\n",
      "         211       1.00      0.95      0.98       176\n",
      "         212       1.00      0.76      0.86        41\n",
      "         213       1.00      0.67      0.80         6\n",
      "         214       1.00      0.95      0.98        21\n",
      "         215       0.96      0.92      0.94       163\n",
      "         216       0.98      0.85      0.91       473\n",
      "         217       0.98      0.96      0.97        47\n",
      "         218       1.00      1.00      1.00        20\n",
      "         219       1.00      0.75      0.86         4\n",
      "         220       1.00      0.88      0.93         8\n",
      "         221       1.00      0.90      0.95        10\n",
      "         222       1.00      0.75      0.86         8\n",
      "         223       1.00      0.89      0.94        28\n",
      "         224       0.98      0.87      0.92        54\n",
      "         225       1.00      0.97      0.98       121\n",
      "         226       0.99      0.90      0.94       170\n",
      "         227       1.00      0.94      0.97        17\n",
      "         228       0.93      0.82      0.87        17\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.94      0.89      0.91        99\n",
      "         231       1.00      0.85      0.92       524\n",
      "         232       1.00      0.77      0.87        57\n",
      "         233       1.00      0.96      0.98        56\n",
      "         234       1.00      0.95      0.98       207\n",
      "         235       0.99      0.89      0.94       185\n",
      "         236       1.00      0.82      0.90        60\n",
      "         237       1.00      0.76      0.86        25\n",
      "         238       1.00      0.96      0.98       201\n",
      "         239       1.00      0.71      0.83        21\n",
      "\n",
      "   micro avg       0.99      0.89      0.94     17059\n",
      "   macro avg       0.98      0.88      0.93     17059\n",
      "weighted avg       0.99      0.89      0.94     17059\n",
      " samples avg       0.91      0.90      0.90     17059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7bc2d",
   "metadata": {},
   "source": [
    "###  prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3b9e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"prescriptions_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"prescriptions_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2b261c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d5db6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be0566e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e18c6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43f730a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87337626",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "922a540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88bcb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c6d708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1330258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 4890 to 2874 or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e22f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Number of desired features (components)\n",
    "n_components = 2874\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_train)\n",
    "X_train = svd.transform(X_train)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of desired features (components)\n",
    "n_components = 2874\n",
    "\n",
    "# Initialize Truncated SVD with the desired number of components\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "svd.fit(X_test)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "# Get the explained variance ratio (how much variance is explained by each component)\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Print the transformed matrix and explained variance ratio\n",
    "# print(\"Transformed Matrix:\")\n",
    "# print(transformed_matrix)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd069ffb",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ffafcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95b12342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2602040816326531\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.42      0.53        19\n",
      "           1       0.58      0.16      0.26        67\n",
      "           2       0.75      0.26      0.38        70\n",
      "           3       1.00      0.50      0.67         6\n",
      "           4       1.00      0.19      0.32        21\n",
      "           5       0.76      0.36      0.49        36\n",
      "           6       0.81      0.46      0.58        57\n",
      "           7       1.00      0.25      0.40        16\n",
      "           8       0.62      0.50      0.55        16\n",
      "           9       1.00      0.60      0.75         5\n",
      "          10       0.60      0.38      0.46         8\n",
      "          11       0.50      0.27      0.35        11\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.67      0.16      0.25        51\n",
      "          14       0.60      0.14      0.23        21\n",
      "          15       0.60      0.38      0.46         8\n",
      "          16       0.69      0.39      0.50        23\n",
      "          17       0.73      0.42      0.53        19\n",
      "          18       0.83      0.62      0.71         8\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.80      0.17      0.29        46\n",
      "          21       0.50      0.20      0.29         5\n",
      "          22       0.80      0.40      0.53        10\n",
      "          23       0.56      0.38      0.45        13\n",
      "          24       0.60      0.14      0.23        21\n",
      "          25       0.67      0.44      0.53         9\n",
      "          26       0.75      0.35      0.47        26\n",
      "          27       1.00      0.32      0.49        31\n",
      "          28       0.75      0.24      0.37       160\n",
      "          29       0.67      0.25      0.36         8\n",
      "          30       0.92      0.27      0.42        41\n",
      "          31       0.75      0.30      0.43        10\n",
      "          32       1.00      0.18      0.31        22\n",
      "          33       0.69      0.53      0.60        17\n",
      "          34       1.00      0.50      0.67         6\n",
      "          35       0.78      0.38      0.51        55\n",
      "          36       1.00      0.44      0.62         9\n",
      "          37       0.33      0.20      0.25         5\n",
      "          38       0.81      0.54      0.65        39\n",
      "          39       0.67      0.44      0.53         9\n",
      "          40       0.67      0.67      0.67         3\n",
      "          41       0.57      0.42      0.48        19\n",
      "          42       0.78      0.17      0.27       108\n",
      "          43       0.75      0.35      0.47        26\n",
      "          44       0.78      0.09      0.17        75\n",
      "          45       0.66      0.24      0.35       212\n",
      "          46       0.82      0.45      0.58        20\n",
      "          47       0.43      0.24      0.31        25\n",
      "          48       0.80      0.29      0.42        42\n",
      "          49       0.74      0.30      0.42        47\n",
      "          50       0.75      0.30      0.43        10\n",
      "          51       0.73      0.37      0.49        30\n",
      "          52       0.69      0.53      0.60        17\n",
      "          53       0.89      0.80      0.84        10\n",
      "          54       1.00      0.09      0.17        11\n",
      "          55       0.33      0.20      0.25         5\n",
      "          56       0.67      0.20      0.31        10\n",
      "          57       0.80      0.43      0.56        28\n",
      "          58       0.00      0.00      0.00        10\n",
      "          59       0.86      0.40      0.55        15\n",
      "          60       0.74      0.38      0.50        45\n",
      "          61       0.75      0.36      0.49       139\n",
      "          62       0.75      0.48      0.59        31\n",
      "          63       1.00      0.35      0.52        20\n",
      "          64       0.50      0.50      0.50         2\n",
      "          65       1.00      0.18      0.31        11\n",
      "          66       0.00      0.00      0.00         3\n",
      "          67       0.67      0.22      0.33        37\n",
      "          68       0.76      0.70      0.73        27\n",
      "          69       0.50      0.11      0.18         9\n",
      "          70       0.71      0.25      0.37       199\n",
      "          71       0.75      0.29      0.42        31\n",
      "          72       0.57      0.42      0.48        19\n",
      "          73       0.73      0.20      0.31        97\n",
      "          74       0.77      0.62      0.69        16\n",
      "          75       0.75      0.50      0.60        30\n",
      "          76       0.86      0.29      0.43        21\n",
      "          77       0.80      0.18      0.30        22\n",
      "          78       0.67      0.67      0.67         3\n",
      "          79       1.00      0.20      0.33         5\n",
      "          80       0.75      0.33      0.46         9\n",
      "          81       0.86      0.55      0.67        11\n",
      "          82       0.78      0.10      0.18        68\n",
      "          83       0.75      0.26      0.38        35\n",
      "          84       0.68      0.23      0.34       174\n",
      "          85       0.71      0.21      0.32        24\n",
      "          86       0.88      0.49      0.63        45\n",
      "          87       1.00      0.56      0.71         9\n",
      "          88       0.88      0.32      0.47        22\n",
      "          89       0.62      0.19      0.29        43\n",
      "          90       1.00      0.09      0.17        11\n",
      "          91       0.62      0.32      0.42        25\n",
      "          92       0.89      0.73      0.80        11\n",
      "          93       0.89      0.80      0.84        10\n",
      "          94       0.95      0.60      0.73        30\n",
      "          95       0.70      0.28      0.40        25\n",
      "          96       0.83      0.38      0.52        40\n",
      "          97       0.80      0.33      0.47        24\n",
      "          98       0.75      0.33      0.46         9\n",
      "          99       0.82      0.24      0.37       133\n",
      "         100       0.83      0.54      0.65        28\n",
      "         101       0.80      0.33      0.47        24\n",
      "         102       1.00      0.18      0.31        11\n",
      "         103       0.80      0.41      0.54        49\n",
      "         104       1.00      0.64      0.78        14\n",
      "         105       0.83      0.31      0.45        32\n",
      "         106       0.67      0.16      0.26        25\n",
      "         107       0.78      0.33      0.47        93\n",
      "         108       0.82      0.58      0.68        53\n",
      "         109       1.00      0.17      0.29         6\n",
      "         110       0.86      0.50      0.63        12\n",
      "         111       1.00      0.12      0.22         8\n",
      "         112       0.50      0.50      0.50         2\n",
      "         113       0.86      0.27      0.41        22\n",
      "         114       0.00      0.00      0.00         3\n",
      "         115       0.53      0.18      0.27        55\n",
      "         116       0.74      0.33      0.45        52\n",
      "         117       0.00      0.00      0.00        11\n",
      "         118       0.00      0.00      0.00         3\n",
      "         119       0.71      0.50      0.59        24\n",
      "         120       0.72      0.58      0.64        31\n",
      "         121       0.71      0.56      0.63         9\n",
      "         122       0.73      0.44      0.55        18\n",
      "         123       1.00      0.27      0.43        11\n",
      "         124       0.67      0.50      0.57        44\n",
      "         125       0.89      0.38      0.53        21\n",
      "         126       0.80      0.18      0.30        22\n",
      "         127       0.86      0.29      0.43        21\n",
      "         128       1.00      0.20      0.33         5\n",
      "         129       0.75      0.50      0.60        30\n",
      "         130       0.75      0.50      0.60        18\n",
      "         131       0.56      0.14      0.23        35\n",
      "         132       0.75      0.38      0.50         8\n",
      "         133       0.00      0.00      0.00         8\n",
      "         134       0.86      0.38      0.52        16\n",
      "         135       0.75      0.13      0.22        47\n",
      "         136       0.91      0.66      0.76        32\n",
      "         137       0.88      0.88      0.88         8\n",
      "         138       1.00      0.95      0.97        20\n",
      "         139       0.33      0.50      0.40         2\n",
      "         140       0.00      0.00      0.00        10\n",
      "         141       1.00      0.25      0.40         4\n",
      "         142       0.75      0.23      0.35        13\n",
      "         143       1.00      0.86      0.92         7\n",
      "         144       0.33      0.14      0.20         7\n",
      "         145       0.80      0.40      0.53        10\n",
      "         146       0.73      0.36      0.48        22\n",
      "         147       1.00      0.33      0.50        18\n",
      "         148       0.75      0.33      0.46         9\n",
      "         149       0.86      0.40      0.54        96\n",
      "         150       1.00      0.42      0.59        12\n",
      "         151       0.50      0.60      0.55         5\n",
      "         152       0.58      0.15      0.24        47\n",
      "         153       0.00      0.00      0.00         5\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       1.00      0.64      0.78        14\n",
      "         156       0.75      0.40      0.52        53\n",
      "         157       1.00      0.47      0.64        17\n",
      "         158       0.33      0.10      0.15        10\n",
      "         159       0.00      0.00      0.00         7\n",
      "         160       0.86      0.40      0.55        15\n",
      "         161       0.60      0.33      0.43         9\n",
      "         162       0.00      0.00      0.00         3\n",
      "         163       0.85      0.92      0.88        12\n",
      "         164       0.74      0.33      0.45        52\n",
      "         165       0.43      0.17      0.24        18\n",
      "         166       0.00      0.00      0.00         3\n",
      "         167       0.50      0.60      0.55         5\n",
      "         168       0.88      0.88      0.88         8\n",
      "         169       0.33      0.50      0.40         2\n",
      "         170       0.71      0.56      0.63         9\n",
      "         171       0.82      0.58      0.68        24\n",
      "         172       0.75      0.54      0.63        28\n",
      "         173       0.70      0.15      0.25        47\n",
      "         174       0.80      0.47      0.59        17\n",
      "         175       0.00      0.00      0.00         5\n",
      "         176       0.80      0.73      0.76        11\n",
      "         177       1.00      0.33      0.50         6\n",
      "         178       0.80      0.50      0.62        16\n",
      "         179       0.57      0.80      0.67         5\n",
      "         180       1.00      0.62      0.76        13\n",
      "         181       0.82      0.77      0.79        30\n",
      "         182       0.00      0.00      0.00         2\n",
      "         183       0.67      0.29      0.41        48\n",
      "         184       0.84      0.90      0.87        29\n",
      "         185       0.93      0.28      0.43        97\n",
      "         186       0.81      0.42      0.55        60\n",
      "         187       0.81      0.15      0.25       265\n",
      "         188       0.79      0.44      0.57        34\n",
      "         189       1.00      0.20      0.33         5\n",
      "         190       0.91      0.71      0.80        14\n",
      "         191       0.50      0.60      0.55         5\n",
      "         192       0.00      0.00      0.00         1\n",
      "         193       0.33      1.00      0.50         1\n",
      "         194       0.87      0.93      0.90        14\n",
      "         195       1.00      0.20      0.33         5\n",
      "         196       0.67      0.67      0.67         3\n",
      "         197       1.00      0.43      0.60         7\n",
      "         198       0.89      0.32      0.47        53\n",
      "         199       0.80      0.73      0.76        11\n",
      "         200       1.00      0.33      0.50        15\n",
      "         201       0.67      0.86      0.75         7\n",
      "         202       0.80      0.50      0.62        16\n",
      "         203       0.20      0.06      0.10        16\n",
      "         204       0.57      0.80      0.67         5\n",
      "         205       1.00      0.40      0.57         5\n",
      "         206       0.82      0.56      0.67        32\n",
      "         207       0.82      0.88      0.85        26\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.93      0.28      0.43        97\n",
      "         210       0.83      0.62      0.71         8\n",
      "         211       0.81      0.42      0.55        60\n",
      "         212       0.80      0.48      0.60        25\n",
      "         213       1.00      0.20      0.33         5\n",
      "         214       0.91      0.71      0.80        14\n",
      "         215       0.80      0.23      0.36        52\n",
      "         216       0.86      0.16      0.27       195\n",
      "         217       0.60      0.30      0.40        10\n",
      "         218       0.87      0.93      0.90        14\n",
      "         219       0.33      1.00      0.50         1\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       1.00      0.20      0.33         5\n",
      "         222       1.00      0.43      0.60         7\n",
      "         223       0.67      0.67      0.67         3\n",
      "         224       0.43      0.24      0.31        25\n",
      "         225       0.65      0.34      0.45        32\n",
      "         226       0.80      0.39      0.53        61\n",
      "         227       1.00      0.33      0.50        15\n",
      "         228       0.67      0.86      0.75         7\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.55      0.14      0.22        43\n",
      "         231       0.79      0.15      0.26       200\n",
      "         232       0.88      0.35      0.50        20\n",
      "         233       0.78      0.68      0.72        31\n",
      "         234       0.65      0.24      0.35        54\n",
      "         235       0.91      0.13      0.23        75\n",
      "         236       0.69      0.26      0.38        34\n",
      "         237       0.50      0.05      0.09        21\n",
      "         238       0.80      0.42      0.55        76\n",
      "         239       1.00      0.50      0.67         2\n",
      "\n",
      "   micro avg       0.77      0.32      0.45      6871\n",
      "   macro avg       0.70      0.37      0.45      6871\n",
      "weighted avg       0.76      0.32      0.43      6871\n",
      " samples avg       0.36      0.32      0.33      6871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jenni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7fa3d",
   "metadata": {},
   "source": [
    "### pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "409213f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"pharmacy_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"pharmacy_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5e72f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['medication_duration']= X_train['medication_duration'].apply(convert_to_days)\n",
    "X_test['medication_duration']= X_test['medication_duration'].apply(convert_to_days)\n",
    "# Convert strings to integers\n",
    "X_train['verification_delay'] = X_train['verification_delay'].str.split().str[0].astype(int)\n",
    "X_test['verification_delay'] = X_test['verification_delay'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd1ead1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bca6ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21087575",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fec05e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f41b16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfec2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "171d2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e5c194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd07c1",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd296d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69170690",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99811ea",
   "metadata": {},
   "source": [
    "### inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ddb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a629b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "file = \"input_data_train.csv\"\n",
    "full_path = path + file\n",
    "X_train = pd.read_csv(full_path)\n",
    "\n",
    "file = \"input_data_test.csv\"\n",
    "full_path = path + file\n",
    "X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4bd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['duration']= X_train['duration'].apply(convert_to_days)\n",
    "X_test['duration']= X_test['duration'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2bcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['recording_delay']= X_train['recording_delay'].apply(convert_to_days)\n",
    "X_test['recording_delay']= X_test['recording_delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea529ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a109978",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67412db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15879621",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64209275",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd445a",
   "metadata": {},
   "source": [
    "## Not enough memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a2e4c",
   "metadata": {},
   "source": [
    "### ingredientevents - ignore, not relevant to diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1ec15",
   "metadata": {},
   "source": [
    "### chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "# file = \"chart_data_train.csv\"\n",
    "# full_path = path + file\n",
    "# X_train = pd.read_csv(full_path)\n",
    "\n",
    "# file = \"chart_data_test.csv\"\n",
    "# full_path = path + file\n",
    "# X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58874fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_test['delay']= X_test['delay'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to deal with days_since_admission\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].apply(convert_to_days)\n",
    "X_test['days_since_admission'] = X_test['days_since_admission'].apply(convert_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cf17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c98e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69145679",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dbe6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad533f1",
   "metadata": {},
   "source": [
    "#### XGBoost for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "base_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize the multi-output classifier with the base classifier\n",
    "classifier = MultiOutputClassifier(base_classifier)\n",
    "\n",
    "# Train the classifier with both input features (X_train) and target labels (y_train)\n",
    "for i in tqdm(range(100)):\n",
    "    classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a8bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    y_pred = classifier.predict(X_test.values)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hamming Loss\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Hamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd964a",
   "metadata": {},
   "source": [
    "### emar_detail - ignore (medication comes after diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba350201",
   "metadata": {},
   "source": [
    "### labevents - can't allocate memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't allocate memory this way \n",
    "\n",
    "# path = \"C:/Users/jenni/OneDrive/Desktop/IP/\"\n",
    "\n",
    "# file = \"labevents_data_train.csv\"\n",
    "# full_path = path + file\n",
    "# X_train = pd.read_csv(full_path)\n",
    "\n",
    "# file = \"labevents_data_test.csv\"\n",
    "# full_path = path + file\n",
    "# X_test = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96998c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52969a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hosp/labevents.csv\"\n",
    "full_path = path + file\n",
    "\n",
    "df_labevents = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents['value'] = pd.to_numeric(df_labevents['value'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e605ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feature for days_since_admission using charttime - admittime\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['charttime'] = pd.to_datetime(df_labevents['charttime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Add admittime column from other dataframe\n",
    "df_labevents = df_labevents.merge(df_admittime, on='hadm_id', how='left')\n",
    "\n",
    "# # Discard the time part and keep only the date\n",
    "# df_hcpcsevents['admittime'] = df_hcpcsevents['admittime'].dt.date\n",
    "# df_hcpcsevents['chartdate'] = df_hcpcsevents['chartdate'].dt.date\n",
    "\n",
    "df_labevents['days_since_admission'] = df_labevents['charttime'] - df_labevents['admittime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['days_since_admission'] = df_labevents['days_since_admission'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add storetime - charttime feature called delay\n",
    "\n",
    "# Convert to datetime\n",
    "df_labevents['storetime'] = pd.to_datetime(df_labevents['storetime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "df_labevents['delay'] = df_labevents['storetime'] - df_labevents['charttime']\n",
    "\n",
    "# Fill any non time values\n",
    "df_labevents['delay'] = df_labevents['delay'].fillna(pd.Timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = df_labevents.drop(columns=['labevent_id','subject_id','order_provider_id','charttime','storetime','comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For flag make abnormal = 1 and fill Null with 0\n",
    "df_labevents['flag'] = df_labevents['flag'].fillna(0)\n",
    "df_labevents['flag'] = df_labevents['flag'].replace('abnormal', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For priority fill Null with N/A and then one hot encode\n",
    "df_labevents['priority'] = df_labevents['priority'].fillna('N/A')\n",
    "df_labevents = pd.get_dummies(df_labevents, columns=['priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = pd.get_dummies(df_labevents, columns=['valueuom','specimen_id','itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null values \n",
    "df_labevents = df_labevents.dropna()\n",
    "# Reduced from 107727 rows to 66660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = df_labevents.drop(columns=['admittime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05baab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_labevents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f5639",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2654c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_labevents\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "labevents_data_train, labevents_data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting training and testing sets\n",
    "print(\"Training set shape:\", labevents_data_train.shape)\n",
    "print(\"Testing set shape:\", labevents_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labevents_data_train.drop(columns=['hadm_id'])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf78e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc853f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# # Make sure the order is the same\n",
    "\n",
    "# # Extract the unique IDs from the column \n",
    "# train_ids = labevents_data_train['hadm_id'].unique()\n",
    "\n",
    "# # Filter to keep only rows where the id column is in train_ids\n",
    "# y_train = df_diagnoses[df_diagnoses['hadm_id'].isin(train_ids)]\n",
    "\n",
    "# test_ids = labevents_data_test['hadm_id'].unique()\n",
    "\n",
    "# # Filter to keep only rows where the id column is in train_ids\n",
    "# y_test = df_diagnoses[df_diagnoses['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3348a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = labevents_data_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = labevents_data_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094fe67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, labevents_data_train['hadm_id'], on='hadm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bf947",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, labevents_data_test['hadm_id'], on='hadm_id')\n",
    "\n",
    "y_test = merged_df\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = labevents_data_train\n",
    "X_test = labevents_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7007f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['delay']= X_train['delay'].astype(str)\n",
    "# X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "# X_train['days_since_admission'] = X_train['days_since_admission'].astype(str)\n",
    "# X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "\n",
    "# X_train = X_train.drop(columns=['hadm_id'])\n",
    "# X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "# y_train = y_train.drop(columns=['hadm_id'])\n",
    "# y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2eb130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['delay']= X_train['delay'].astype(str)\n",
    "X_train['delay']= X_train['delay'].apply(convert_to_days)\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].astype(str)\n",
    "X_train['days_since_admission'] = X_train['days_since_admission'].str.split().str[0].astype(int)\n",
    "\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrices to address memory issue\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X_train_sparse = csr_matrix(X_train)\n",
    "X_test_sparse = csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc44518",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction - not enough memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce from 11681 to 10665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393bd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['delay']= data['delay'].astype(str)\n",
    "# data['delay']= data['delay'].apply(convert_to_days)\n",
    "# data['days_since_admission'] = data['days_since_admission'].astype(str)\n",
    "# data['days_since_admission'] = data['days_since_admission'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# # Number of desired features (components)\n",
    "# n_components = 10665\n",
    "\n",
    "# # Initialize Truncated SVD with the desired number of components\n",
    "# svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# # Fit the Truncated SVD model to the sparse matrix and transform the data\n",
    "# svd.fit(data)\n",
    "# data = svd.transform(data)\n",
    "\n",
    "# # Get the explained variance ratio (how much variance is explained by each component)\n",
    "# explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# # Print the transformed matrix and explained variance ratio\n",
    "# # print(\"Transformed Matrix:\")\n",
    "# # print(transformed_matrix)\n",
    "# print(\"\\nExplained Variance Ratio:\")\n",
    "# print(explained_variance_ratio)\n",
    "\n",
    "# print(\"\\n Amount of original variance conserved:\", np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_diagnoses (rows where hadm_id is in train data)\n",
    "# Make sure the order is the same\n",
    "\n",
    "# Extract the unique IDs from the column \n",
    "train_ids = X_train['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_train = df_drgcodes[df_drgcodes['hadm_id'].isin(train_ids)]\n",
    "\n",
    "test_ids = X_test['hadm_id'].unique()\n",
    "\n",
    "# Filter to keep only rows where the id column is in train_ids\n",
    "y_test = df_drgcodes[df_drgcodes['hadm_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_train, X_train['hadm_id'], on='hadm_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11000dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(y_test, X_test['hadm_id'], on='hadm_id', how='inner')\n",
    "y_test = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_train['hadm_id'].unique()\n",
    "X_train = X_train[X_train['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = y_test['hadm_id'].unique()\n",
    "X_test = X_test[X_test['hadm_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a968612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by hadm_id and drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.sort_values(by='hadm_id')\n",
    "y_train = y_train.drop(columns=['hadm_id'])\n",
    "\n",
    "y_test = y_test.sort_values(by='hadm_id')\n",
    "y_test = y_test.drop(columns=['hadm_id'])\n",
    "\n",
    "X_train = X_train.sort_values(by='hadm_id')\n",
    "X_train = X_train.drop(columns=['hadm_id'])\n",
    "\n",
    "X_test = X_test.sort_values(by='hadm_id')\n",
    "X_test = X_test.drop(columns=['hadm_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
